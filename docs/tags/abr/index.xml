<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>ABR - 标签 - Ayamir&#39;s Blog</title>
        <link>https://ayamir.github.io/tags/abr/</link>
        <description>ABR - 标签 - Ayamir&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>miracle_l@bupt.edu.cn (Ayamir)</managingEditor>
            <webMaster>miracle_l@bupt.edu.cn (Ayamir)</webMaster><lastBuildDate>Sat, 26 Feb 2022 11:26:06 &#43;0800</lastBuildDate><atom:link href="https://ayamir.github.io/tags/abr/" rel="self" type="application/rss+xml" /><item>
    <title>Note for Survey on Bitrate Adaptation Schemes for Streaming Media Over HTTP (1)</title>
    <link>https://ayamir.github.io/posts/note-for-survey-on-bitrate-adaptation-schemes-for-streaming-media-over-http/</link>
    <pubDate>Sat, 26 Feb 2022 11:26:06 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/note-for-survey-on-bitrate-adaptation-schemes-for-streaming-media-over-http/</guid>
    <description><![CDATA[<h1 id="paper-overview">Paper Overview</h1>
<p>Link: <a href="https://ieeexplore.ieee.org/document/8424813" target="_blank" rel="noopener noreffer">https://ieeexplore.ieee.org/document/8424813</a></p>
<p>Level: IEEE Communications Surveys &amp; Tutorials 2019</p>
<h1 id="background">Background</h1>
<h2 id="traditional-non-has-ip-based-streaming">Traditional non-HAS IP-based streaming</h2>
<ol>
<li>
<p>The client receives media that is typically <em>pushed</em> by a media server using <strong>connection-oriented</strong> protocol such as Real-time Messaging Protocol(RTMP/TCP) or <strong>connectionless</strong> protocol such as Real-time Transport Protocol(RTP/UDP).</p>
</li>
<li>
<p>Real-time Streaming Protocol(RTSP) is a common protocol to control the media servers, which is responsible for setting up a streaming session and keeping the state information during this session, but is not responsible for actual media delivery(task for protocol like RTP).</p>
</li>
<li>
<p>The media server performs rate adaption and data delivery scheduling based on the RTP Control Protocol(RTCP) reports sent by the client.</p>
</li>
<li>
<p>When it comes to NAT and firewall, additional protocols or configurations are needed during the session establishment.</p>
</li>
</ol>
<p>The characteristics result in complex and expensive servers. These scalability and vendor dependency issues as well as high maintenance costs have resulted in deployment challenges for protocols like RTSP.</p>
<h2 id="has">HAS</h2>
<p>Around 2005, HTTP adaptive streaming(HAS) became popular and dominant, which treated the media content like regular Web content and delivered it in small pieces over HTTP protocol.</p>
<ol>
<li>HTTP as application and TCP as the transport-layer protocol.</li>
<li>Client <em>pull</em> the data from a standard HTTP server, which simply hosts the media content.</li>
<li>HAS solutions employ dynamic adaptation with respect to varying network conditions to provide a seamless streaming experience.</li>
<li>The original file/stream is partitioned into <em>segments</em> (also called <em>chunks</em>) of equi-length playback time. Multiple versions(also called representations) of each segment are generated that vary in bitrate/resolution/quality using an encoder or a transcoder.</li>
<li>The server generates an index file, which is a manifest that lists the available representations including HTTP urls to identify the segments along with their availability times.</li>
<li>The client first receives the manifest that contains the metadata for video, audio, subtitles and other features, then constantly measures certain parameters: available network bandwidth, buffer status, battery and CPU levels, etc. According to these parameters, the HAS client repeatedly fetches the most suitable next segment among the available representations from the server.</li>
</ol>
<p>Advantages:</p>
<ol>
<li>It use HTTP to deliver video segments, which simplifies the traversal through NATs and firewalls.</li>
<li>At the server side, it use conventional Web servers or caches available within the networks of ISPs and CDNs.</li>
<li>At the client side, it requests and fetches each segment independently from others and maintains the playback session state, whereas the server is not required to maintain any state.</li>
<li>It doesn&rsquo;t require a persistent connection between the client and server, which improves system scalability and reduces implementation and deployment costs.</li>
</ol>
<h2 id="comparison-summary">Comparison Summary</h2>
<p></p>
<p></p>
<h1 id="challenges">Challenges</h1>
<h2 id="multi-client-competitionstability-issues">Multi-Client Competition/Stability Issues</h2>
<p>A centralized management controller can enhance the overall video quality, while improve QoE.</p>
<p>A robust HAS scheme should achieve 3 main objectives:</p>
<ol>
<li><em>Stability</em>: HAS clients should avoid frequent bitrate switching.</li>
<li><em>Fairness</em>: Multiple HAS clients competing for available bandwidth should equally share network resources based on viewer, content and device characteristics.</li>
<li><em>High Utilization</em>: While the clients attempt to be stable and fair, network resources should be used as efficiently as possible.</li>
</ol>
<p>A streaming session consists of 2 states: buffer-filling state and steady state.</p>
<ul>
<li>
<p>The buffer-filling state aims to fill the playback buffer and reach a certain threshold where the playback can be initiated or resumed.</p>
</li>
<li>
<p>The steady state is to keep the buffer level above a minimum threshold despite bandwidth fluctuation or interruptions. The steady state consists of 2 activity periods referred to as ON and OFF.</p>
<p>The client requests a segment every $T_s$ time units, where $T_s$ represents the content time duration of each segment, and sum of ON and OFF period durations equals $T_s$.</p>
<ul>
<li>ON period: client downloads the current segment and notes the achieved throughput value that will be later used in selecting the appropriate bitrate for future segments.</li>
<li>OFF period: client becomes idle temporarily.</li>
</ul>
</li>
</ul>
<p></p>
<p>There are different cases during competition process.</p>
<ol>
<li>
<p>The ON periods of clients don&rsquo;t overlap during the current segment download, each client will overestimate the available bandwidth. So longer download time will cause the initially non-overlapping ON periods to eventually start overlapping.</p>
<p></p>
</li>
<li>
<p>As the amount of overlap increases, the clients will have lower bandwidth estimations and start selecting segments that have lower bitrate. These segment will take less time to download, causing the amount of overlap among the ON periods to precedurally shorten, until the process reverts to its initial situation.</p>
<p></p>
</li>
<li>
<p>The cycle repeats itself, causing periodic up and down shift in the selected bitrates, leading to unstable video quality, unfairness, and underutilization.</p>
<p></p>
</li>
</ol>
<h2 id="consistent-quality-streaming">Consistent-Quality Streaming</h2>
<p>The correlation between video bitrate and its perceptual quality is non-linear.</p>
<ul>
<li>Different video content types have unique characteristics.</li>
<li>Differences of inter-stream and intra-stream video scene complexity across content.</li>
</ul>
<p></p>
<p></p>
<h2 id="qoe-optimization-and-measurement">QoE Optimization and Measurement</h2>
<p>HAS scheme uses application control loop, which also interacts with a lower-layer control loop(such as TCP congestion control). It plays a key role in determining the viewer QoE.</p>
<p></p>
<p>Factors influencing QoE are categorized as:</p>
<ol>
<li>Perceptual, directly perceived by the viewer.</li>
<li>Technical, indirectly affecting the QoE.</li>
</ol>
<h3 id="perceptual">Perceptual</h3>
<p>Perceptual factors include the video image quality, initial delay, stalling duration and frequency.</p>
<p>The impact of these factors differs depending on the users subjectivity.</p>
<p>Most users consider initial delays less critical than stalling.</p>
<h3 id="technical">Technical</h3>
<p>Technical factors include the algorithms, parameters, and hardware/software used in streaming system.</p>
<p>Specifically, factors are:</p>
<ul>
<li>Server side: encoding parameters, video qualities and segment size.</li>
<li>Client side: adaptation parameters and environment that clients reside in.</li>
</ul>
<h3 id="qoe-measurement">QoE measurement</h3>
<ol>
<li>Objective matrics: Peak Signal-to-Noise Ratio(PSNR), Structural SIMilarity(SSIM and SSIMplus), Perceived Video Quality(PVQ) and Statistically Indifferent Quality Variation(SIQV).</li>
<li>Subjective matrics: Mean Opinion Score(MOS).</li>
<li>Quality-of-Service (QoS)-derived matrics: startup delay, average video bitrate, quality switches and rebuffering events.</li>
</ol>
<p>Try to optimize each metric is difficult because it may result in conflicts.</p>
<h2 id="inter-destination-multimedia-synchronization">Inter-Destination Multimedia Synchronization</h2>
<p>Online communities are drifting towards watching online videos together in a synchronized manner.</p>
<p>Having Multiple streaming clients distributed in different geographical locations poses challenges in delivering video content simultaneously, while keeping the playback state of each client the same.</p>
<p>Typically, IDMS solutions involve a master node to which clients synchronize their playout to.</p>
<p>Rainer et proposed an IDMS architecture for DASH by using a distribute control scheme where peers can communicate and negotiate a reference placback timestamp in each session.</p>
<p>In another work, Rainer et provided a crowdsourced subjective evaluation to find a asynchronism threshold at which QoE was not significantly affected.</p>
]]></description>
</item>
<item>
    <title>Note for srlABR Cross User</title>
    <link>https://ayamir.github.io/posts/note-for-srlabr-cross-user/</link>
    <pubDate>Sat, 15 Jan 2022 18:46:02 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/note-for-srlabr-cross-user/</guid>
    <description><![CDATA[<h2 id="论文概况">论文概况</h2>
<p>Link：<a href="https://ieeexplore.ieee.org/document/9234071" target="_blank" rel="noopener noreffer">Sequential Reinforced 360-Degree Video Adaptive Streaming With Cross-User Attentive Network</a></p>
<p>Level：IEEE Transactions on Broadcasting 2021</p>
<p>Keywords：Cross-user vp, Sequetial RL ABR</p>
<h2 id="主要工作">主要工作</h2>
<ul>
<li>使用跨用户注意力网络<code>CUAN</code>来做VP；</li>
<li>使用<code>360SRL</code>来做ABR</li>
<li>将上面两者集成到了推流框架中；</li>
</ul>
<h2 id="vp">VP</h2>
<h3 id="motivation">Motivation</h3>
<p>形式化VP问题如下：</p>
<p>给出 $p^{th}$ 用户的 $1-t$ 时间内的历史视点坐标 $L^{p}_{1:t} = \lbrace l^p_1, l^p_2, &hellip;, l^p_t \rbrace$ ，其中 $l^p_t = (x_t, y_t), x_t \in [-180, 180]; y_t \in [-90, 90]$ ；</p>
<p>同一视频的不同用户视点表示为 $L^{1:M}_{1:t+T}$ ， $M$ 表示其他用户的数量；</p>
<p>目标是预测未来的 $T$ 个时刻的视点位置 $L^p_i, i = t+1, &hellip;, t+T$ ；</p>
<p>最终可以用数学公式表达为：
$$
\underset{F}{min} \sum^{t+T}_{k = t+1} {\parallel l^p_k - \hat{l}^p_k \parallel}_1
$$</p>
<p>现有的用<code>KNN</code>做的跨用户预测基于LR的模型，而LR的模型很容易产生偏差，所以为了增强<code>KNN</code>的性能，同时考虑单用户的历史视点轨迹和跨用户的视点轨迹。</p>
<ul>
<li>提出一种注意力机制来自动提取来自其他用户视口的有用信息；</li>
<li>对于与当前用户有相似偏好的用户轨迹信息给与更多的注意；</li>
<li>相似性通过基于过去时间段内其他用户的轨迹计算出来；</li>
</ul>
<h3 id="design">Design</h3>
<p></p>
<ol>
<li>
<p>轨迹编码器模块从用户的历史视点位置提取时间特征；</p>
<p>使用<code>LSTM</code>来编码用户的观看路径；</p>
<p>为了预测 ${(t+1)}^{th}$ 帧的视点位置，首先向<code>LSTM</code>输入 $p^{th}$ 用户的历史视点坐标：
$$
f^{p}_{t+1} = h(l^p_1, l^p_2, &hellip;, l^p_t)
$$
$h(\cdot)$ 是<code>LSTM</code>的输入输出函数；</p>
<p>接着使用相同的<code>LTSM</code>编码其他用户的观看轨迹：
$$
f^{i}_{t+1} = h(l^i_1, l^i_2, &hellip;, l^i_{t+1}), i \in \lbrace 1, &hellip;, M \rbrace
$$</p>
</li>
<li>
<p>注意力模块从其他用户的视点轨迹中提取与 $p^{th}$ 用户相关的信息</p>
<p>首先推导出 $p^{th}$ 用户和其他用户之间的相关系数：
$$
s^{pi}_{t+1} = z(f^{i}_{t+1}, l^{p}_{t+1}), i \in \lbrace 1, &hellip;, M \rbrace \cup \lbrace p \rbrace;
$$
$s^{th}_{t+1}$ 表示 $p^{th}$ 用户和 $i^{th}$ 用户之间的相似性；$z()$ 由内积运算建模（还可用其他方式建模比如多个FC层）；</p>
<p>接着将相关系数规范化：
$$
{\alpha}^{pi}_{t+1} = \frac{e^{s^{pi}_{t+1}}}{\sum_{i \in \lbrace 1,&hellip; M \rbrace \cup {\lbrace p \rbrace}^{e^{s^{pi}_{t+1}}}}}
$$
最后得到融合特征：
$$
g^{p}_{t+1} = \sum_{i \in {\lbrace 1,&hellip;M \rbrace \cup \lbrace p \rbrace}} {\alpha}^{pi}_{t+1} \cdot f^{i}_{t+1}
$$
融合特征被最后用于VP。</p>
</li>
<li>
<p>VP模块预测 ${(t+1)}^{th}$ 帧的视点位置</p>
<p>$$
\hat{l}^{p}_{t+1} = r(g^{p}_{t+1})
$$
函数 $r(\cdot)$ 由一层FC建模。值得注意的是，对应于未来 T 帧的视点是以滚动方式预测的。</p>
</li>
</ol>
<h3 id="loss">Loss</h3>
<p>损失函数定义为预测的视点位置和实际视点位置之间的所有绝对差异的总和：
$$
L = \sum^{t+T}_{i=t} {|\hat{l}^p_i - l^p_i|}_1
$$</p>
<h3 id="details">Details</h3>
<ul>
<li>使用<code>PyTorch</code>实现；</li>
<li>函数 $h(\cdot)$ 由两个堆叠的<code>LSTM</code>层组成，两者都有32个神经元；</li>
<li>函数 $r(\cdot)$ 包含一个带有32个神经元的FC层，接着是<code>Tanh</code>函数；</li>
<li>历史视点和未来视点的长度设定为1秒和5秒；</li>
<li>每次迭代从数据集中随机产生2048个样本；</li>
<li>所有训练变量的优化函数采用<code>Adam</code>；</li>
<li>$\beta_1 = 0.9, \beta_2 = 0.999, \epsilon = 10^{-8}$；</li>
<li>$learning\ rate = 10^{-3}, training\ epoch = 50$；</li>
</ul>
<h2 id="abr">ABR</h2>
<h3 id="formulation">Formulation</h3>
<p>全景视频被切分成 $m$ 个长度为 $T$ 秒的视频片段，每个视频片段空间上划分成 $N$ 个分块，分别以 $M$ 个不同的码率等级编码。因此对于每段有 $N \times M$ 个可选的编码块。</p>
<p>ABR的目标是为每个片段找到最优的码率集 $X = \lbrace x_{i, j} \rbrace \in Z^{N \times M}$ （ $x_{i, j} = 1$ 意味着为 $i^{th}$ 块选择 $j^{th}$ 的码率等级）：
$$
\underset{X}{max} \sum^{m}_{t=1} Q_t
$$
$Q_t$ 表示 $t^{th}$ 段的QoE分数，与以下几个方面有关：</p>
<ul>
<li>
<p>VIewport Quality：
$$
Q^1_t = \sum^{N}_{i=1} \sum^{M}_{j=1} x_{i,j} \cdot p_i \cdot r_{i,j}
$$
$p_i$ 表示 $i^{th}$ 分块的规范化观看概率； $r_{i,j}$ 记录块 $(i, j)$ 的码率；</p>
</li>
<li>
<p>Viewport Temporal Variation：
$$
Q^2_t = |Q^1_t - Q^{1}_{t-1}|
$$</p>
</li>
<li>
<p>Viewport Spatial Variation：
$$
Q^3_t = \frac{1}{2} \sum^{N}_{i=1} \sum_{u \in U_i} p_i \cdot p_u \sum^{M}_{j=1} |x_{i,j} \cdot r_{i,j} - x_{u,j} \cdot r_{u,j}|
$$
$U_i$ 表示 $i^{th}$ 个分块的1跳邻居中的tile索引<a href="https://ieeexplore.ieee.org/document/8486606" target="_blank" rel="noopener noreffer">[1]</a>；</p>
</li>
<li>
<p>Rebuffering：
$$
Q^4_t = max(\frac{\sum^{N}_{i=1} \sum^{M}_{j=1} x_{i,j} \cdot r_{i,j} \cdot T}{\xi_t} - b_{t-1}, 0)
$$
$\xi_t$ 表示网络吞吐量； $b_{t-1}$ 表示播放器的缓冲区占用率；</p>
<p>最终的QoE可以由上面的指标定义：
$$
Q_t = Q^1_t - \eta_1 \cdot Q^2_t - \eta_2 \cdot Q^3_t - \eta_3 \cdot Q^4_t
$$
$\eta_*$ 是可调节的参数，与不同的用户偏好对应。</p>
</li>
</ul>
<h3 id="sequential-rl-based-abr">Sequential RL-Based ABR</h3>
<p>假设基于tile的全景推流ABR过程也是MDP。</p>
<p></p>
<p>细节在<a href="https://ayamir.github.io/posts/note-for-360srl/" target="_blank" rel="noopener noreffer">360SRL</a>中已经说明清楚。</p>
]]></description>
</item>
<item>
    <title>Note for 360SRL</title>
    <link>https://ayamir.github.io/posts/note-for-360srl/</link>
    <pubDate>Thu, 13 Jan 2022 12:08:36 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/note-for-360srl/</guid>
    <description><![CDATA[<h2 id="论文概况">论文概况</h2>
<p>Link：<a href="https://ieeexplore.ieee.org/document/8784927" target="_blank" rel="noopener noreffer">360SRL: A Sequential Reinforcement Learning Approach for ABR Tile-Based 360 Video Streaming</a></p>
<p>Level：ICME 2019</p>
<p>Keywords：ABR、RL、Sequential decision</p>
<h2 id="创新点">创新点</h2>
<ul>
<li>在MDP中，将N维决策空间内的一次决策转换为1维空间内的N次级联顺序决策处理来降低复杂度。</li>
</ul>
<h2 id="问题定义">问题定义</h2>
<p>原始的全景视频被划分成每段固定长度为 $T$ 的片段，</p>
<p>每个片段包含 $N$ 个分块，并以 $M$ 的码率等级独立编码，</p>
<p>因此对每个片段，有 $N \times M$ 种可选的编码块。</p>
<p>为了保证播放时的流畅性，需要确定最优的预取集合：</p>
<p>${a_0, &hellip;, a_i, &hellip;, a_{N-1}}, i \in \lbrace 0, &hellip;, N-1 \rbrace, a_i \in \lbrace 0, &hellip;, M-1 \rbrace $</p>
<p>分别用 $q_{i, a_i}$ 和 $w_{i, a_i}$ 表示码率选择为 $a^{th}_i$ 的 $i^{th}$ 分块的质量和相应的分块片段大小。</p>
<p>用 $p_i \in [0, 1]$ 表示 $i^{th}$ 块的被看到的可能性。</p>
<h2 id="顺序abr决策">顺序ABR决策</h2>
<p></p>
<h2 id="代理设计">代理设计</h2>
<h3 id="状态">状态</h3>
<p>对于 $i^{th}$ 维，输入状态包括原始的环境状态 $s_t$ ；</p>
<p>与之前维度的动作集合相关的信号： $u^{i}_{s_t} = \lbrace Th, C_i, p_{0:i-1}, q_{0:i-1}, b_t, p_i, S_i, Q_{t-1} \rbrace$</p>
<p>$Th$ ：表示过去 m 次下载一个段的平均吞吐量；</p>
<p>$C_i \in R^M$ ：表示 $i^{th}$ 个分块的可用块大小向量；</p>
<p>$p_{0:i-1}$ 和 $q_{0:i-1, a^{0:i-1}_{t}}$ 分别表示选中的码率集合和看到之前 $i-1$ 个分块的概率集；</p>
<p>$b_t$ 是缓冲区大小；</p>
<p>$p_i$ 是 $i^{th}$ 个分块被看到的可能性；</p>
<p>$S_i$ 是之前选择的 $i-1$ 个分块的块大小之和： $S_i = \sum^{i-1}_{h=0} C_{h, a^h_t}$ ；</p>
<p>$Q_{t-1}$ 记录了最后一个段中 $N$ 个分块的平均视频质量；</p>
<h3 id="动作">动作</h3>
<p>动作空间离散，代理输出定义为价值函数：$f(u^i_{s_t}, a^i_t)$</p>
<p>表示所选状态的价值 $a^i_t \in \lbrace 0, &hellip;, M-1 \rbrace$ 处于状态 $u_{s_t}^i$ .</p>
<h3 id="回报">回报</h3>
<p>回报定义为下列因素的加权和：</p>
<p>平均视频质量 $q^{avg}_t$，空间视频质量方差 $q^{s_v}_t$，时间视频质量方差 $q^{t_v}_t$ ，重缓冲时间 $T^r_t$</p>
<p>$$
q^{avg}_t = \frac{1}{\sum^{N-1}_{i=0} p_i} \cdot \sum^{N-1}_{i=0} p_i \cdot q_{i, a_i}
$$</p>
<p>$$
q^{s_v}_t = \frac{1}{\sum^{N-1}_{i=0} p_i} \cdot \sum^{N-1}_{i=0} p_i \cdot |q_{i, a_i} - q^{avg}_t|
$$</p>
<p>$$
q^{t_v}_t = |q^{avg}_{t-1} - q^{avg}_t|
$$</p>
<p>$$
T^r_t = max \lbrace T_t - b_{t-1}, 0 \rbrace
$$</p>
<p>$$
R_t = w_1 \cdot q^{avg}_t - w_2 \cdot q^{s_v}_t - w_3 \cdot q^{t_v}_t - w_4 \cdot T^r_t
$$</p>
<h2 id="训练方法">训练方法</h2>
<p>使用<code>DQN</code>作为基本的算法来学习动作-价值函数 $Q(s_t, a_t; \theta)$ ，其中 $\theta$ 作为参数，对应的贪心策略为 $\pi(s_t; \theta) = \underset{\theta}{argmax} Q(s_t, a_t; \theta)$ 。</p>
<p><code>DQN</code>网络的关键想法是更新最小化损失函数的方向上的参数：
$$
L(\theta) = E[y_t - Q(s_t, a_t; \theta)]
$$</p>
<p>$$
y_t = r(s_t, a_t) + \gamma Q(s_{t+1}, \pi(s_{t+1}; {\theta}'); {\theta}')
$$
${\theta}'$ 表示固定且分离的目标网络的参数；</p>
<p>$r(\cdot)$ 是即时奖励函数，即上面公式5中的 $R_t$ ；</p>
<p>$\gamma \in [0, 1]$ 是折扣因子；</p>
<p>为了缓解过拟合，引入 <code>double-DQN</code> 的结构，所以公式7被重写为：
$$
y_t = r(s_t, a_t) + \gamma Q(s_{t+1}, {\pi}(s_{t+1}; \theta); {\theta}')
$$
利用公式6和公式8可以得出 $i^{th}$ 维的暂时损失函数：
$$
l^i_t = Q_{target} - Q(u^i_{s_t}, a^i_t; \theta), \forall i \in [0, &hellip;N-1]
$$
其中 $Q_{target}$ 满足：</p>
<p>$$
Q_{target} = r_t + {\gamma}_u \cdot Q(u^0_{s_{t+1}}, \pi(u^0_{s_{t+1}}; 0); {\theta}')
$$</p>
<p>${\gamma}_u$ 和 ${\gamma}_b$ 分别代表”Top MDP“和”Bottom MDP“的折扣因子，训练中设定 ${\gamma}_b = 1$ 。</p>
<p>观察公式9和公式10可以看出每维都有相同的目标函数，意味着无法区别每个独立维度的动作 $a^i_t$ 对 $r_t$ 的贡献。</p>
<p>为了克服限制，根据某个分块的动作 $a^i_t$ 与其观看概率成正比的先验知识，向 $l^i_t$ 添加一个额外的 $r^i_{extra}$ ：
$$
l^i_t = r^i_{extra} + Q_{target} - Q(u^i_{s_t}, a^i_t; \theta), \forall i \in [0, &hellip;N-1]
$$</p>
<p>$$
r^i_{extra} =
\begin{cases}
0, p_i &gt; P ;
\
-a^i_t, p_i \le P
\end{cases}
$$</p>
<p>通过设定一个观看概率的阈值 $P$ ，对观看概率低于 $P$ 但选择了高码率的分块施加 $-a^i_t$ 的奖励。</p>
<p>因此最终的平均损失可以形式化为：
$$
l^{avg}_t = \frac{1}{N} \sum^{N-1}_{i=0} l^i_t
$$
接着使用梯度下降法来更新模型，学习率设定为 $\alpha$：
$$
\theta \larr \theta + \alpha \triangledown l^{avg}_t
$$
同时，在训练阶段利用经验回放法来提高<code>360SRL</code>的泛化性。</p>
<p></p>
<p></p>
<h2 id="实现细节">实现细节</h2>
<p></p>
<p>特征从输入状态中通过特征提取网络提取出来。</p>
<p>初始的4个输入通过带有128个过滤器的1维卷积层被传递，4个输入核心大小分别为 $1 \times m$ 、 $1 \times M$ 、 $1 \times N$ 、 $1 \times M$ ，后续这4个输入被喂给有128个神经元的全连接层；</p>
<p>随后特征映射被连接成一个张量，接着是具有1024个神经元和256个神经元的前向网络；</p>
<p>整个动作-价值网络的输出是M维的向量。</p>
<p>特征提取层和前向网络层都使用 <code>Leaky-ReLU</code>作为激活函数，最后是层归一化层。</p>
]]></description>
</item>
<item>
    <title>Note for MPC</title>
    <link>https://ayamir.github.io/posts/note-for-mpc/</link>
    <pubDate>Thu, 23 Dec 2021 10:39:32 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/note-for-mpc/</guid>
    <description><![CDATA[<h2 id="论文概况">论文概况</h2>
<p>Link：<a href="https://dl.acm.org/doi/10.1145/2785956.2787486" target="_blank" rel="noopener noreffer">A Control-Theoretic Approach for Dynamic Adaptive Video Streaming over HTTP</a></p>
<p>Level：ACM SIGCOMM 15</p>
<p>Keywords：Model Predictive Control，ABR，DASH</p>
<h2 id="motivation">Motivation</h2>
<p>关于码率自适应的逻辑，现有的解决方案还没有形成清晰的、一致的意见。不同类型的方案之间优化的出发点并不相同，比如基于速率和基于缓冲区，而且没有广泛考虑各方面的因素并形成折中。</p>
<p>文章引入了控制论中的方法，将各方面的影响因素形式化为<em>随机优化控制</em>问题，利用<strong>模型预测控制MPC</strong>将两种不同出发点的解决方案结合到一起，进而解决其最优化的问题。而仿真结果也证明，如果能运行一个最优化的MPC算法，并且预测误差很低，那么MPC方案可以优于传统的基于速率和基于缓冲区的策略。</p>
<h2 id="背景">背景</h2>
<ul>
<li>播放器端为QoE需要考虑的问题：
<ol>
<li>最小化冲缓冲事件发生的次数；</li>
<li>在吞吐量限制下尽可能传输码率较高的视频；</li>
<li>最小化播放器开始播放花费的时间（启动时间）；</li>
<li>保持播放过程平滑，尽可能避免大幅度的码率变化；</li>
</ol>
</li>
<li>这些目标相互冲突的原因：
<ol>
<li>最小化重缓冲次数和启动时间会导致只选择最低码率的视频；</li>
<li>尽可能选择高码率的视频会导致很多的重缓冲事件；</li>
<li>保持播放过程平滑可能会与最小的重缓冲次数与最大化的平均码率相冲突；</li>
</ol>
</li>
</ul>
<h2 id="控制论模型">控制论模型</h2>
<h3 id="视频推流模型">视频推流模型</h3>
<ol>
<li>
<p>参数形式化</p>
<ul>
<li>
<p>将视频建模成连续片段的集合，即：$V = \lbrace 1, 2, &hellip;, K \rbrace$，每个片段长为$L$秒；</p>
</li>
<li>
<p>每个片段以不同码率编码，$R$ 作为所有可用码率的集合；</p>
</li>
<li>
<p>播放器可以选择以码率$R_k \in R$ 下载第$k$块片段，$d_k(R_k)$ 表示以码率$R_k$编码的视频大小；</p>
<ul>
<li>对于恒定码率CBR的情况，$d_k(R_k) = L \times R_k$；</li>
<li>对于变化码率VBR的情况，$d_k \sim R_k$；</li>
</ul>
</li>
<li>
<p>选择的码率越高，用户感知到的质量越高：</p>
<p>$q(\cdot):R \rightarrow \R_+$ 是一个不减函数，是选择的码率 $R_k$ 到用户感知到的视频质量 $q(R_k)$ 的映射；</p>
</li>
<li>
<p>片段被下载到<em>回访缓冲</em>中，其中包含下载了的但还没看过的片段。</p>
</li>
<li>
<p>$B(t) \in [0, B_{max}]$ 表示 $t$ 时刻缓冲区的占用， $B_{max}$ 表示内容提供商的策略和播放器的存储限制；</p>
</li>
</ul>
</li>
<li>
<p>播放过程形式化</p>
<p>在 $t_k$ 时刻，视频播放器开始下载第 $k$ 个块，这个块的下载时间可以计算为： $d_k(R_k) / C_k$； $C_k$ 表示下载过程中经历的平均下载速度；</p>
<p>一旦第 $k$ 个块下载完毕，播放器等待 $\Delta t_k$ 时间并在 $t_{k+1}$ 时刻下载下一个块 $k+1$ ；</p>
<p>假设等待时间 $\Delta t_k$ 很短并且不会导致重缓冲事件，用 $C_t$ 表示 $t$ 时刻的网络吞吐量：
$$
t_{k+1} = t_k + \frac{d_k(R_k)}{C_k} + \Delta t_k
$$</p>
<p>$$
C_k = \frac{1}{t_{k+1} - t_k - \Delta t_k} \int_{t_k}^{t_{k+1} - \Delta t_k} C_t dt
$$</p>
<p>$B(t)$ 的变化取决于下载的块和播放的块的数量：</p>
<p>在第 $k$ 个块下载完毕之后缓冲区占用增长 $L$ 秒；用户观看一个块之后缓冲区占用减少 $L$ 秒；</p>
<p>$B_k = B(t_k)$ 表示播放器开始下载第 $k$ 个块时的缓冲区占用；</p>
<p>缓冲区占用的动态变化可以表示为：
$$
B_{k+1} = \big( (B_k - \frac{d_k(R_k)}{C_k})_+ + L - \Delta t_k \big)_+
$$
其中 $(x)_+ = max\lbrace x, 0 \rbrace $ 确保其非负；</p>
<p>如果 $B_k &lt; d_k(R_k) / C_k$ ，表示缓冲区在播放器还在下载第 $k$ 个块时变空，而这会导致重缓冲事件；</p>
<p></p>
<p>等待时间 $\Delta t_k$ 的确定也称为<em>块调度</em>问题，本文中假设播放器在第 $k$ 个块下载完毕之后尽可能快地去下载第 $k+1$ 个块（除了缓冲区满了的情况，播放器等待缓冲区中的块被消耗之后再下载新的块）：
$$
\Delta t_k = \Big( \big( B_k - \frac{d_k(R_k)}{C_k} \big)_+ + L - B_max \Big)_+
$$</p>
</li>
</ol>
<h3 id="qoe最大化问题">QoE最大化问题</h3>
<p>QoE的组成部分：</p>
<ol>
<li>
<p>平均视频质量：在所有块中每个块平均的质量，计算为：
$$
\frac{1}{K} \sum^K_{k=1} q(B_k)
$$</p>
</li>
<li>
<p>平均质量变化：相邻块之间质量变化的平均值，计算为：
$$
\frac{1}{K-1} \sum^{K-1}_{k=1} | q(R_{k+1}) - q(R_k) |
$$</p>
</li>
<li>
<p>重缓冲总计时间：对每个块而言，当轮到其被消耗时但下载块的过程还没完成即出现了重缓冲，总时间计算为：
$$
\sum^K_{k=1} (\frac{d_k(R_k)}{C_k} - B_k)_+
$$</p>
</li>
<li>
<p>启动延迟 $T_s$ ，假设 $T_s \ll B_{max}$ 。</p>
</li>
</ol>
<p>对不同用户而言，上述4种因素的重要程度不同。使用上述分量的加权，定义视频块 $1$ 到 $K$ 的QoE：
$$
QoE^K_1 = \sum^K_{k=1} q(R_k) - \lambda \sum^K_{k=1} | q(R_{k+1}) - q(R_k) | - \mu \sum^K_{k=1} (\frac{d_k(R_k)}{C_k} - B_k)_+ - \mu_s T_s,\
\lambda, \mu, \mu_s \nless 0
$$
相对较小的 $\lambda$ 表示用户不太关心视频质量变化； $\lambda$ 越大表明越需要使视频质量变得光滑。</p>
<p>相对较大的 $\mu$ 表示用户很在意重缓冲；</p>
<p>在这里文章倾向于启动延迟很低，所以采用大 $\mu_s$ ；</p>
<p>QoE的最大化：</p>
<p>输入：吞吐量迹 ${C_t, t \in [t_1, t_{K+1}]}$</p>
<p>输出：码率选择 $R_1, &hellip;, R_K$；启动时间 $T_s$ ；</p>
<p>需要注意：当最大化的决策发生在播放过程中时，启动时间便不再存在；</p>
<p></p>
<h3 id="算法">算法</h3>
<p>上图中的QoE最大化问题是一种随机优化控制问题，随机性源自可获得的吞吐量 $C_t$ 。</p>
<p>$t_k$ 时刻播放器选择码率 $R_k$ ，只有过去的吞吐量 $\lbrace C_t, t \le t_k \rbrace$ 可知，未来的值 ${C_t, t &gt; t_k}$ 未知。</p>
<p>但是，<em>吞吐量预测器</em>可以用于获取对吞吐量的预测，定义其为 $\lbrace \hat{C_t}, t &gt; t_k \rbrace$ 。</p>
<p>基于这样的预测和缓冲区的信息（精确可知），<em>码率选择器</em>对下个块 $k$ 的码率选择可以表示为：
$$
R_k = f \big( B_k, \lbrace \hat{C_t}, t &gt; t_k \rbrace, \lbrace R_i, i &lt; k \rbrace \big)
$$
文章只关注码率自适应算法，假设已经得到了预测值，并根据预期预测误差对其进行了表征，即：</p>
<p>我们着重于 $f(\cdot)$ 的设计以及预测误差对比较控制算法性能的影响。</p>
<p>现有的两类自适应算法：基于速率和基于缓冲区，分别可以表示为：
$$
R_k = f \big( \lbrace \hat{C_t}, t &gt; t_k \rbrace, \lbrace R_i, i &lt; k \rbrace \big)
$$</p>
<p>$$
R_k = f(B_k, \lbrace R_i, i &lt; k \rbrace)
$$</p>
<p>前者只基于吞吐量的预测结果而不管缓冲区状况；后者只基于缓冲区而不管未来的吞吐量可能状况；</p>
<p>这两种方法在原则上都只是次优的，理想情况下我们想要同时考虑缓冲区占用和吞吐量预测结果。</p>
<p></p>
<h2 id="mpc-for-optimal-bitrate-adaptation">MPC for Optimal Bitrate Adaptation</h2>
<h3 id="why-mpc">Why MPC</h3>
<p>MPC天然适合码率自适应问题。</p>
<ul>
<li>
<p><strong>Strawman solutions</strong></p>
<p>码率自适应问题本质是<em>随机控制优化</em>问题，就这一点而言，有两个知名控制算法：</p>
<ol>
<li>Proportional-integral-derivation(PID) control.</li>
<li>Markov Decision Process(MDP) based control.</li>
</ol>
<p>PID相较MDP而言计算起来更加简单，只能用于使系统稳定，不能显式地优化QoE目标；此外PID被设计用于有连续的时间和连续的状态空间的问题中，用于当前这种高度离散化的问题中会导致性能亏损和不稳定。</p>
<p>应用MDP的话可以将吞吐量和缓冲区状态形式化为马氏过程，然后使用诸如值迭代和策略迭代等标准算法求出最优解。</p>
<p>（然而，这有一个很强的假设，即吞吐量动态遵循马尔可夫过程，不清楚这在实践中是否成立。我们将MDP的潜在用途和吞吐量动态分析作为未来的工作。）</p>
</li>
<li>
<p><strong>Case for MPC</strong></p>
<p>理想情况下，如果给出未来吞吐量的完美数据，那么启动时间 $T_s$ 和最优码率选择 $R_1, &hellip; R_K$ 可以一下子就计算出来；</p>
<p>实际情况中，虽然不能得到未来吞吐量的完美预测，但是我们可以假设吞吐量在较短的时间段 $[t_k, t_{k+N}]$ 内不会剧烈变化。</p>
<p>基于此，可以使用当前视界中的预测来应用第1个码率 $R_k$ ，之后将视界向前移动到 $[t_{k+1}, t_{k+N+1}]$ 。</p>
<p>而这种方案就称为MPC。MPC的一般好处在于，MPC可以利用预测在约束条件下在线优化动态系统中的复杂控制目标。</p>
</li>
</ul>
]]></description>
</item>
</channel>
</rss>
