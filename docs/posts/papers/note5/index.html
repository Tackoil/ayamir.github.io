<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>自适应360度视频推流挑战 - Ayamir&#39;s Blog</title><meta name="description" content="Welcome to Ayamir&#39;s blog."><meta property="og:title" content="自适应360度视频推流挑战" />
<meta property="og:description" content="背景 用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。 沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ayamir.github.io/posts/papers/note5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-04T11:01:18+08:00" />
<meta property="article:modified_time" content="2023-06-01T02:10:37+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="自适应360度视频推流挑战"/>
<meta name="twitter:description" content="背景 用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。 沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的"/>
<meta name="application-name" content="Ayamir&#39;s blog">
<meta name="apple-mobile-web-app-title" content="Ayamir&#39;s blog"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://ayamir.github.io/posts/papers/note5/" /><link rel="prev" href="https://ayamir.github.io/posts/papers/note4/" /><link rel="next" href="https://ayamir.github.io/posts/papers/note6/" /><link rel="stylesheet" href="/css/page.min.3c64fa2243caf1a1a9f6f88aa692d72009f930caa2e1677ef98d74dc6469d3cf.css" integrity="sha256-PGT6IkPK8aGp9viKppLXIAn5MMqi4Wd&#43;&#43;Y103GRp088="><link rel="stylesheet" href="/css/home.min.f4efba72b201bd01e9371fb690efe6063b4a3785c6a9807a9340423c9aeed132.css" integrity="sha256-9O&#43;6crIBvQHpNx&#43;2kO/mBjtKN4XGqYB6k0BCPJru0TI="><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "自适应360度视频推流挑战",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/ayamir.github.io\/posts\/papers\/note5\/"
        },"genre": "posts","keywords": "Immersive Video","wordcount":  10274 ,
        "url": "https:\/\/ayamir.github.io\/posts\/papers\/note5\/","datePublished": "2021-11-04T11:01:18+08:00","dateModified": "2023-06-01T02:10:37+08:00","publisher": {
            "@type": "Organization",
            "name": "Ayamir"},"author": {
                "@type": "Person",
                "name": "Ayamir"
            },"description": ""
    }
    </script></head><body data-header-desktop="auto" data-header-mobile="auto"><script>(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : '' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Ayamir&#39;s Blog">Ayamir&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="#" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Ayamir&#39;s Blog">Ayamir&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="#" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="#" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><div class="menu-item"><a href="javascript:void(0);" class="theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div></div>
    </div>
</header><div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single" data-toc="enable"><div class="single-card" ><h2 class="single-title animated flipInX">自适应360度视频推流挑战</h2><div class="post-meta">
                <div class="post-meta-line"><span class="post-author"><a href="https://github.com/ayamir" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>Ayamir</a></span>&nbsp;<span class="post-category">出版于  <a href="/categories/paper/"><i class="far fa-folder fa-fw"></i>paper</a></span></div>
                <div class="post-meta-line"><span><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-04">2021-11-04</time></span>&nbsp;<span><i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 10274 字</span>&nbsp;
                    <span><i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 21 分钟</span>&nbsp;</div>
            </div>
            
            <hr><div class="details toc" id="toc-static"  data-kept="">
                    <div class="details-summary toc-title">
                        <span>目录</span>
                        <span><i class="details-icon fas fa-angle-right"></i></span>
                    </div>
                    <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#背景">背景</a>
      <ul>
        <li><a href="#viewport预测">Viewport预测</a>
          <ul>
            <li><a href="#背景-1">背景</a></li>
            <li><a href="#分类">分类</a></li>
            <li><a href="#内容不可知方式">内容不可知方式</a>
              <ul>
                <li><a href="#分类-1">分类</a></li>
                <li><a href="#现有成果">现有成果</a>
                  <ul>
                    <li><a href="#qians-worklr">Qian&rsquo;s work——LR</a></li>
                    <li><a href="#petrangelis-worklr">Petrangeli&rsquo;s work——LR</a></li>
                    <li><a href="#mavlankar-and-girods-work运动向量">Mavlankar and Girod&rsquo;s work——运动向量</a></li>
                    <li><a href="#la-fuentes-work运动向量">La Fuente&rsquo;s work——运动向量</a></li>
                    <li><a href="#bans-workknnlr">Ban&rsquo;s work——KNN+LR</a></li>
                    <li><a href="#lius-workcluster">Liu&rsquo;s work——cluster</a></li>
                    <li><a href="#petrangelis-workcluster">Petrangeli&rsquo;s work——cluster</a></li>
                    <li><a href="#rossis-workcluster">Rossi&rsquo;s work——cluster</a></li>
                    <li><a href="#jiangs-work">Jiang&rsquo;s work</a></li>
                    <li><a href="#baos-work">Bao&rsquo;s work</a></li>
                    <li><a href="#hous-work">Hou&rsquo;s work</a></li>
                    <li><a href="#heyses-work">Heyse&rsquo;s work</a></li>
                    <li><a href="#qians-work">Qian&rsquo;s work</a></li>
                    <li><a href="#yu-and-lius-work">Yu and Liu&rsquo;s work</a></li>
                    <li><a href="#jamalis-work">Jamali&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#内容感知方式">内容感知方式</a>
              <ul>
                <li><a href="#背景-2">背景</a></li>
                <li><a href="#具体方法">具体方法</a>
                  <ul>
                    <li><a href="#aladaglis-work">Aladagli&rsquo;s work</a></li>
                    <li><a href="#nguyens-work">Nguyen&rsquo;s work</a></li>
                    <li><a href="#xus-work">Xu&rsquo;s work</a></li>
                    <li><a href="#xus-work-1">Xu&rsquo;s work</a></li>
                    <li><a href="#fans-work">Fan&rsquo;s work</a></li>
                    <li><a href="#yangs-work">Yang&rsquo;s work</a></li>
                    <li><a href="#ozcinars-work">Ozcinar&rsquo;s work</a></li>
                    <li><a href="#lis-work">Li&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#总结">总结</a></li>
          </ul>
        </li>
        <li><a href="#qoe评估">QoE评估</a>
          <ul>
            <li><a href="#背景-3">背景</a></li>
            <li><a href="#主观质量评估">主观质量评估</a>
              <ul>
                <li><a href="#upeniks-work">Upenik&rsquo;s work</a></li>
                <li><a href="#zhangs-work">Zhang&rsquo;s work</a></li>
                <li><a href="#xus-work-2">Xu&rsquo;s work</a></li>
                <li><a href="#schatzs-work">Schatz&rsquo;s work</a></li>
                <li><a href="#可用的开源工具">可用的开源工具</a></li>
                <li><a href="#cybersickness"><code>Cybersickness</code></a>
                  <ul>
                    <li><a href="#singlas-work">Singla&rsquo;s work</a></li>
                    <li><a href="#trans-work">Tran&rsquo;s work</a></li>
                    <li><a href="#singlas-work-1">Singla&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#空间存在感">空间存在感</a>
                  <ul>
                    <li><a href="#zous-work">Zou&rsquo;s work</a></li>
                    <li><a href="#huponts-work">Hupont&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#生理特征度量">生理特征度量</a>
                  <ul>
                    <li><a href="#salgados-work">Salgado&rsquo;s work</a></li>
                    <li><a href="#egans-work">Egan&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#技术因素感知">技术因素感知</a>
                  <ul>
                    <li><a href="#fremereys-work">Fremerey&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#总结-1">总结</a></li>
              </ul>
            </li>
            <li><a href="#客观质量评估">客观质量评估</a>
              <ul>
                <li><a href="#计算psnr">计算PSNR</a>
                  <ul>
                    <li><a href="#yus-work">Yu&rsquo;s work</a></li>
                    <li><a href="#zakharchenkos-work">Zakharchenko&rsquo;s work</a></li>
                    <li><a href="#suns-work">Sun&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#计算ssim">计算SSIM</a>
                  <ul>
                    <li><a href="#chens-work">Chen&rsquo;s work</a></li>
                    <li><a href="#zhous-work">Zhou&rsquo;s work</a></li>
                    <li><a href="#van-der-hoofts-work">Van der Hooft&rsquo;s work</a></li>
                    <li><a href="#xus-work-3">Xu&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#基于psnr和ssim方式的改进">基于PSNR和SSIM方式的改进</a>
                  <ul>
                    <li><a href="#upeniks-work-1">Upenik&rsquo;s work</a></li>
                    <li><a href="#trans-work-1">Tran&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#基于ml的方式">基于ML的方式</a>
                  <ul>
                    <li><a href="#da-costa-filhos-work">Da Costa Filho&rsquo;s work</a></li>
                    <li><a href="#lis-work-1">Li&rsquo;s work</a></li>
                    <li><a href="#yangs-work-1">Yang&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#总结-2">总结</a></li>
          </ul>
        </li>
        <li><a href="#低延迟推流">低延迟推流</a>
          <ul>
            <li><a href="#背景-4">背景</a></li>
            <li><a href="#减少启动时间">减少启动时间</a>
              <ul>
                <li><a href="#减少初始化请求的数据量">减少初始化请求的数据量</a>
                  <ul>
                    <li><a href="#van-der-hoofts-work-1">Van der Hooft&rsquo;s work</a></li>
                    <li><a href="#nguyens-work-1">Nguyen&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#降低由tile分块带来的网络负载">降低由tile分块带来的网络负载</a>
              <ul>
                <li>
                  <ul>
                    <li><a href="#weis-work">Wei&rsquo;s work</a></li>
                    <li><a href="#petrangelis-work">Petrangeli&rsquo;s work</a></li>
                    <li><a href="#xus-work-4">Xu&rsquo;s work</a></li>
                    <li><a href="#yahias-work">Yahia&rsquo;s work</a></li>
                    <li><a href="#yens-work">Yen&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#使用移动边缘计算降低延迟">使用移动边缘计算降低延迟</a>
              <ul>
                <li>
                  <ul>
                    <li><a href="#mangiantes-work">Mangiante&rsquo;s work</a></li>
                    <li><a href="#lius-work">Liu&rsquo;s work</a></li>
                    <li><a href="#viitanens-work">Viitanen&rsquo;s work</a></li>
                    <li><a href="#shis-work">Shi&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#共享vr环境中的延迟处理">共享VR环境中的延迟处理</a>
              <ul>
                <li>
                  <ul>
                    <li><a href="#parks-work">Park&rsquo;s work</a></li>
                    <li><a href="#perfectos-work">Perfecto&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#总结-3">总结</a></li>
          </ul>
        </li>
        <li><a href="#360度直播推流">360度直播推流</a>
          <ul>
            <li><a href="#背景-5">背景</a>
              <ul>
                <li><a href="#内容分发">内容分发</a>
                  <ul>
                    <li><a href="#hus-work">Hu&rsquo;s work</a></li>
                    <li><a href="#griwodzs-work">Griwodz&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#视频转码">视频转码</a>
                  <ul>
                    <li><a href="#lius-work-1">Liu&rsquo;s work</a></li>
                    <li><a href="#baigs-work">Baig&rsquo;s work</a></li>
                    <li><a href="#les-work">Le&rsquo;s work</a></li>
                  </ul>
                </li>
                <li><a href="#内容拼接缝合">内容拼接缝合</a>
                  <ul>
                    <li><a href="#chens-work-1">Chen&rsquo;s work</a></li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><a href="#总结-4">总结</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav></div>
                </div><div class="content" id="content"><h1 id="背景">背景</h1>
<p>用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。</p>
<p>沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的消极影响。</p>
<p>目前主要面临的挑战有以下4个：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png"
        data-srcset="https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png, https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png 1.5x, https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png 2x"
        data-sizes="auto"
        alt="https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png"
        title="image-20211104111113514" /></p>
<h2 id="viewport预测">Viewport预测</h2>
<h3 id="背景-1">背景</h3>
<p>HMD的本质特征是快速响应用户头部的移动。当用户改变viewport时HMD处理交互并检测相关的viewport来精确播放器的信息，这样视野就能以正常的可视角度被提供给用户。Viewport预测在优化的360度视频推流中非常必要。配备有位置传感器的可穿戴HMD允许客户端更新其视角方向相应的视角场景。</p>
<h3 id="分类">分类</h3>
<ul>
<li><em>内容不可知</em>的方式基于历史信息对viewport进行预测。</li>
<li><em>内容感知</em>的方式需要视频内容信息来预测未来的viewport。</li>
</ul>
<h3 id="内容不可知方式">内容不可知方式</h3>
<h4 id="分类-1">分类</h4>
<ul>
<li>平均线性回归LR</li>
<li>航位推算DR</li>
<li>聚类</li>
<li>机器学习ML</li>
<li>编解码器体系结构</li>
</ul>
<h4 id="现有成果">现有成果</h4>
<h5 id="qians-worklr">Qian&rsquo;s work——LR</h5>
<p>使用平均线性回归和加权线性回归模型来做viewport预测，之后对与预测区域重叠的tile进行整体推流。</p>
<ul>
<li>当预测后0.5s、1s、2s加权线性回归表现更好</li>
</ul>
<h5 id="petrangelis-worklr">Petrangeli&rsquo;s work——LR</h5>
<p>将被划分成tile的等矩形的帧分成3个区域：viewport区、相邻区、其他区。</p>
<p>结合观察者头部的移动，将可变比特率分配给可见和不可见区域。</p>
<p>作者利用最近（100毫秒）用户观看历史的线性外推来预测未来的注视点。</p>
<h5 id="mavlankar-and-girods-work运动向量">Mavlankar and Girod&rsquo;s work——运动向量</h5>
<p>使用运动向量比如观察者的平移、倾斜、缩放等方向上的速度和加速度，来执行视角区域预测。</p>
<h5 id="la-fuentes-work运动向量">La Fuente&rsquo;s work——运动向量</h5>
<p>考虑了两种预测变体：角速度和角加速度，从用户以前的方向数据来估计未来的头部方向。按照预测结果分配不同的量化参数到每个tile上。</p>
<p>当进行进一步的预测时（超过2s），这种方式限制了预测的精度。</p>
<p>如果视频tile被基于错误的预测而被请求，用户的实际viewport可能会被没有请求因而没有内容的黑色tile所覆盖。</p>
<h5 id="bans-workknnlr">Ban&rsquo;s work——KNN+LR</h5>
<p>使用KNN算法利用跨用户观看历史，使用LR模型利用户个体化的行为。</p>
<p>就视角预测的准确率而言，分别取得了20%和48%的绝对和相对改进。</p>
<h5 id="lius-workcluster">Liu&rsquo;s work——cluster</h5>
<p>提出了使用数据融合方法，通过考虑几个特征来估计未来视角位置。特征例如：用户的参与度、用户观看同一视频的行为、单个用户观看多个视频的行为、最终用户设备、移动性水平。</p>
<h5 id="petrangelis-workcluster">Petrangeli&rsquo;s work——cluster</h5>
<p>基于车辆轨迹预测的概念，考虑了类似的轨迹形成一个簇来预测未来的viewport。</p>
<p>结果表明这种方法为更长的视野提高了精确度。</p>
<p>检查了来自三个欧拉角的不同轨迹，这样做可能导致性能不足。</p>
<h5 id="rossis-workcluster">Rossi&rsquo;s work——cluster</h5>
<p>提出了一种聚类的方法，基于球形空间中有意义的viewport重叠来确认用户的簇。</p>
<p>基于Bron-Kerbosch（BK）算法的聚类算法能够识别大量用户，这些用户观看的是相同的60%的3s长球形视频块。</p>
<p>与基准相比，该方法为簇提供了可兼容且重要的几何viewport重叠。</p>
<h5 id="jiangs-work">Jiang&rsquo;s work</h5>
<p>背景：</p>
<p>LR方法对于长期的预测视野会导致较差的预测精度。长短时记忆（LSTM）是一种递归神经网络（RNN）架构，适用于序列建模和模式开发。</p>
<p>方法：</p>
<p>为了在FoV预测中获取比LR方法更高的精确度，开发了一种使用带有128个神经元的LSTM模型的viewport预测方法。</p>
<ul>
<li>分析了360度数据集，观察到用户在水平方向头部有快速转向，但是在垂直方向几乎是稳定的。</li>
<li>实验表明，这种方法同时考虑水平和垂直方向的头部移动时，比LR等方法产生了更少的预测错误。</li>
</ul>
<h5 id="baos-work">Bao&rsquo;s work</h5>
<p>背景：</p>
<p>对150个用户进行了16个视频剪辑的主观实验，并对其行为进行了分析。</p>
<p>使用3个方向的欧拉角$\theta$, $\phi$, $\psi$来表示用户在3D空间中头部的移动，结果表明不同方向的动作有强自相关性和消极的互相关性。因此多个角度的预测可以分开进行。</p>
<p>方法：</p>
<p>开发两个独立的LSTM模型来分别预测$\theta$和$\phi$，之后将预测结果应用于目标区域流来有效利用可用网络资源。</p>
<h5 id="hous-work">Hou&rsquo;s work</h5>
<ul>
<li>提出一种基于深度学习的视角产生方法来只对提前预测的360度视频和3自由度的VR应用的viewport tile进行抽取和推流。（使用了大规模的数据集来训练模型）</li>
<li>使用包含多层感知器和LSTM模型来预测6自由度的VR环境中头部乃至身体的移动，预测的视野被预渲染来做到低延迟的VR体验。</li>
</ul>
<h5 id="heyses-work">Heyse&rsquo;s work</h5>
<p>背景：</p>
<p>在某些例子中，用户的移动在视频的不同部分中非常不稳定。这增加了机器学习方式的训练压力。</p>
<p>方法：</p>
<p>提出了一个基于RL模型的上下文代理，这个模型首先检测用户的显著移动，然后预测移动的方向。这种分层自学习执行器优于球形轨迹外推法（这种方法将用户运动建模为轨迹的一部分，而不是单位球体上的完整轨迹）</p>
<h5 id="qians-work">Qian&rsquo;s work</h5>
<p>提出了一种叫做Flare的算法来最小化实际viewport和预测viewport之间的不匹配。</p>
<ul>
<li>应用了一种ML方法来执行频繁的viewport预测，包括从130名用户收集的1300条头部运动轨迹的4个间隔。</li>
<li>使用viewport轨迹预测，Flare可以将错误预测替换成最新预测。</li>
</ul>
<h5 id="yu-and-lius-work">Yu and Liu&rsquo;s work</h5>
<p>背景：</p>
<p>LSTM网络本身具有耗时的线性训练特性。编解码器的LSTM模型把训练过程并行化，相比于LR和LSTM本身而言，改善了预测精度。</p>
<p>方法：</p>
<p>使用基于注意力的LSTM编解码器网络体系结构来避免昂贵的递归并能更好地捕获viewport变化。</p>
<ul>
<li>提出的体系结构相比于传统的RNN，获得了更高的预测精度，更低的训练复杂度和更快的收敛。</li>
</ul>
<h5 id="jamalis-work">Jamali&rsquo;s work</h5>
<p>提出使用LSTM编解码器网络来做长期的viewport预测（例如3.5s）。</p>
<p>收集了低延迟异质网络上跨用户的方向反馈来调整高延迟网络上目标用户的预测性能。</p>
<h3 id="内容感知方式">内容感知方式</h3>
<h4 id="背景-2">背景</h4>
<p>内容感知方式可以提高预测效率。</p>
<h4 id="具体方法">具体方法</h4>
<h5 id="aladaglis-work">Aladagli&rsquo;s work</h5>
<p>提出了一个显著性驱动的模型来提高预测精度。</p>
<ul>
<li>没有考虑用户在360度视频中的视角行为。</li>
<li>viewport预测错误可以通过理解用户对360度视频独特的可见注意力最小化。</li>
</ul>
<h5 id="nguyens-work">Nguyen&rsquo;s work</h5>
<p>背景：</p>
<p>大多数现存的方法把显著性图看作是360度显示中的位置信息来获得更好的预测结果。</p>
<p>通用的显著性和位置信息体系结构基于固定预测模型。</p>
<p>方法：</p>
<p>提出了<code>PanoSalNet</code>来捕获用户在360度帧中独特的可见注意力来改善显著性检测的性能。</p>
<ul>
<li>同时使用HMD特性和显著性图的固定预测模型获得了可测量的结果。</li>
</ul>
<h5 id="xus-work">Xu&rsquo;s work</h5>
<p>提出了两个DRL(Deep Reinforcement Learning)模型用于同时考虑运动轨迹和可见注意力特性的viewport预测网络。</p>
<ul>
<li>离线模型基于内容流行度检测每个帧里的显著性。</li>
<li>在线模型基于从离线模型获得的显著性图和之前的viewport预测信息预测viewport方向和大小。</li>
<li>这个网络只能预测30ms的下一个viewport位置。</li>
</ul>
<h5 id="xus-work-1">Xu&rsquo;s work</h5>
<p>收集了大规模的被使用带有眼部轨迹跟踪的HMD的45个观测者观察的动态360度视频数据集，提出了基于历史扫描路径和图像特征预测注视位移的方法。</p>
<ul>
<li>在与当前注视点、viewport和整个图像相关的三个空间尺度上执行了显著性计算。</li>
<li>可能的图像特性被通过向CNN喂图像和相应的显著性图，同时LSTM模型捕获历史信息来抽取出来。</li>
<li>之后将LSTM和CNN特性耦合起来，用于下一次的用户注视信息预测。</li>
</ul>
<h5 id="fans-work">Fan&rsquo;s work</h5>
<p>用户更容易被运动的物体吸引，因此除了显著性图之外，Fan等人也考虑了使用预训练  的CNN来估计用户未来注视点的内容运动图。</p>
<ul>
<li>由于可能存在多个运动，这让预测变得不可靠，因此运动贴图的开发还需要进一步的研究。</li>
</ul>
<h5 id="yangs-work">Yang&rsquo;s work</h5>
<ul>
<li>使用CNN模型基于历史观测角度信息预测了单viewport。</li>
<li>接着考虑了一种使用内容不可知和内容感知方法如RNN和CFVT模型的融合层的viewport轨迹预测策略。</li>
<li>融合模型使其同时支持更好地预测并且提高了大概40%的精度。</li>
</ul>
<h5 id="ozcinars-work">Ozcinar&rsquo;s work</h5>
<p>将viewport轨迹转换为基于viewport的视觉注意图，然后对不同大小的tile进行推流以保证更高的编码效率。</p>
<h5 id="lis-work">Li&rsquo;s work</h5>
<p>现有的预测模型对未来的预测能力有限，Li等人提出了两种模型，分别用于viewport相关和基于tile的推流系统。</p>
<ul>
<li>第一个模型应用了基于用户轨迹的LSTM编解码网络体系结构。</li>
<li>第二个模型应用了卷积LSTM编解码体系结构，使用序列的热图来预测用户的未来方向。</li>
</ul>
<h3 id="总结">总结</h3>
<p>精确的方向预测使360度视频的客户端可以以高分辨率下载最相关的tile。</p>
<p>当前采用显著性和位置信息的神经网络模型的性能比直接利用当前观察位置进行未来viewport位置估计的简单无运动的基线方法表现差。估计的显著性中的噪音等级限制了这些模型的预测精度。并且这些模型也引入了额外的计算复杂度。</p>
<p>对于360度视频注意点的可靠预测和用户观看可能性与显著性图之间关系的理解，显著性模型必须被改善并通过训练大规模的数据集来适应，尤其是被配备了不同摄像机旋转的镜头所捕获的数据。</p>
<p>另一方面，卷积LSTM编解码器和基于轨迹的预测方法适合长期预测，并能带来相当大的QoE改进，特别是在协作流媒体环境中。</p>
<h2 id="qoe评估">QoE评估</h2>
<h3 id="背景-3">背景</h3>
<p>由于全方位视频非常普遍，因此，通过这种类型的视频分发来确定用户的特定质量方面是至关重要的。QoE在视频推流应用中扮演着重要角色。在传统视频推流中，QoE很大程度上被网络负载和分发性能所影响。现有的次优目标度量方法并不适用于全向视频，因为全向视频受网络状况和用户视角行为的影响很大。</p>
<h3 id="主观质量评估">主观质量评估</h3>
<p>主观质量评估是估计360度视频推流质量的现实并且可靠的方法。</p>
<h4 id="upeniks-work">Upenik&rsquo;s work</h4>
<p>用一台MergeVR HMD执行了主观测试来体验360度图像。</p>
<ul>
<li>实验数据包括主观分数、视角轨迹、在每个图像上花费的时间由软件上获得。</li>
<li>视角方向信息被用于计算显著性图。</li>
<li>但是这项研究没有考虑对360度视频的评估。</li>
</ul>
<h4 id="zhangs-work">Zhang&rsquo;s work</h4>
<p>为了弥补360度视频和常规视频度量方式之间的性能差距，为全景视频提出了一种主观质量评估方法，称为<em>SAMPVIQ</em>。</p>
<ul>
<li>23位参与者被允许观看4个受损视频，整体视频质量体验的评分在0～5分之间。</li>
<li>参与者之间存在较大的评分差异。</li>
</ul>
<h4 id="xus-work-2">Xu&rsquo;s work</h4>
<p>提出两种主观测量方式：总体区分平均意见分数(O-DMOS)和矢量区分平均意见分数(V-DMOS)来获得360度视频的质量损失。</p>
<ul>
<li>类似于传统食品的DMOS度量方式，O-DMOS度量方式计算主观测试序列的总计区分分数。</li>
</ul>
<h4 id="schatzs-work">Schatz&rsquo;s work</h4>
<p>研究了使用HMD观看360度内容时停顿事件的影响。</p>
<ul>
<li>沉浸式内容的主观质量评估并非不重要，可能导致比实际推荐更多的开放性问题。</li>
<li>通常来讲人们的期望于传统的HAS相似，即如果可能的话，根本没有停顿。</li>
</ul>
<h4 id="可用的开源工具">可用的开源工具</h4>
<p>AVTrack360，OpenTrack和360player能捕获用户观看360度视频的头部轨迹。</p>
<p>VRate是一个在VR环境中提供主观问卷调查的基于Unity的工具。</p>
<p>安卓应用*<a href="https://github.com/zerepolbap/miro360" target="_blank" rel="noopener noreffer">MIRO360</a>*，支持未来VR主观测试的指南开发。</p>
<h4 id="cybersickness"><code>Cybersickness</code></h4>
<p><code>Cybersickness</code>是一种获得高QoE的潜在障碍，它能引起疲劳、恶心、不适和呕吐。</p>
<h5 id="singlas-work">Singla&rsquo;s work</h5>
<p>使用受限的带宽和分辨率，在不同的延迟情况下进行了两个主观实验。</p>
<ul>
<li>开发了主观测试平台、测试方法和指标来评估viewport自适应360度视频推流中的视频感知等级和<code>Cybersickness</code>。</li>
<li>基于tile的推流在带宽受限的情况下表现很好。</li>
<li>47ms的延迟实际上不影响感知质量。</li>
</ul>
<h5 id="trans-work">Tran&rsquo;s work</h5>
<p>考虑了几个影响因子例如内容的空间复杂性，数量参数，分辨率特性和渲染模型来评估cybersickness，质量，可用性和用户的存在。</p>
<ul>
<li>VR环境中快速移动的内容很容易引发cybersickness。</li>
<li>由于高可用性和存在性，用户的cybersickness也可能加剧。</li>
</ul>
<h5 id="singlas-work-1">Singla&rsquo;s work</h5>
<p>评估了28名受试者在Oculus Rift和HTC Vive头戴式电脑上观看6个全高清和超高清分辨率YouTube视频时的观看不适感。</p>
<ul>
<li>HMD的类型轻微地影响感知质量。</li>
<li>分辨率和内容类型强烈影响个人体验。</li>
<li>女性用户感到<code>cybersickness</code>的人数更多。</li>
</ul>
<h4 id="空间存在感">空间存在感</h4>
<p>空间存在感能增强沉浸感。</p>
<h5 id="zous-work">Zou&rsquo;s work</h5>
<p>方法：</p>
<p>提出了一个主观框架来测量25名受试者的空间存在感。</p>
<ul>
<li>提出的框架包括三层，从上到下分别为：空间存在层、感知层、科技影响层。</li>
<li>心理上的空间存在感形成了空间存在层。</li>
<li>感知层以视频真实感、音频真实感和交互元素为特征。</li>
<li>科技影响层由几个模块组成，这些模块与感知层相连，以反映传感器的真实性。</li>
</ul>
<h5 id="huponts-work">Hupont&rsquo;s work</h5>
<p>应用通用感知的原则来研究在Oculus HMD和传统2D显示器上玩游戏的用户的空间存在感。</p>
<ul>
<li>与2D显示器相比，3D虚拟现实主义显示出更高的惊奇、沉浸感、存在感、可用性和兴奋感。</li>
</ul>
<h4 id="生理特征度量">生理特征度量</h4>
<h5 id="salgados-work">Salgado&rsquo;s work</h5>
<p>方法：</p>
<p>捕获多种多样的生理度量，例如心率HR，皮肤电活性EDA、皮肤温度、心电图信号ECG、呼吸速率、血压BVP、脑电图信号EEG来评价沉浸式模拟器的质量。</p>
<h5 id="egans-work">Egan&rsquo;s work</h5>
<p>基于HR和EDA信号评估VR和非VR渲染模式质量分数。</p>
<ul>
<li>相比于HR，EDA对质量分数有强烈的影响。</li>
</ul>
<h4 id="技术因素感知">技术因素感知</h4>
<p>不同的技术和感知特征，如失真、清晰度、色彩、对比度、闪烁等，用于评估感知视频质量。</p>
<h5 id="fremereys-work">Fremerey&rsquo;s work</h5>
<p>确定了可视质量强烈地依赖于应用的运动插值（MI）算法和视频特征，例如相机旋转和物体的运动。</p>
<p>在一项主观实验中，12位视频专家回顾了使用FFmpeg混合、FFmpeg MCI（运动补偿插值）和butterflow插值到90 fps的四个视频序列。作者发现，与其他算法相比，MCI在QoE方面提供了极好的改进。</p>
<h4 id="总结-1">总结</h4>
<p>主观测试与人眼直接相关，并揭示了360度视频质量评估的不同方面的影响。</p>
<p>在这些方面中，空间存在感和由佩戴VR头戴设备观看360度视频导致的<em>cybersickness</em>极为重要，因为这些效果并不在传统的2D视频观看中出现。</p>
<p>主观评估需要综合的手工努力并因此昂贵耗时并易于出错，相对而言，客观评估更易于管理和可行。</p>
<h3 id="客观质量评估">客观质量评估</h3>
<p>由于类似的编码结构和2D平面投影格式，对360度内容应用客观质量评估很自然。</p>
<h4 id="计算psnr">计算PSNR</h4>
<p>现有投影方式中的采样密度在每个像素位置并不均匀。</p>
<h5 id="yus-work">Yu&rsquo;s work</h5>
<p>为基于球形的PSNR计算引入S-PSNR和L-PSNR。</p>
<ul>
<li>S-PSNR通过对球面上所有位置的像素点做同等加权来计算PSNR。</li>
<li>利用插值算法，S-PSNR可以完成对支持多种投影模式的360度视频的客观质量评估。</li>
<li>L-PSNR通过基于纬度和访问频率的像素点加权测量PSNR。</li>
<li>L-PSNR可以测量viewport的平均PSNR而无需特定的头部运动轨迹。</li>
</ul>
<h5 id="zakharchenkos-work">Zakharchenko&rsquo;s work</h5>
<p>提出了一种Craster Parabolic Projection-PSNR (CPP-PSNR) 度量方式来比较多种投影方案，通过不改变空间分辨率和不计算实际像素位置的PSNR，将像素重新映射成CPP投影。</p>
<ul>
<li>CPP投影方式可能使视频分辨率大幅下降。</li>
</ul>
<h5 id="suns-work">Sun&rsquo;s work</h5>
<p>提出了一种叫做weighted-to-spherically-uniform PSNR (WS-PSNR)的质量度量方式，以此来测量原始和受损内容之间的质量变化。</p>
<ul>
<li>根据像素在球面上的位置考虑权重。</li>
</ul>
<h4 id="计算ssim">计算SSIM</h4>
<p>SSIM是另一种质量评估指标，它通过三个因素反映图像失真，包括亮度、对比度和结构。</p>
<h5 id="chens-work">Chen&rsquo;s work</h5>
<p>为2D和360度视频分析了SSIM结果，引入了球型结构的相似性度量（S-SSIM）来计算原始和受损的360度视频之间的相似性。</p>
<ul>
<li>在S-SSIM中，使用重投影来计算两个提取的viewport之间的相似性。</li>
</ul>
<h5 id="zhous-work">Zhou&rsquo;s work</h5>
<p>考虑相似性的权重提出了WS-SSIM来测量投影区域中窗口的相似性。</p>
<ul>
<li>性能评估表明，与其他质量评估指标相比，WS-SSIM更接近人类感知。</li>
</ul>
<h5 id="van-der-hoofts-work">Van der Hooft&rsquo;s work</h5>
<p>提出了<em>ProbGaze</em>度量方式，基于tile的空间尺寸和viewport中的注视点。</p>
<ul>
<li>考虑外围tile的权重来提供合适的质量测量。</li>
<li>相比于基于中心和基于平均的PSNR和SSIM度量方式，<em>ProbGaze</em>能估计当用户突然改变viewport位置时的视频质量变化。</li>
</ul>
<h5 id="xus-work-3">Xu&rsquo;s work</h5>
<p>引入了两种客观质量评估度量手段：基于内容感知的PSNR和非内容感知的PSNR，用于编码360度视频。</p>
<ul>
<li>第一种方式基于空间全景内容对像素失真进行加权。</li>
<li>第二种方式考虑人类偏好的统计数据来估计质量损失。</li>
</ul>
<h4 id="基于psnr和ssim方式的改进">基于PSNR和SSIM方式的改进</h4>
<p>尽管各种基于PSNR和SSIM的方式被广阔地应用到了360度视频的质量评估中，但这些方式都没有真正地捕获到感知质量，特别是当HMD被用于观看视频时。因此需要为360度内容特别设计一种优化的质量度量方式。</p>
<h5 id="upeniks-work-1">Upenik&rsquo;s work</h5>
<p>考虑了一场使用4张高质量360度全景图像来让45名受试者在不同的编码设定下评估和比较客观质量度量方式性能的主观实验。</p>
<ul>
<li>现有的客观度量方式和主观感知到的质量相关性较低。</li>
</ul>
<h5 id="trans-work-1">Tran&rsquo;s work</h5>
<p>论证主观度量和客观度量之间相关性较高，但是使用的数据集较小。</p>
<h4 id="基于ml的方式">基于ML的方式</h4>
<p>基于ML的方式可以弥补客观评估和主观评估之间的差距。</p>
<h5 id="da-costa-filhos-work">Da Costa Filho&rsquo;s work</h5>
<p>提出了一个有两个阶段的模型。</p>
<ul>
<li>首先自适应VR视频的播放性能由机器学习算法所确定。</li>
<li>之后模型利用估计的度量手段如视频质量、质量变化、卡顿时间和启动延迟来确定用户的QoE。</li>
</ul>
<h5 id="lis-work-1">Li&rsquo;s work</h5>
<p>引入了基于DRL的质量获取模型，在一次推流会话中同时考虑头部和眼部的移动。</p>
<ul>
<li>360度视频被分割成几个补丁。</li>
<li>低观看概率的补丁被消除。</li>
<li>参考和受损视频序列都被输入到深度学习可执行文件中，以计算补丁的质量分数。</li>
<li>之后分数被加权并加到一起得到最终的分数。</li>
</ul>
<h5 id="yangs-work-1">Yang&rsquo;s work</h5>
<p>考虑了多质量等级的特性和融合模型。</p>
<ul>
<li>质量特性用<code>region of interest(ROI)</code>图来计算，其中包括像素点等级、区域等级、对象等级和赤道偏差。</li>
<li>混合模型由后向传播的神经网络构造而成，这个神经网络组合了多种质量特性来获取整体的质量评分。</li>
</ul>
<h3 id="总结-2">总结</h3>
<p>精确的QoE获取是优化360度视频推流服务中重要的因素，也是自适应分发方案中基础的一环。</p>
<p>单独考虑VR中的可视质量对完整的QoE框架而言并不足够。</p>
<p>为能获得学界的认可，找到其他因素的影响也很必要，例如<code>cybersickness</code>，生理症状，用户的不适感，HMD的重量和可用性，VR音频，viewport降级率，网络特性（延迟，抖动，带宽等），内容特性（相机动作，帧率，编码，投影等），推流特性（viewport偏差，播放缓冲区，时空质量变化等）。</p>
<h2 id="低延迟推流">低延迟推流</h2>
<h3 id="背景-4">背景</h3>
<p>360度全景视频推流过程中的延迟由几部分组成：传感器延迟、云/边处理延迟、网络延迟、请求开销、缓冲延迟、渲染延迟和反馈延迟。</p>
<p>低延迟的要求对于云VR游戏、沉浸式临场感和视频会议等更为严格。</p>
<p>要求极低的终端处理延迟、快速的云/边计算和极低的网络延迟来确保对用户头部移动做出反馈。</p>
<p>现代HMD可以做到使传感器延迟降低到用户无法感知的程度。</p>
<p>传输延迟已经由5G移动和无线通信技术大幅减少。</p>
<p>但是，对于减少处理、缓冲和渲染延迟的工作也是必要的。</p>
<p>许多沉浸式应用的目标是MTP的延迟少于20ms，理想情况是小于15ms。</p>
<h3 id="减少启动时间">减少启动时间</h3>
<h4 id="减少初始化请求的数据量">减少初始化请求的数据量</h4>
<p>通常来讲，较小的视频segment能减少启动和下载时间。</p>
<h5 id="van-der-hoofts-work-1">Van der Hooft&rsquo;s work</h5>
<p>考虑了新闻相关内容的推流，使用的技术有：</p>
<ol>
<li>服务端编码</li>
<li>服务端的用户分析</li>
<li>服务器推送策略</li>
<li>客户端积极存储视频数据</li>
</ol>
<p>取得的效果：</p>
<ul>
<li>降低了启动时间</li>
<li>允许不同网络设定下的快速内容切换</li>
<li>较长的响应时间降低了性能</li>
</ul>
<h5 id="nguyens-work-1">Nguyen&rsquo;s work</h5>
<p>基于viewport依赖的自适应策略分析了自适应间隔延迟和缓冲延迟的影响。</p>
<ul>
<li>使用服务端比特率计算策略来最小化响应延迟的影响。</li>
<li>根据客户端的响应估计可用的网络吞吐量和未来的viewport位置。</li>
<li>服务端的决策引擎推流合适的tile来满足延迟限制。</li>
</ul>
<p>取得的效果：</p>
<ul>
<li>对于viewport依赖型推流方案而言，较少的自适应和缓冲延迟不可避免。</li>
</ul>
<h3 id="降低由tile分块带来的网络负载">降低由tile分块带来的网络负载</h3>
<p>在HTTP/1.1中，在空间上将视频帧分成矩形tile会增加网络负载，因为每个tile会产生独立的网络请求。</p>
<p>请求爆炸的问题导致了较长的响应延迟，但是可以通过使用HTTP/2的服务器推送特性解决。这个特型使服务器能使用一条HTTP请求复用多条消息。</p>
<h5 id="weis-work">Wei&rsquo;s work</h5>
<p>利用HTTP/2协议来促进低延迟的HTTP自适应推流。</p>
<ul>
<li>提出的服务端推送的策略使用一条请求同时发送几个segment避免多个GET请求。</li>
</ul>
<h5 id="petrangelis-work">Petrangeli&rsquo;s work</h5>
<p>结合特定请求参数与HTTP/2的服务端推送特性来促进360度视频推流。</p>
<ul>
<li>客户端为一个segment发送一条call，服务器使用FCFS策略传送k个tile。</li>
<li>利用HTTP/2的优先级特性可以使高优先级的tile以紧急的优先级被获取，进而改善网络环境中的高往返时间的性能。</li>
</ul>
<h5 id="xus-work-4">Xu&rsquo;s work</h5>
<p>为360度内容采用了<code>k-push</code>策略：将k个tile推送到客户端，组成一个单独的时间段。</p>
<ul>
<li>提出的方法与QoE感知的比特率自适应算法一起，在不同的RTT设定下，提高了20%的视频质量，减少了30%的网络传输延迟。</li>
</ul>
<h5 id="yahias-work">Yahia&rsquo;s work</h5>
<p>使用HTTP/2的优先级和多路复用功能，在两个连续的viewport预测之间，即在交付相同片段之前和期间，组织紧急视频块的受控自适应传输。</p>
<h5 id="yens-work">Yen&rsquo;s work</h5>
<p>开发了一种支持QUIC的体系结构来利用流优先级和多路复用的特性来实现360度视频的安全和低优先级的传输。</p>
<ul>
<li>当viewport变化发生时，QUIC能让常规的tile以低优先级推流，viewport内的tile以高优先级推流，都通过一条QUIC连接来降低viewport tile的缺失率。</li>
<li>作者说测试表明基于QUIC的自适应360度推流比HTTP/1.1和HTTP/2的方案表现更好。</li>
</ul>
<h3 id="使用移动边缘计算降低延迟">使用移动边缘计算降低延迟</h3>
<h5 id="mangiantes-work">Mangiante&rsquo;s work</h5>
<p>提出了利用基于边缘处理的viewport渲染方案来减少延迟，同时利用终端设备上的电源和计算负载。</p>
<ul>
<li>但是作者没有给出有效的算法或是建立一个实践执行平台。</li>
</ul>
<h5 id="lius-work">Liu&rsquo;s work</h5>
<p>采用远端渲染技术，通过为不受约束的VR系统获取高刷新率来隐藏网络延迟。</p>
<ul>
<li>采用60GHz的无线链路支持的高端GPU，来加快计算速度和4K渲染，减少显示延迟。</li>
<li>尽管提供了高质量和低延迟的推流，但是使用了昂贵的带宽连接，这通常并不能获得。</li>
</ul>
<h5 id="viitanens-work">Viitanen&rsquo;s work</h5>
<p>引入了端到端的VR游戏系统。通过执行边缘渲染来降低延迟，能源和计算开销。</p>
<ul>
<li>为1080p 30fps的视频格式实现了端到端的低延迟（30ms）的系统。</li>
<li>前提是有充足的带宽资源、终端设备需要性能强劲的游戏本。</li>
</ul>
<h5 id="shis-work">Shi&rsquo;s work</h5>
<p>考虑了不重视viewport预测的高质量360度视频渲染。</p>
<ul>
<li>提出的MEC-VR系统采用了一个远端服务器通过使用一个自适应裁剪过滤器来动态适应viewport覆盖率，这个过滤器按照观测到的系统延迟增加viewport之外的区域。</li>
<li>基于viewport覆盖率的延迟调整允许客户端容纳和补偿突然的头部移动。</li>
</ul>
<h3 id="共享vr环境中的延迟处理">共享VR环境中的延迟处理</h3>
<p>共享VR环境中用户的延迟取决于用户的位置和边缘资源的分发。</p>
<h5 id="parks-work">Park&rsquo;s work</h5>
<p>通过考虑多个用户和边缘服务器之间的双向通信，提出了一种使用线性蜂窝拓扑中的带宽分配策略，以最小化端到端系统延迟。确定了推流延迟强烈地依赖于：</p>
<ul>
<li>边缘服务器的处理性能</li>
<li>多个交互用户之间的物理和虚拟空间</li>
</ul>
<h5 id="perfectos-work">Perfecto&rsquo;s work</h5>
<p>集成了深度神经网络和毫米波多播传输技术来降低协同VR环境中的延迟。</p>
<ul>
<li>神经网络模型估计了用户即将来临的viewport。</li>
<li>用户被基于预测的相关性和位置分组，以此来优化正确的viewport许可。</li>
<li>执行积极的多播资源调度来最小化延迟和拥塞。</li>
</ul>
<h3 id="总结-3">总结</h3>
<p>在单用户和多用户的环境中，边缘辅助的解决方式对于控制延迟而言占主要地位。</p>
<p>此外还有服务端的viewport计算、服务端push机制和远程渲染机制都能用于低延迟的控制。</p>
<p>现有的4G网络足以支持早期的自适应沉浸式多媒体，正在成长的5G网络更能满足沉浸式内容的需求。</p>
<h2 id="360度直播推流">360度直播推流</h2>
<h3 id="背景-5">背景</h3>
<p>传统的广播电视频道是直播推流的流行来源。现在私人的360度直播视频在各个社交媒体上也有大幅增长。</p>
<p>因为视频生产者和消费者之间在云端的转码操作，360度视频推流是更为延迟敏感的应用。</p>
<p>现有的处理设备在诸如转码、渲染等实时处理任务上受到了限制。</p>
<h4 id="内容分发">内容分发</h4>
<h5 id="hus-work">Hu&rsquo;s work</h5>
<p>提出了一套基于云端的直播推流系统，叫做<code>MELiveOV</code>，它使高分辨率的全向内容的处理任务以毛细管分布的方式分发到多个支持5G的云端服务器。</p>
<ul>
<li>端到端的直播推流系统包括内容创作模块、传输模块和viewport预测模块。</li>
<li>移动边缘辅助的推流设计减少了50%的带宽需求。</li>
</ul>
<h5 id="griwodzs-work">Griwodz&rsquo;s work</h5>
<p>为360度直播推流开发了优化FoV的原型，结合了RTP和基于DASH的<code>pull-patching</code>来传送两种质量等级的360度视频给华为IPTV机顶盒和Gear VR头戴设备。</p>
<ul>
<li>作者通过在单个H.265硬件解码器上多路复用多个解码器来实现集体解码器的想法，以此减少切换时间。</li>
</ul>
<h4 id="视频转码">视频转码</h4>
<h5 id="lius-work-1">Liu&rsquo;s work</h5>
<p>研究表明只转码viewport区域有潜力大幅减少高性能转码的计算需求。</p>
<h5 id="baigs-work">Baig&rsquo;s work</h5>
<p>开发了快速编码方案来分发直播的4K视频到消费端设备。</p>
<ul>
<li>采用了分层视频编码的方式来在高度动态且不可预测的WiGig和WiFi链路上分发质量可变的块。</li>
</ul>
<h5 id="les-work">Le&rsquo;s work</h5>
<p>使用RTSP网络控制协议为CCTV的360度直播推流提出了实时转码和加密系统。</p>
<ul>
<li>转码方式基于ARIA加密库，Intel媒体SDK和FFmpeg库。</li>
<li>系统可以管理并行的转码操作，实现高速的转码性能。</li>
</ul>
<h4 id="内容拼接缝合">内容拼接缝合</h4>
<p>相比于其他因素如捕获、转码、解码、渲染，内容拼接在决定整体上的推流质量时扮演至关重要的角色。</p>
<h5 id="chens-work-1">Chen&rsquo;s work</h5>
<p>提出了一种内容驱动的拼接方式，这种方式将360度帧的语义信息的不同类型看作事件，以此来优化拼接时间预算。</p>
<ul>
<li>基于VR帧中的语义信息，tile执行器模块选择合适的tile设计。</li>
<li>拼接器模块然后执行基于tile的拼接，这样，基于可用资源，事件tile有更高的拼接质量。</li>
<li>评估表明系统通过实现89.4%的时间预算，很好地适应了不同的事件和时间限制。</li>
</ul>
<h3 id="总结-4">总结</h3>
<p>相比于点播式流媒体，360度直播推流面临多个挑战，例如在事先不知情的情况下处理用户导航、视频的首次流式传输以及实时视频的转码。在多用户场景中，这些挑战更为棘手。</p>
<p>关于处理多个用户的观看模式，可伸缩的多播可以用于在低带宽和高带宽网络上以接近于按需推流的质量等级。</p>
<p>基于ROI的tile拼接和转码可以显著地减少延迟敏感的交互型应用的延迟需求。</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info"><div class="post-info-tag"><span><a href="/tags/immersive-video/">Immersive-Video</a>
                </span></div><div class="post-info-line"><div class="post-info-mod">
                <span>更新于 2023-06-01</span>
            </div><div class="post-info-mod"><span>
                            <a class="link-to-markdown" href="/posts/papers/note5/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
        </div></div><div class="post-nav"><a href="/posts/papers/note4/" class="prev" rel="prev" title="沉浸式流媒体网络问题的相关解决方案"><i class="fas fa-angle-left fa-fw"></i>Previous Post</a>
            <a href="/posts/papers/note6/" class="next" rel="next" title="沉浸式流媒体现有标准">Next Post<i class="fas fa-angle-right fa-fw"></i></a></div></div>
</div></article></div>
            </main>
            <footer class="footer"><div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.111.3">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/khusika/FeelIt" target="_blank" rel="noopener noreffer" title="FeelIt 1.0.1"><i class="fas fa-hand-holding-heart fa-fw"></i> FeelIt</a>
        </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/ayamir">Ayamir</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
</div>
<script>
if ('serviceWorker' in navigator) {
    navigator.serviceWorker
        .register('/sw.min.js?version=0.0.1', { scope: '/' })
        .then(() => {
            console.info('Ayamir\u0027s Blog\u00A0Service Worker Registered');
        }, err => console.error('Ayamir\u0027s Blog\u00A0Service Worker registration failed: ', err));

    navigator.serviceWorker
        .ready
        .then(() => {
            console.info('Ayamir\u0027s Blog\u00A0Service Worker Ready');
        });
}
</script>
</footer>
        </div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-chevron-up fa-fw"></i>
            </a></div><link rel="stylesheet" href="/lib/fontawesome-free/all.min.b5e38de32d149f2263d86a25f0db6e63418e296f5c42f004f1ad157b5062db96.css" integrity="sha256-teON4y0UnyJj2Gol8NtuY0GOKW9cQvAE8a0Ve1Bi25Y="><link rel="stylesheet" href="/lib/animate/animate.min.1c3d8cfdde90f444127299b299594deb40f4663766535f6e21a57ddab4deabf5.css" integrity="sha256-HD2M/d6Q9EQScpmymVlN60D0ZjdmU19uIaV92rTeq/U="><link rel="stylesheet" href="/lib/katex/katex.min.961fd3a6a9b9bf63773097865329ea8d4053802a545f3757d766b2d63b276b72.css" integrity="sha256-lh/Tpqm5v2N3MJeGUynqjUBTgCpUXzdX12ay1jsna3I="><link rel="stylesheet" href="/lib/katex/copy-tex.min.597e9b6c995ec97dc1115467003ff273cfc0eb7d2844feaa06d368d99266adc7.css" integrity="sha256-WX6bbJleyX3BEVRnAD/yc8/A630oRP6qBtNo2ZJmrcc="><script src="https://polyfill.io/v3/polyfill.min.js?features=Array.prototype.fill%2CArray.prototype.find%2CArray.from%2CIntersectionObserver%2CMath.sign%2CObject.assign%2CPromise%2CObject.entries%2Chtml5shiv%2CObject.values%2Cfetch%2CElement.prototype.after"></script><script src="/lib/autocomplete/autocomplete.min.e33e378e11ac24cc3c9ee40d7a6df29c2afeec212336868310abc241a9f53008.js" integrity="sha256-4z43jhGsJMw8nuQNem3ynCr&#43;7CEjNoaDEKvCQan1MAg="></script><script src="/lib/algoliasearch/algoliasearch-lite.umd.min.8b87104129ecaa804dcef8773ac3319726cb192e237034cd01858ff15740c4d6.js" integrity="sha256-i4cQQSnsqoBNzvh3OsMxlybLGS4jcDTNAYWP8VdAxNY="></script><script src="/lib/lazysizes/lazysizes.min.50255c73893719f94881b9d5cbc204a922d84f9765765b91718268c90212537c.js" integrity="sha256-UCVcc4k3GflIgbnVy8IEqSLYT5dldluRcYJoyQISU3w="></script><script src="/lib/clipboard/clipboard.min.cf20e21aa9022c1b958f2724f3849edd8002638cbd6e883759a8b9edabbc0100.js" integrity="sha256-zyDiGqkCLBuVjyck84Se3YACY4y9bog3Wai57au8AQA="></script><script src="/lib/katex/katex.min.a9525e779e5807afad67d2f3274c5565302b70cc365d7c6315e791204526c0e9.js" integrity="sha256-qVJed55YB6&#43;tZ9LzJ0xVZTArcMw2XXxjFeeRIEUmwOk="></script><script src="/lib/katex/auto-render.min.1b9ddb6192ce6db4cb4c0de3ef4c5118f2b12989416f3bc367bf3d07ab121641.js" integrity="sha256-G53bYZLObbTLTA3j70xRGPKxKYlBbzvDZ789B6sSFkE="></script><script src="/lib/katex/copy-tex.min.7ad4aa6d2545e3e2f07bc30693f55a9dcd6c47e996bfea8e1bbddfc56c3da7de.js" integrity="sha256-etSqbSVF4&#43;Lwe8MGk/Vanc1sR&#43;mWv&#43;qOG73fxWw9p94="></script><script src="/lib/katex/mhchem.min.add54727de824e382d0922469c067386bbc13a494c07d8cdd41ea8ca0e49f2e5.js" integrity="sha256-rdVHJ96CTjgtCSJGnAZzhrvBOklMB9jN1B6oyg5J8uU="></script><script src="/sw.min.39a97596903cc57488c5bee6fde4825489cd0faf1c3a8ca3520f3616b0be4a44.js" integrity="sha256-Oal1lpA8xXSIxb7m/eSCVInND68cOoyjUg82FrC&#43;SkQ="></script><script>window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"ZO1JYZIF7J","algoliaIndex":"ayamir_io","algoliaSearchKey":"2d94be64af0985c7d1980d1ed75ee698","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script src="/js/theme.min.904025b078f2ab8ff417a039c698b64e0484569262eb0830aaa52a18b479a5d9.js" integrity="sha256-kEAlsHjyq4/0F6A5xpi2TgSEVpJi6wgwqqUqGLR5pdk="></script></body></html>
