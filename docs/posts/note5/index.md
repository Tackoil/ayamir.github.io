# 自适应360度视频推流挑战


# 背景

用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。

沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的消极影响。

目前主要面临的挑战有以下4个：

![image-20211104111113514](https://i.loli.net/2021/11/04/BOIuq9Ws7obHS3i.png)

## Viewport预测

### 背景

HMD的本质特征是快速响应用户头部的移动。当用户改变viewport时HMD处理交互并检测相关的viewport来精确播放器的信息，这样视野就能以正常的可视角度被提供给用户。Viewport预测在优化的360度视频推流中非常必要。配备有位置传感器的可穿戴HMD允许客户端更新其视角方向相应的视角场景。

### 分类

+ *内容不可知*的方式基于历史信息对viewport进行预测。
+ *内容感知*的方式需要视频内容信息来预测未来的viewport。

### 内容不可知方式

#### 分类

+ 平均线性回归LR
+ 航位推算DR
+ 聚类
+ 机器学习ML
+ 编解码器体系结构

#### 现有成果

##### Qian's work——LR

使用平均线性回归和加权线性回归模型来做viewport预测，之后对与预测区域重叠的tile进行整体推流。

+ 当预测后0.5s、1s、2s加权线性回归表现更好

##### Petrangeli's work——LR

将被划分成tile的等矩形的帧分成3个区域：viewport区、相邻区、其他区。

结合观察者头部的移动，将可变比特率分配给可见和不可见区域。

作者利用最近（100毫秒）用户观看历史的线性外推来预测未来的注视点。

##### Mavlankar and Girod's work——运动向量

使用运动向量比如观察者的平移、倾斜、缩放等方向上的速度和加速度，来执行视角区域预测。

##### La Fuente's work——运动向量

考虑了两种预测变体：角速度和角加速度，从用户以前的方向数据来估计未来的头部方向。按照预测结果分配不同的量化参数到每个tile上。

当进行进一步的预测时（超过2s），这种方式限制了预测的精度。

如果视频tile被基于错误的预测而被请求，用户的实际viewport可能会被没有请求因而没有内容的黑色tile所覆盖。

##### Ban's work——KNN+LR

使用KNN算法利用跨用户观看历史，使用LR模型利用户个体化的行为。

就视角预测的准确率而言，分别取得了20%和48%的绝对和相对改进。

##### Liu's work——cluster

提出了使用数据融合方法，通过考虑几个特征来估计未来视角位置。特征例如：用户的参与度、用户观看同一视频的行为、单个用户观看多个视频的行为、最终用户设备、移动性水平。

##### Petrangeli's work——cluster

基于车辆轨迹预测的概念，考虑了类似的轨迹形成一个簇来预测未来的viewport。

结果表明这种方法为更长的视野提高了精确度。

检查了来自三个欧拉角的不同轨迹，这样做可能导致性能不足。

##### Rossi's work——cluster

提出了一种聚类的方法，基于球形空间中有意义的viewport重叠来确认用户的簇。

基于Bron-Kerbosch（BK）算法的聚类算法能够识别大量用户，这些用户观看的是相同的60%的3s长球形视频块。

与基准相比，该方法为簇提供了可兼容且重要的几何viewport重叠。

##### Jiang's work

背景：

LR方法对于长期的预测视野会导致较差的预测精度。长短时记忆（LSTM）是一种递归神经网络（RNN）架构，适用于序列建模和模式开发。

方法：

为了在FoV预测中获取比LR方法更高的精确度，开发了一种使用带有128个神经元的LSTM模型的viewport预测方法。

+ 分析了360度数据集，观察到用户在水平方向头部有快速转向，但是在垂直方向几乎是稳定的。
+ 实验表明，这种方法同时考虑水平和垂直方向的头部移动时，比LR等方法产生了更少的预测错误。

##### Bao's work

背景：

对150个用户进行了16个视频剪辑的主观实验，并对其行为进行了分析。

使用3个方向的欧拉角$\theta$, $\phi$, $\psi$来表示用户在3D空间中头部的移动，结果表明不同方向的动作有强自相关性和消极的互相关性。因此多个角度的预测可以分开进行。

方法：

开发两个独立的LSTM模型来分别预测$\theta$和$\phi$，之后将预测结果应用于目标区域流来有效利用可用网络资源。

##### Hou's work

+ 提出一种基于深度学习的视角产生方法来只对提前预测的360度视频和3自由度的VR应用的viewport tile进行抽取和推流。（使用了大规模的数据集来训练模型）
+ 使用包含多层感知器和LSTM模型来预测6自由度的VR环境中头部乃至身体的移动，预测的视野被预渲染来做到低延迟的VR体验。

##### Heyse's work

背景：

在某些例子中，用户的移动在视频的不同部分中非常不稳定。这增加了机器学习方式的训练压力。

方法：

提出了一个基于RL模型的上下文代理，这个模型首先检测用户的显著移动，然后预测移动的方向。这种分层自学习执行器优于球形轨迹外推法（这种方法将用户运动建模为轨迹的一部分，而不是单位球体上的完整轨迹）

##### Qian's work

提出了一种叫做Flare的算法来最小化实际viewport和预测viewport之间的不匹配。

+ 应用了一种ML方法来执行频繁的viewport预测，包括从130名用户收集的1300条头部运动轨迹的4个间隔。
+ 使用viewport轨迹预测，Flare可以将错误预测替换成最新预测。

##### Yu and Liu's work

背景：

LSTM网络本身具有耗时的线性训练特性。编解码器的LSTM模型把训练过程并行化，相比于LR和LSTM本身而言，改善了预测精度。

方法：

使用基于注意力的LSTM编解码器网络体系结构来避免昂贵的递归并能更好地捕获viewport变化。

+ 提出的体系结构相比于传统的RNN，获得了更高的预测精度，更低的训练复杂度和更快的收敛。

##### Jamali's work

提出使用LSTM编解码器网络来做长期的viewport预测（例如3.5s）。

收集了低延迟异质网络上跨用户的方向反馈来调整高延迟网络上目标用户的预测性能。

### 内容感知方式

#### 背景

内容感知方式可以提高预测效率。

#### 具体方法

##### Aladagli's work

提出了一个显著性驱动的模型来提高预测精度。

+ 没有考虑用户在360度视频中的视角行为。
+ viewport预测错误可以通过理解用户对360度视频独特的可见注意力最小化。

##### Nguyen's work

背景：

大多数现存的方法把显著性图看作是360度显示中的位置信息来获得更好的预测结果。

通用的显著性和位置信息体系结构基于固定预测模型。

方法：

提出了`PanoSalNet`来捕获用户在360度帧中独特的可见注意力来改善显著性检测的性能。

+ 同时使用HMD特性和显著性图的固定预测模型获得了可测量的结果。

##### Xu's work

提出了两个DRL(Deep Reinforcement Learning)模型用于同时考虑运动轨迹和可见注意力特性的viewport预测网络。

+ 离线模型基于内容流行度检测每个帧里的显著性。
+ 在线模型基于从离线模型获得的显著性图和之前的viewport预测信息预测viewport方向和大小。
+ 这个网络只能预测30ms的下一个viewport位置。

##### Xu's work

收集了大规模的被使用带有眼部轨迹跟踪的HMD的45个观测者观察的动态360度视频数据集，提出了基于历史扫描路径和图像特征预测注视位移的方法。

+ 在与当前注视点、viewport和整个图像相关的三个空间尺度上执行了显著性计算。
+ 可能的图像特性被通过向CNN喂图像和相应的显著性图，同时LSTM模型捕获历史信息来抽取出来。
+ 之后将LSTM和CNN特性耦合起来，用于下一次的用户注视信息预测。

##### Fan's work

用户更容易被运动的物体吸引，因此除了显著性图之外，Fan等人也考虑了使用预训练  的CNN来估计用户未来注视点的内容运动图。

+ 由于可能存在多个运动，这让预测变得不可靠，因此运动贴图的开发还需要进一步的研究。

##### Yang's work

+ 使用CNN模型基于历史观测角度信息预测了单viewport。
+ 接着考虑了一种使用内容不可知和内容感知方法如RNN和CFVT模型的融合层的viewport轨迹预测策略。
+ 融合模型使其同时支持更好地预测并且提高了大概40%的精度。

##### Ozcinar's work

将viewport轨迹转换为基于viewport的视觉注意图，然后对不同大小的tile进行推流以保证更高的编码效率。

##### Li's work

现有的预测模型对未来的预测能力有限，Li等人提出了两种模型，分别用于viewport相关和基于tile的推流系统。

+ 第一个模型应用了基于用户轨迹的LSTM编解码网络体系结构。
+ 第二个模型应用了卷积LSTM编解码体系结构，使用序列的热图来预测用户的未来方向。

### 总结

精确的方向预测使360度视频的客户端可以以高分辨率下载最相关的tile。

当前采用显著性和位置信息的神经网络模型的性能比直接利用当前观察位置进行未来viewport位置估计的简单无运动的基线方法表现差。估计的显著性中的噪音等级限制了这些模型的预测精度。并且这些模型也引入了额外的计算复杂度。

对于360度视频注意点的可靠预测和用户观看可能性与显著性图之间关系的理解，显著性模型必须被改善并通过训练大规模的数据集来适应，尤其是被配备了不同摄像机旋转的镜头所捕获的数据。

另一方面，卷积LSTM编解码器和基于轨迹的预测方法适合长期预测，并能带来相当大的QoE改进，特别是在协作流媒体环境中。

## QoE评估

### 背景

由于全方位视频非常普遍，因此，通过这种类型的视频分发来确定用户的特定质量方面是至关重要的。QoE在视频推流应用中扮演着重要角色。在传统视频推流中，QoE很大程度上被网络负载和分发性能所影响。现有的次优目标度量方法并不适用于全向视频，因为全向视频受网络状况和用户视角行为的影响很大。

### 主观质量评估

主观质量评估是估计360度视频推流质量的现实并且可靠的方法。

#### Upenik's work

用一台MergeVR HMD执行了主观测试来体验360度图像。

+ 实验数据包括主观分数、视角轨迹、在每个图像上花费的时间由软件上获得。
+ 视角方向信息被用于计算显著性图。
+ 但是这项研究没有考虑对360度视频的评估。

#### Zhang's work

为了弥补360度视频和常规视频度量方式之间的性能差距，为全景视频提出了一种主观质量评估方法，称为*SAMPVIQ*。

+ 23位参与者被允许观看4个受损视频，整体视频质量体验的评分在0～5分之间。
+ 参与者之间存在较大的评分差异。

#### Xu's work

提出两种主观测量方式：总体区分平均意见分数(O-DMOS)和矢量区分平均意见分数(V-DMOS)来获得360度视频的质量损失。

+ 类似于传统食品的DMOS度量方式，O-DMOS度量方式计算主观测试序列的总计区分分数。

#### Schatz's work

研究了使用HMD观看360度内容时停顿事件的影响。

+ 沉浸式内容的主观质量评估并非不重要，可能导致比实际推荐更多的开放性问题。
+ 通常来讲人们的期望于传统的HAS相似，即如果可能的话，根本没有停顿。

#### 可用的开源工具

AVTrack360，OpenTrack和360player能捕获用户观看360度视频的头部轨迹。

VRate是一个在VR环境中提供主观问卷调查的基于Unity的工具。

安卓应用*[MIRO360](https://github.com/zerepolbap/miro360)*，支持未来VR主观测试的指南开发。

#### `Cybersickness`

`Cybersickness`是一种获得高QoE的潜在障碍，它能引起疲劳、恶心、不适和呕吐。

##### Singla's work

使用受限的带宽和分辨率，在不同的延迟情况下进行了两个主观实验。

+ 开发了主观测试平台、测试方法和指标来评估viewport自适应360度视频推流中的视频感知等级和`Cybersickness`。
+ 基于tile的推流在带宽受限的情况下表现很好。
+ 47ms的延迟实际上不影响感知质量。

##### Tran's work

考虑了几个影响因子例如内容的空间复杂性，数量参数，分辨率特性和渲染模型来评估cybersickness，质量，可用性和用户的存在。

+ VR环境中快速移动的内容很容易引发cybersickness。
+ 由于高可用性和存在性，用户的cybersickness也可能加剧。

##### Singla's work

评估了28名受试者在Oculus Rift和HTC Vive头戴式电脑上观看6个全高清和超高清分辨率YouTube视频时的观看不适感。

+ HMD的类型轻微地影响感知质量。
+ 分辨率和内容类型强烈影响个人体验。
+ 女性用户感到`cybersickness`的人数更多。

#### 空间存在感

空间存在感能增强沉浸感。

##### Zou's work

方法：

提出了一个主观框架来测量25名受试者的空间存在感。

+ 提出的框架包括三层，从上到下分别为：空间存在层、感知层、科技影响层。
+ 心理上的空间存在感形成了空间存在层。
+ 感知层以视频真实感、音频真实感和交互元素为特征。
+ 科技影响层由几个模块组成，这些模块与感知层相连，以反映传感器的真实性。

##### Hupont's work

应用通用感知的原则来研究在Oculus HMD和传统2D显示器上玩游戏的用户的空间存在感。

+ 与2D显示器相比，3D虚拟现实主义显示出更高的惊奇、沉浸感、存在感、可用性和兴奋感。

#### 生理特征度量

##### Salgado's work

方法：

捕获多种多样的生理度量，例如心率HR，皮肤电活性EDA、皮肤温度、心电图信号ECG、呼吸速率、血压BVP、脑电图信号EEG来评价沉浸式模拟器的质量。

##### Egan's work

基于HR和EDA信号评估VR和非VR渲染模式质量分数。

+ 相比于HR，EDA对质量分数有强烈的影响。

#### 技术因素感知

不同的技术和感知特征，如失真、清晰度、色彩、对比度、闪烁等，用于评估感知视频质量。

##### Fremerey's work

确定了可视质量强烈地依赖于应用的运动插值（MI）算法和视频特征，例如相机旋转和物体的运动。

在一项主观实验中，12位视频专家回顾了使用FFmpeg混合、FFmpeg MCI（运动补偿插值）和butterflow插值到90 fps的四个视频序列。作者发现，与其他算法相比，MCI在QoE方面提供了极好的改进。

#### 总结

主观测试与人眼直接相关，并揭示了360度视频质量评估的不同方面的影响。

在这些方面中，空间存在感和由佩戴VR头戴设备观看360度视频导致的*cybersickness*极为重要，因为这些效果并不在传统的2D视频观看中出现。

主观评估需要综合的手工努力并因此昂贵耗时并易于出错，相对而言，客观评估更易于管理和可行。

### 客观质量评估

由于类似的编码结构和2D平面投影格式，对360度内容应用客观质量评估很自然。

#### 计算PSNR

现有投影方式中的采样密度在每个像素位置并不均匀。

##### Yu's work

为基于球形的PSNR计算引入S-PSNR和L-PSNR。

+ S-PSNR通过对球面上所有位置的像素点做同等加权来计算PSNR。
+ 利用插值算法，S-PSNR可以完成对支持多种投影模式的360度视频的客观质量评估。
+ L-PSNR通过基于纬度和访问频率的像素点加权测量PSNR。
+ L-PSNR可以测量viewport的平均PSNR而无需特定的头部运动轨迹。

##### Zakharchenko's work

提出了一种Craster Parabolic Projection-PSNR (CPP-PSNR) 度量方式来比较多种投影方案，通过不改变空间分辨率和不计算实际像素位置的PSNR，将像素重新映射成CPP投影。

+ CPP投影方式可能使视频分辨率大幅下降。

##### Sun's work

提出了一种叫做weighted-to-spherically-uniform PSNR (WS-PSNR)的质量度量方式，以此来测量原始和受损内容之间的质量变化。

+ 根据像素在球面上的位置考虑权重。

#### 计算SSIM

SSIM是另一种质量评估指标，它通过三个因素反映图像失真，包括亮度、对比度和结构。

##### Chen's work

为2D和360度视频分析了SSIM结果，引入了球型结构的相似性度量（S-SSIM）来计算原始和受损的360度视频之间的相似性。

+ 在S-SSIM中，使用重投影来计算两个提取的viewport之间的相似性。

##### Zhou's work

考虑相似性的权重提出了WS-SSIM来测量投影区域中窗口的相似性。

+ 性能评估表明，与其他质量评估指标相比，WS-SSIM更接近人类感知。

##### Van der Hooft's work

提出了*ProbGaze*度量方式，基于tile的空间尺寸和viewport中的注视点。

+ 考虑外围tile的权重来提供合适的质量测量。
+ 相比于基于中心和基于平均的PSNR和SSIM度量方式，*ProbGaze*能估计当用户突然改变viewport位置时的视频质量变化。

##### Xu's work

引入了两种客观质量评估度量手段：基于内容感知的PSNR和非内容感知的PSNR，用于编码360度视频。

+ 第一种方式基于空间全景内容对像素失真进行加权。
+ 第二种方式考虑人类偏好的统计数据来估计质量损失。

#### 基于PSNR和SSIM方式的改进

尽管各种基于PSNR和SSIM的方式被广阔地应用到了360度视频的质量评估中，但这些方式都没有真正地捕获到感知质量，特别是当HMD被用于观看视频时。因此需要为360度内容特别设计一种优化的质量度量方式。

##### Upenik's work

考虑了一场使用4张高质量360度全景图像来让45名受试者在不同的编码设定下评估和比较客观质量度量方式性能的主观实验。

+ 现有的客观度量方式和主观感知到的质量相关性较低。

##### Tran's work

论证主观度量和客观度量之间相关性较高，但是使用的数据集较小。

#### 基于ML的方式

基于ML的方式可以弥补客观评估和主观评估之间的差距。

##### Da Costa Filho's work

提出了一个有两个阶段的模型。

+ 首先自适应VR视频的播放性能由机器学习算法所确定。
+ 之后模型利用估计的度量手段如视频质量、质量变化、卡顿时间和启动延迟来确定用户的QoE。

##### Li's work

引入了基于DRL的质量获取模型，在一次推流会话中同时考虑头部和眼部的移动。

+ 360度视频被分割成几个补丁。
+ 低观看概率的补丁被消除。
+ 参考和受损视频序列都被输入到深度学习可执行文件中，以计算补丁的质量分数。
+ 之后分数被加权并加到一起得到最终的分数。

##### Yang's work

考虑了多质量等级的特性和融合模型。

+ 质量特性用`region of interest(ROI)`图来计算，其中包括像素点等级、区域等级、对象等级和赤道偏差。
+ 混合模型由后向传播的神经网络构造而成，这个神经网络组合了多种质量特性来获取整体的质量评分。

#### 总结

精确的QoE获取是优化360度视频推流服务中重要的因素，也是自适应分发方案中基础的一环。

单独考虑VR中的可视质量对完整的QoE框架而言并不足够。

为能获得学界的认可，找到其他因素的影响也很必要，例如`cybersickness`，生理症状，用户的不适感，HMD的重量和可用性，VR音频，viewport降级率，网络特性（延迟，抖动，带宽等），内容特性（相机动作，帧率，编码，投影等），推流特性（viewport偏差，播放缓冲区，时空质量变化等）。


