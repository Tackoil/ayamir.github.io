[{"categories":["Immersive Video"],"content":"论文概况 Link：QoE-driven Mobile 360 Video Streaming: Predictive View Generation and Dynamic Tile Selection Level：ICCC 2021 Keywords：QoE maximization，Trajectory-based viewport prediction，Dynamic tile selection，Differential weight on FOV tiles ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:1:0","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"系统建模与形式化 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:2:0","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"视频划分 先将视频划分成片段：$\\Iota = {1, 2, …, I}$表示片段数为$I$的片段集合。 接着将片段在空间上均匀划分成$M \\times N$个tile，FOV由被用户看到的tile所确定。 使用ERP投影，$(\\phi_i, \\theta_i),\\ \\phi_i \\in (-180\\textdegree, 180\\textdegree], \\theta_i \\in (-90\\textdegree, 90\\textdegree]$来表示用户在第$i$个片段中的视点坐标。 播放过程中记录用户头部运动的轨迹，积累的数据可以用于FOV预测。 跨用户之间的FOV轨迹可以用于提高预测精度。 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:2:1","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"QoE模型 前提 视频编解码器预先确定，无法调整每个tile的码率。 实现 每个tile都以不同的码率编码成不同的版本。 每个tile都有两种分辨率的版本。 QoE内容 客户端收到的视频质量和观看时的卡顿时间。 质量形式化 对于每个片段$i \\in \\Iota$，$S_i = {\\tau_{i, j}}_{j=1}^{M \\times N}$是用来表示用户实际看到的tile的集合的向量。 $\\tau_{i, j} = 1$表示第$i$个段中的第$j$个tile被看到；$\\tau_{i, j} = 0$表示未被看到。 同样的， $\\tilde{S}i = {\\tilde{\\tau}{i, j}}_{j = 1}^{M \\times N}$ 表示经过FOV预测和tile选择之后成功被传送到用户头戴设备上的tile集合的向量。 $\\tilde{\\tau}{i, j} = 1$表示第$i$个段中的第$j$个tile被用户接收；$\\tilde{\\tau}{i, j} = 0$表示未被接收。 第$i$个段的可感知到的质量可以表示为： $$ Q_i = \\sum_{j = 1}^{M \\times N} p_{i, j}b_{i, j}\\tau_{i, j}\\tilde{\\tau}{i, j} $$ $b{i, j}$表示第$i$个片段的第$j$个tile的码率；$p_{i, j}$表示对不同位置tile所分配的权重； 关于权重$p_{i, j}$ 研究表明用户在全景视频FOV中的注意力分配并不是均等的，越靠近FOV中心的tile对用户的QoE贡献越大。 下面讨论单个片段的情况：用$(\\phi_j, \\theta_j)$表示tile中心点的坐标，并映射到笛卡尔坐标系上$(x_j, y_j, z_j)$： $$ x_j = cos\\theta_jcos\\phi_j,\\ y_j = sin\\theta_j,\\ z_j = -cos\\theta_jsin\\phi_j $$ 则两个tile之间的半径距离$d_{j, j'}$可以表示为： $$ d_{j, j'} = arccos(x_j x_{j'} + y_j y_{j'} + z_j z_{j'}) $$ 对于第$i$个片段，假设用户FOV中心的tile为$j^$，那么第$j$个tile的权重可以计算出来： $$ p_{i, j} = (1 - d_{j, j^} / \\pi) \\tau_{i, j} $$ 卡顿时间形式化 当$\\tilde{\\tau}{i, j}$与$\\tau{i, j}$出现分歧时，用户就不能成功收到请求的tile，头戴设备中显示的内容就会被冻结，由此导致卡顿。 对于任意的片段$i \\in \\Iota$，相应的卡顿时间$D_i$可以计算出来： $$ D_i = \\frac{\\sum_{j = 1}^{M \\times N} b_{i, j} \\cdot [\\tau_{i, j} - \\tilde{\\tau}_{i, j}]^+}{\\xi} $$ $[x]^+ = max{x, 0}$；$\\xi$表示可用的网络资源（已知，并且在推流过程中保持为常数） 卡顿发生于在播放时，用户FOV内的tile还没有被传输到用户头戴设备中的时刻，终止于所有FOV内tile被成功传送的时刻。 质量与卡顿时间的结合 $$ max\\ QoE = \\sum_{i = 1}^I (Q_i - wD_i) $$ $w$表示卡顿事件的惩罚权重。例如，w＝1000意味着1秒视频暂停接收的QoE惩罚与将片段的比特率降低1000 bps相同。 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:2:2","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"联合viewport预测与tile选择 联合框架包括viewport预测和动态tile选择两个阶段。 viewport预测阶段集成带有注意力机制的RNN，接收用户的历史头部移动信息作为输入，输出每个tile出现在FOV中的可能性分布。 选择tile阶段为预测的输出建立的上下文空间，基于上下文赌博机学习算法来选择tile并确定所选tile的质量版本。 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:3:0","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"Viewport预测 FOV预测问题可以看作是序列预测问题。 不同用户观看相同视频时的头部移动轨迹有强相关性，所以跨用户的行为分析可以用于提高新用户的viewport预测精度。 被广泛使用的LSTM的变体——Bi-LSTM（Bi-directional LSTM）用于FOV预测。 输入参数构造 为了构造Bi-LSTM学习网络，需要对不同用户的viewpoint特性作表征。 在用户观看事先划分好的$I$个片段时，记录每个片段对应的viewpoint坐标： $\\Phi_{1:I} = {\\phi_i}{i = 1}^I,\\ \\Theta{1:I} = {\\theta_i}_{i=1}^I$ 预测时使用的历史信息的窗口大小记为$k$； 对于第$i, (i \u003e k)$个片段，相应的viewpoint特性由$\\Phi_{i-1:i-k}$和$\\Theta_{i-1:i-k}$所给出； 列索引$m_i$和行索引$n_i$作为viewpoint tile $(\\phi_i, \\theta_i)$的标签，由独热编码表示； 通过滑动预测的窗口，所看到的视频片段的特性和标签可以被获取。 LSTM网络构造 整个网络包含3层： 遗忘门层决定丢弃哪些信息； 更新门层决定哪类信息需要存储； 输出门层过滤输出信息。 为了预测用户在第$i$个段的viewpoint，LSTM网络接受$\\Phi_{i-1:i-k}$和$\\Theta_{i-1:i-k}$作为输入；输出行列索引； $$ m_i = LSTM(\\theta_{i-k}, …, \\phi_{i-1}; \\alpha) $$ $$ n_i = LSTM(\\theta_{i-k}, …, \\theta_{i-1}; \\beta) $$ $\\alpha, \\beta$是学习网络的参数；分类交叉熵被用作网络训练的损失函数。 Bi-LSTM的特殊构造 将公共单向的LSTM划分成2个方向。 当前片段的输出利用前向和反向信息，这为网络提供了额外的上下文，加速了学习过程。 双向的LSTM不直接连接，不共享参数。 每个时间槽的输入会被分别传输到前向和反向的LSTM中，并分别根据其状态产生输出。 两个输出直接连接到Bi-LSTM的输出节点。 引入注意力机制为每步时间自动分配权重，从大量信息中选择性地筛选出重要信息。 将Softmax层堆叠在网络顶部，以获取不同tile的viewpoint概率。 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:3:1","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"动态tile选择 使用上下文赌博机学习算法来补偿viewport预测错误对QoE造成的影响。 上下文赌博机学习算法概况 上下文赌博机学习算法是一个基于特征的exploration-exploitation技术。 通过在多条手臂上重复执行选择过程，可以获得在不同上下文中的每条手臂的回报。 通过exploration-exploitation，目标是最大化累积的回报。 组成部分形式化 上下文 直觉上讲，当预测的viewpoint不够精确时，需要扩大FOV并选择更多的tile进行传输。 为了做出第$i$个片段上的预测viewpoint填充决策，定义串联的上下文向量： $c_i = [f_i^s, f_i^c]$，$f_i^s$表示自预测的上下文，$f_i^c$表示跨用户之间的预测上下文。 预测输出的用户$u$的viewpoint tile索引用$[\\tilde{m}{i-1}^u, \\tilde{n}{i-1}^u]$表示； 实际的用户$u$的viewpoint tile索引用$[m_{i-1}^u, n_{i-1}^u]$表示； 那么对第$i$个片段而言，自预测的上下文可以计算出来： $$ f_i^s = [|m_{i-1}^u - \\tilde{m}{i-1}^u|, |n{i-1}^u - \\tilde{n}_{i-1}^u|] $$ 跨用户的上下文信息获取：使用KNN准则选择一组用户，其在前$k$个片段中的轨迹最接近用户$u$的轨迹。 使用$\\zeta$表示获得的用户集合，使用$E_{\\zeta_u}(m_i) = \\frac{1}{|\\zeta_u|}\\sum_{u \\in \\zeta_u} |m_i^u - \\tilde{m}i^u|$和$E{\\zeta_u}(n_i) = \\frac{1}{|\\zeta_u|}\\sum_{u \\in \\zeta_u}|n_i^u - \\tilde{n}i^u|$表示预测误差，则： $$ f_i^u = [E{\\zeta_u}(m_i), E_{\\zeta_u}(n_i)] $$ 手臂 根据从第一个阶段得到的每个tile的可能性分布，所有的tile可以用倒序的方式排列。 最高可能性的tile被看作FOV的中心，高码率以此tile为中心分配。 剩余的带宽用于扩展FOV，低可能性的tile被顺序选择来扩展FOV直至带宽耗尽。 手臂的状态$a \\in {0, 1}$表示tile选择的策略： $a = 0$表示viewpoint预测准确，填充tile分配了高质量； $a = 1$表示viewpoint预测不准确，填充tile分配的质量较低，为了传送尽可能多的tile而减少卡顿； 回报 给定上下文$c_i$，选择手臂$a$，预期的回报$r_{i, a}$建模为$c_i$和$a$组合的线性函数： $$ \\Epsilon[r_{i, a}|c_{i, a}] = c_{i, a}^T \\theta_a^* $$ 未知参数$\\theta_a$表示每个手臂的特性，目标是为第$i$个片段选择最优的手臂： $$ a_i^* = \\underset{a}{argmax}\\ c_{i, a}^T \\theta_a^* $$ 使用LinUCB算法做出特征向量的精确估计并获取$\\theta_a^*$。 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:3:2","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"实验评估 评估准备 使用现有的viewpoint轨迹数据集，所有视频被编码为至少每秒25帧，长度为20到60秒； 视频每个片段被划分为$6 \\times 12$的tile，每个的角度是$30\\degree \\times 30\\degree$； 初始FOV设定为$90\\degree \\times 90\\degree$，在viewpoint周围是$3 \\times 3$的tile； 每个片段的长度为500ms； 默认的预测滑动窗口大小$k = 5$； HD和LD版本分别以按照HEVC的$QP={32, 22}$的参数编码而得到； 训练集和测试集的比例为$7:3$； Bi-LSTM层配置有128个隐单元； batch大小为64； epoch次数为60； 性能参数 预测精度 视频质量 由传送给用户的有效码率决定：例如实际FOV中的tile码率总和 卡顿时间 规范化的QoE 实际取得的QoE与在viewpoint轨迹已知情况下的QoE的比值 对比目标 预测阶段——预测精度 LSTM LR KNN 取tile的阶段——规范化的QoE 两个阶段都使用纯LR 只预测而不做动态选择 ","date":"2021-12-16","objectID":"/2021/12/note-for-rnnqoe/:4:0","tags":["Immersive Video","RNN","Trajectory-based predict","Dynamic tile selection"],"title":"Note for RnnQoE","uri":"/2021/12/note-for-rnnqoe/"},{"categories":["Immersive Video"],"content":"论文概况 Link：OpTile: Toward Optimal Tiling in 360-degree Video Streaming Level：ACM MM 17 Keyword：Dynamic tile division, Optimize encoding efficiency, Optimize tile size ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:1:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"背景知识 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:2:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"编码过程概述 对一帧图像中的每一个 block，编码算法在当前帧的已解码部分或由解码器缓冲的临近的帧中搜索类似的 block。 当编码器在邻近的帧中找到一个 block 与当前 block 紧密匹配时，它会将这个类似的 block 编码进一个动作向量中。 编码器计算当前 block 和引用 block 之间像素点的差异，通过应用变换（如离散余弦变换），量化变换系数以及对剩余稀疏矩阵系数集应用无损熵编码（如 Huffman 编码）对计算出的差异进行编码。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:2:1","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"对编码过程的影响 基于 tile 的方式会减少可用于拷贝的 block 数量，增大了可供匹配的 tile 之间的距离。 不同的投影方式会影响编码变换输出的系数稀疏性，而这会降低视频编码效率。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:2:2","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"投影过程 因为直接对 360 度图像和视频的编码技术还没有成熟，所以 360 度推流系统目前还需要先将 3D 球面投影到 2D 平面上。 目前应用最广的投影技术主要是 ERP 和 CMP，分别被 YouTube 和 Meta 采用。 ERP 投影 基于球面上点的左右偏航角$\\theta$与上下俯仰角$\\phi$将其映射到宽高分别为$W$和$H$的矩形上。 对于平面坐标为$(x, y)$的点，其球面坐标分别为： $$ \\theta = (\\frac{x}{W} - 0.5) * 360 $$ $$ \\phi = (0.5 - \\frac{y}{H}) * 180 $$ CMP 投影 将球面置于一个立方体中，光线从球心向外发射，并分别与球面和立方体相交于两点，这两点之间便建立了映射关系。 之后将立方体 6 个平面拼接成矩形，就可以使用标准的视频编码方式进行压缩。 关于投影方式还可以参考这里的讲解：谈谈全景视频投影方式 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:2:3","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"tile 方式的缺点 降低编码效率 tile 划分越细，编码越低效 增加更大的整体存储需求 可能要求更多的带宽 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:2:4","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"OpTile 的设计 直觉上需要增大一些 tile 的大小来使与这些 tile 相关联的片段能捕获高效编码所需的类似块。 同时也需要 tile 来分割视频帧来减少传输过程中造成的带宽浪费。 为了明白哪些片段的空间部分可以被高效独立编码，需要关于 tile 的存储大小的不同维度的信息。 为了找到切分视频的最好位置，需要在片段播放过程中用户 viewport 运动轨迹的偏好。 将编码效率和浪费数据的竞争考虑到同一个问题之中，这个问题关注的是一个片段中所有可能的视图的分布。 片段的每个可能的视图可以被 tile 的不同组合所覆盖。 目标是为一个片段选择一个 tile 覆盖层，以最小化固定时间段内视图分布的总传输带宽。 目标分离的部分考虑整个固定时间段的表示（representation）的存储开销。 目标的存储部分与下载的带宽部分相竞争。例如，如果一个不受欢迎的视频一年只观看一次，那么我们更喜欢一个紧凑的表示，我们可以期望向用户发送更多未观看的像素。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:3:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"问题形式化 segment/片段 推流过程中可以被下载的连续播放的视频单元 basic sub-rectangle/基本子矩形 推流过程中可以被下载的片段中最小的空间划分块 solution sub-rectangle/解子矩形 片段中由若干基本子矩形组成的任何矩形部分 $x$ 用于表示子矩形在解中的存在的二元向量 $c^{(stor)}$ 每个子矩形存储开销相关的向量 $c^{(view)}$ 给定一个 segment 中用户 viewport 的分布，$c^{(view)}$指相关子矩形的预期下载字节 $\\alpha$ 分配到$c^{(view)}$的权重，以此来控制相对于传输一个片段的存储开销 考虑将 1 个矩形片段划分成 4 个基本子矩形，其对应的坐标如下： 4 个基本子矩形可以有 9 种分配方式，成为解子矩形，如下（因为需要保持对应的空间关系，所以只有 9 种）： $x$的形式化 可以用向量$x$来分别表示上图中子矩形在解中的存在： $$ [1 \\times 1\\ at\\ (0, 0),\\ 1 \\times 1\\ at\\ (0, 1),\\ 1 \\times 1\\ at\\ (1, 0), \\ 1 \\times 1\\ at\\ (1, 1),\\ 1 \\times 2\\ at\\ (0, 0),\\ 1 \\times 2\\ at\\ (1, 0), \\ 2 \\times 1\\ at\\ (0, 0),\\ 2 \\times 1\\ at\\ (0,1),\\ 2 \\times 2\\ at\\ (0,0).] $$ （$x$中每个二元变量的的组成：$1 \\times 1$表示子矩形的形状，$(0,0)$表示所处的位置） 要使$x$有效，每个基本子矩形必须被$x$中编码的子矩形精确覆盖一次。例如： $[0, 0, 0, 0, 1, 1, 0, 0, 0]$=\u003e有效（第 5 和第 6 次序的位置分别对应$e$和$f$子矩形，恰好覆盖了所有基本子矩形 1 次） $[0,0,0,1,1,0,0,0,0]$=\u003e无效（第 4 和第 5 次序的位置分别对应$d$和$e$子矩形，没有覆盖到$(1,0)$基本子矩形） $[0,0,0,1,1,1,0,0,0]$=\u003e无效（第 4、第 5 和第 6 次序的位置分别对应$d$、$e$和$f$子矩形，$(1,1)$基本子矩形被覆盖了两次） $c^{(stor)}$的形式化 与每个$x$相对应的向量$c^{(stor)}$长度与$x$相等，其中每个元素是$x$中对应位置的子矩形的存储开销的估计值。 $c^{(view)}$的形式化 考虑分发子矩形的网络带宽开销时，需要考虑所有可能被分发的 360 度表面的视图。 为了简化问题，将片段所有可能的视图离散化到一个大小为$V$的集合中。 集合中每个元素表示一个事件，即向观看 360 度视频片段的用户显示基本子矩形的唯一子集。 注意到片段中被看到的视频区域可以包含来自多个视角的区域。 将之前离散化好的大小为$V$的集合中每个元素与可能性相关联：$[p_1, p_2, …, p_V]$。 考虑为给定的解下载视图$V$的开销，作为需要为该视图下载的数据量： $$ quantity = x^{\\top}diag(d_v)c^{(stor)} $$ $d_v$是一个二元向量，其内容是按照$x$所描述的表示方案，对所有覆盖视图的子矩形的选择。 例如对于 ERP 投影中位置坐标为$yaw = 0, pitch = 90$即处于等矩形顶部的图像，对应的$d_{view-(0, 90)} = [1, 1, 0, 0, 1, 0, 1, 1, 1]$ （即上面图中$a, b, e, g, h, i$位置的子矩形包含此视图所需的基本子矩形）。 给出一个片段中的用户 viewport 分布，$c^{(view)}$的元素是相关联的子矩形预期的下载字节。 $$ c^{(view)} = \\sum_v p_v diag(d_v) c^{(stor)} $$ 最后，将优化问题的基本子矩形覆盖约束编码为矩阵$A$。 $A$是一个列中包含给定子矩形解所覆盖的基本子矩形信息的二元矩阵。 对于$2 \\times 2$的矩形片段，其$A$有 4 行 9 列，例子如下： 因此最终的问题可以形式化为一个整数线性程序： $c^{(stor)}$ 可以理解为存储一段$\\Delta t$时间长的片段的子矩形的存储开销； $c^{(view)}$ 可以理解为传输一个视图所需要的所有的子矩形的传输开销。 $\\alpha$ 控制相比于传输一个片段的相对存储开销，同时应该考虑片段的流行度。 即$\\alpha$应该与所期望的片段在$\\Delta t$的时间间隔内的下载次数成比例，$\\alpha$应该可以通过经验测量以合理的精度进行估计。 可以通过将$x$的二元离散限制放松到$0 \\le x_i \\le 1\\ \\forall i$构成一个线性程序，其解为整数。 （对于有 33516 个变量的$x$，其解可以在单核 CPU 上用 7~10 秒求出） ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:4:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"开销向量建构 首先需要建构出存储开销向量$c^{(stor)}$，但是对于有$n$个基本子矩形的子矩形，其建构复杂度为$O(n^2)$。 因此对每个子矩形进行编码来获得存储开销并不可行，所以利用视频压缩与运动估计之间的强相关性来预测$c^{(stor)}$的值。 给定一个视频，首先暂时将其分成长度为 1 秒的片段，每个片段被限定为只拥有 1 个 GOP，片段的大小表示为$S_{orig}$。 接着抽取出每个片段中的动作序列用于之后的分析。 将片段从空间上划分成基本子矩形，每个基本子矩形包含$4 \\times 4 = 16$个宏块（例如：$64 \\times 64$个像素点）。 独立编码每个基本子矩形，其大小表示为$S_i$。 通过分析动作向量信息，可以推断出如果对基本子矩形$i$进行独立编码，指向基本子矩形$i$的原始运动向量应该重新定位多少。 将其表示为$r_i$。 每个运动向量的存储开销可以计算为： $$ o = \\frac{\\sum_i S_i - S_{orig}}{\\sum_i r_i} $$ 即：存储开销的整体增长除以被基本子矩形边界所分割的运动向量数。 如果基本子矩形被融合进更大的子矩形$t$，使用$m_t$来表示由于融合操作而无须再进行重定位的运动向量的数量： $$ m_t = \\sum_{i \\in t} r_i - r_t $$ $i \\in t$表示基本子矩形位于子矩形$t$中。 为了估计任意子矩形$t$的大小，使用下面 5 个参数： $$ \\sum_{i \\in t} S_i,\\ \\sum_{i \\in t} r_i,\\ m_t,\\ o,\\ n $$ $n$表示$t$中基本子矩形的数量。 实际操作： 创建了来自 4 个单视角 360 度视频的 6082 个 tile 数据集。4 个视频都以两种分辨率进行编码：$1920 \\times 960$和$3980 \\times 1920$。 为了产生 tile，从视频中随机选取片段，随机选取 tile 的位置，宽度和高度。 设置 tile 的 size 最大为$12 \\times 12$个基本子矩形。 对于每个选择的 tile，为其建构一个数据集元素： 计算上面提到的 5 参数的特性向量。 使用 FFmpeg 编码 tile 的视频段来得到存储该段需要的空间。 使用多层感知机 MLP 来估计 tile 的大小。 MLP 中包含 50 个节点的单隐层，激活函数为 ReLU 函数，300 次迭代的训练过程使用L-BFGS 算法。 为了评估 MLP 的预测效果，使用 4 折的交叉验证法。 每次折叠时先从 3 个视频训练 MLP，接着使用训练好的模型去预测第 4 个视频的 tile 大小。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:5:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"实现 将视频划分成1秒长的片段，之后为每个片段解决整数线性问题来确定最优的tile划分策略。 使用MLP模型估计每个tile的存储开销。 根据视图的集合$d$及其对应的可能性分布$p$，来估计视图的下载开销$c^{(view)}$。 构造矩阵$A$时，限制最大的tile大小为$12 \\times 12$的基本子矩形（如果设置每个基本子矩形包含$64 \\times 64$的像素，tile的最大尺寸即为$768 \\times 768$的像素）。 使用GNU Linear Programming Kit来解决问题。 将所有可能的解子矩形编码进一个二元向量$x$中来表示解。 GLPK的解表明一个可能的解子矩形是否应该被放入解中。 基于最终得到的解，划分片段并使用ffmepg以同样参数的x264格式进行编码。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:6:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"评估 度量指标 服务端存储需求。 客户端需要下载的字节数。 数据来源 数据集：dash.ipv6.enstb.fr 评估准备 下载5个使用ERP投影的视频，抽取出测试中用户看到的对应部分。 每个视频都有$1920 \\times 960$和$3840 \\times 1920$的两种分辨率的版本。 $1920 \\times 960$视频的基本子矩形尺寸为$64 \\times 64$的像素。 $3840 \\times 1920$视频的基本子矩形尺寸为$128 \\times 128$的像素。 将视频划分成1秒长的片段，对每个片段都产生出MLP所需的5元组特性。 之后使用训练好的MLP模型来预测所有可能的tile的大小。 数据选择 从数据集中随机选择出40个用户的集合。 假设100°的水平和垂直FOV，并使用40个用户的头部方向来为每个片段产生$p_v$和$d_v$。 即：分块的决策基于每个片段的内容特征信息与用户的经验视图模式。 参数设定：$\\alpha = 0,1,1000$. 对比实验： 一组使用由ILP得出的结构进行分块； 另外一组： $1920 \\times 960$的视频片段分别使用$64 \\times 64$，$128 \\times 128$，$256 \\times 256$，$512 \\times 512$的方案固定大小分块。 $3840 \\times 1920$的视频片段分别使用$128 \\times 128$，$256 \\times 256$，$512 \\times 512$，$1024 \\times 1024$的方案固定大小分块。 划分结果对比 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:7:0","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"服务端的存储大小 按照$\\alpha = 0$方案分块之后的视频大小几乎与未分块之前的视频大小持平，有时甚至略微小于未分块前的视频大小。 因为所有分块方案都使用相同的编码参数，所以重新编码带来的有损压缩并不会影响竞争的公平性。 如果将$\\alpha$的值调大，存储的大小会略微增大；固定分块大小的方案所得到的存储大小也会随tile变小而变大。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:7:1","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Immersive Video"],"content":"客户端的下载大小 预测完美的情况——下载的tile没有任何浪费 $\\alpha= 1000$的情况下，OpTile的表现总是最好的。 正常预测的情况 预测的方法：假设用户的头部方向不会改变，预测的位置即为按照当前方向几秒之后的位置。 相比于完美假设的预测，所有分块方案的下载大小都增大了。 $\\alpha = 1000$的方案在两个视频的情况下都取得了最小的下载大小。在剩下的3个视频中，OpTile方案的下载大小比起最优的固定分块大小方案不超过25%。 尽管固定分块大小的方案可能表现更好，但是这种表现随视频的改变而变化显著。 因为固定分块的方案没有考虑视频内容的特性与用户的观看行为。 ","date":"2021-12-13","objectID":"/2021/12/note-for-optile/:7:2","tags":["Immersive Video","Tile-based","Dynamic tile"],"title":"Note for OpTile","uri":"/2021/12/note-for-optile/"},{"categories":["Common sense"],"content":"媒体处理过程 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:0:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"解协议 将流媒体传输方案中要求的数据解析为标准的相应封装格式数据。 音视频在网络中传播时需要遵守对应的传输方案所要求的格式，如DASH、HLS将媒体内容分解成一系列小片段，每个片段有不同的备用码率版本。 同时应用层的协议会要求在媒体文件本身之外，传输信令数据（如对播放的控制或网络状态的描述） 解协议的过程会去除信令数据并保留音视频内容，需要的话还要对视频段进行拼接，最终将其还原成传输之前的媒体格式如MP4，FLV等。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:1:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"封装格式 封装格式如AVI、MPEG、Real Video将音频和视频组合打包成一个完整的文件. 封装格式不会影响视频的画质，影响画质的是视频的编码格式。 解封装过程就是将打包好的封装格式分离成某种编码的音频压缩文件和视频压缩文件，有时也包含字幕和脚本。 比如FLV或TS格式数据，解封装之后得到H.264-AVC编码的视频码流和AAC编码的音频码流。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:2:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"编码 视频的本质是一帧又一帧的图片。 所以对于一部每秒30帧，90分钟，分辨率为1920x1080，24位的真彩色的视频，在压缩之前的大小$S$满足： $$ 一帧大小s = 1920 * 1080 * 24 = 49766400(bit) = 6220800(Byte) \\ 总帧数n = 90 * 60 * 30 = 162000 \\ 总大小S = s * n = 6220800 * 162000 = 1.0077696*10^{12}(Byte) \\approx 939(GB) $$ 因为未经压缩的视频体积过于庞大，所以需要对其进行压缩，而压缩就是通常所说的编码。 视频编码方式：H.264-AVC，H.265-HEVC，H.266-VVC 音频编码方式：MP3，AAC 压缩比越大，解压还原之后播放的视频越失真，因为压缩过程中不可避免地丢失了视频中原有图像的数据信息。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:3:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"解码 解码就是解压缩过程。 解码之后能够得到系统音频驱动和视频驱动能识别的音频采样数据（如PCM数据）和视频像素数据（如YUV420，RGB数据）。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:4:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"音视频同步 根据时间，帧率和采样率采用一定的算法，同步解码出来的音频和视频数据，将其分别送至声卡和显卡播放。 视频质量指标 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:5:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"分辨率 分辨率指的是视频图像在一个单位尺寸内的精密度。 将视频放大足够大的倍数之后就能看到组成影像的基本单元：像素。 视频的分辨率从数值上描述了像素点的个数，如1920x1080：视频在水平方向有1920个像素，垂直方向有1080个像素。 常见的描述方式： 1080P：指视频有1080行像素，P=\u003eProgressive（逐行扫描） 2K：指视频有2000列像素 MP：像素总数，指像素的行数P与列数K乘积的结果（百万像素） 1080P的分辨率为1920x1080=2073600，所以1080P通常也称为200万像素分辨率 通常视频在同样大小的情况下，分辨率越高，所包含的像素点越多，画面就越细腻清晰 参考链接： 科普：视频分辨率是什么？ 「1080p」和「2k、4k」的关系与差别在哪里？ ","date":"2021-12-13","objectID":"/2021/12/mm-base/:6:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"视频帧率 帧率的单位FPS(Frame Per Second)或Hz，即每秒多少帧，决定视频画面的流畅程度。 低帧率会导致播放卡顿，镜头移动不顺畅，并伴随画面模糊的主观体验； 帧率过高则会造成眩晕的感觉。 不同帧率的视频在支持不同帧率的设备上播放： 若设备最高支持60fps，则播放120fps视频的时候，设备会每隔一帧删除一帧，被删除的帧即成为无效帧。 所以高帧率的视频在低帧率设备上播放时会导致播放卡顿。 若设备最高支持120fps，则播放60fps视频的时候，设备会每隔一帧复制一帧，来填补空缺的帧位置。 但是效果和在60fps上的设备播放一样，不能提升播放流畅度。 关于显卡对帧率的影像： 显示器帧率低而显卡输出帧率高时，会导致画面撕裂：显示器同时将两帧或几帧显示在同一个画面上 显示器帧率高而显卡输出帧率低时，同视频帧率高显示器帧率低的情况。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:7:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Common sense"],"content":"视频码率 码率的概念出现在视频编码之后，因为压缩之后的视频已经成为二进制数据，所以使用码率的称呼。 码率的单位是bps(bit per second)，即每秒多少比特。 与视频质量的关系： 分辨率不变的情况下，码率越大，压缩比越好，画面质量越清晰。 码率越高，精度越高，处理出的文件就越接近压缩前的原始状态，每一帧的图像质量越高，画质越清晰，当然对播放设备的解码能力要求也越高。 压缩比越小，视频体积越大，越接近源文件。 ","date":"2021-12-13","objectID":"/2021/12/mm-base/:8:0","tags":["Multimedia"],"title":"多媒体基础知识","uri":"/2021/12/mm-base/"},{"categories":["Immersive Video"],"content":"论文概况 Level：IEEE Transaction on multimedia 21 Keyword：Rainbow-DQN, Multi-type tiles, Full streaming system ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:1:0","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"问题形式化 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:0","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"模型 原始视频用网格划分成$N$块tile，每个tile都被转码成$M$个不同的质量等级$q_i$。 基于传输控制模块得出的结果，播放器请求$t_i$个tile的$q_i$质量的版本并将其存储在缓冲区中，对应的缓冲区大小为$l_i$。 用户Viewport的信息用$V$表示，可以确定FOV的中心。 根据$V$可以将tile划分成3种类型：FOV、OOS、Base。 FOV中的tile被分配更高的码率； OOS按照与$V$的距离逐步降低质量等级$q_i$； Base总是使用低质量等级$q_{Base}$但使用完整的分辨率。 传输的tile在同步完成之后交给渲染器渲染。 播放器根据各项指标计算可以评估播放性能： $\u003cV, B, Q, F, E\u003e$：viewport信息$V$，网络带宽$B$，FOV质量$Q$，重缓冲频率$F$，传输效率$E$。 传输控制模块用于确定每个tile的质量等级$q_i$和缓冲区大小$l_i$。 传输控制模块优化的最终目标是获取最大的性能： $$ performance = E_{max},\\ QoE \\in accept\\ range $$ ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:1","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"带宽评估 收集每个tile的下载日志来评估带宽。 使用指数加权移动平均算法EWMA使评估结果光滑，来应对网络波动。 第$t$次评估结果使用$B_t$表示，用下式计算： $$ B_t = \\beta B_{t-1} + (1-\\beta)b_t $$ $b_t$是B的第$t$次测量值；$\\beta$是EWMA的加权系数。 $t=0$时，$B_0$被初始化为0；所以在初始的$t$比较小的时候，$B_t$与理想值相比就很小。 这种影响会随着$t$增大而减少。 为了优化启动过程，对公式做出修改： $$ B_t = \\frac{\\beta B_{t-1} + (1-\\beta)b_t}{1 - \\beta^t} $$ $t$较小的时候，分母会放大$B_t$；$t$较大时，分母趋近于1，影响随之消失。 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:2","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"FOV表示和预测 3D虚拟相机用于渲染视频，处于全景视频球面上的某条轨道，其坐标可以表示为$(\\theta, \\phi)$，可以直接从系统中获取。 相机始终朝向球的中心，所以用户的FOV中心坐标$(\\theta^{'}, \\phi^{'})$可以用$(\\theta, \\phi)$表示： $$ \\begin{cases} \\theta^{'} = (\\theta + \\pi)\\ mod\\ 2\\pi,\\ 0 \\le \\theta \\le 2\\pi \\ \\phi^{'} = \\pi - \\phi,\\ 0 \\le \\phi \\le \\pi \\end{cases} $$ 2D网格中tile坐标$(u, v)$可以通过球面坐标使用ERP投影获得 $$ \\begin{cases} u = \\frac{\\theta^{'}}{2\\pi} \\cdot W, 0 \\le u \\le W. \\ v = \\frac{\\phi^{'}}{\\pi} \\cdot H, 0 \\le v \\le H. \\end{cases} $$ $W$和$H$分别表示使用ERP投影得到的矩形宽度和高度 短期的FOV预测基于目前和历史的FOV信息。 使用$(U_t, V_t)$表示$t$时刻的FOV中心位置；$U_{t1:t2}$和$V_{t1:t2}$分别表示从$t1$到$t2$过程中$U$和$V$的序列； $$ \\begin{cases} \\hat{U}{t+T_f} = f_U (U{t-T_p:t}). \\ \\hat{V}{t+T_f} = f_V (V{t-T_p:t}). \\end{cases} $$ $T_p$是过去记录的滑动窗口；$T_f$是短期的预测窗口；$f_U$和$f_V$分别对应$U$和$V$方向上的映射函数； 因为是时间序列回归模型，所以映射函数使用LSTM。 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:3","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"QoE评估 QoE由3个部分组成：平均FOV质量$Q$、重缓冲频率$F$与FOV内tile的质量变化（因为平均分配所以不考虑）。 FOV质量$Q$ 第$t$次的FOV质量评估表示为$Q_t$： $$ Q_t = \\frac{\\beta Q_{t-1} + (1-\\beta) \\frac{1}{k} \\cdot \\sum_{j=1}^{k} max{q_j, q_b}}{1 - \\beta^t} $$ $q_j$表示第$j$条FOV tile流的质量；$k$表示FOV内tile的数量； 为了避免评估结果的大幅波动，使用了EWMA来光滑结果。 当第$j$条tile流因为缓冲区不足不能成功播放时，$q_j = q_{Base}$（这表明了Base tile在提高QoE中的作用）。 重缓冲频率$F$ 在基于tile的传输中，每条流都属于一个缓冲区。所以当FOV中tile的缓冲区处于饥饿状态时，重缓冲就会发生。 重缓冲频率描述了FOV内的tile流在一段时间内的重新缓冲频率。 第$t$次重缓冲频率的评估表示为$F_t$： $$ F_t = \\frac{\\beta F_{t-\\tau} + (1-\\beta) \\frac{f_t}{\\tau}}{1 - \\beta^{\\tau}} $$ $f_t$表示播放失败的次数；$\\tau$表示一段时间； ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:4","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"传输效率评估 第$t$次传输效率评估表示为$E_t$，$E_t$通过传输的FOV内tile占总tile的比率来计算： $$ E_t = \\frac{\\beta E_{t-1} + (1-\\beta) \\frac{total^{FOV}}{total^{ALL}}}{1 - \\beta^t} $$ $total^{FOV}$表示FOV内tile的数据量；$total^{ALL}$表示tile的总共数据量； 效率计算并不在传输过程中完成，因为需要获取哪些tile在FOV中的信息，效率评估滞后于播放过程。 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:5","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"问题形式化 传输控制的任务：确定所有tile流的质量等级$\\chi$和缓冲区大小$\\psi$。 $$ \\chi = \u003cq_1, q_2, …, q_N\u003e \\ \\psi = \u003cl_1, l_2, …, l_N\u003e \\ \u003cQ, F, E\u003e = \\xi (B, V, \\chi, \\psi) $$ $\\chi$和$\\psi$与带宽$B$和Viewport轨迹$V$一起作用于系统$\\xi$，最终影响FOV质量$Q$，重缓冲频率$F$和传输效率$E$。 进一步，将目标形式化为获得每条tile流的$q_i$和$l_i$通过限制QoE满足可接受的范围、在此基础上最大化传输效率： $$ \\underset{\\chi, \\psi}{argmax} \\sum_{t=0}^{+\\infty} E_t, $$ $$ s.t.:\\ 0 \\le q_i \\le M, $$ $$ 0 \\le l_i \\le L, $$ $$ Q^{min} \\le Q_t \\le M, $$ $$ 0 \\le F_t \\le F^{max}. $$ $q_i$和$l_i$分别受限于质量版本数$M$和最大缓冲区大小$L$； $Q_t$受限于最低QoE标准$Q^{min}$； $F_t$受限于最大能忍受的重缓冲频率$F^{max}$。 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:2:6","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"系统架构 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:3:0","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"服务端 将原始视频转码为有不同比特率的多个版本。 转码后的视频被划分成多个tile。 传输协议使用MPEG-DASH。 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:3:1","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"客户端 评估器 任务：获取 QoE、FOV预测、传输效率、网络带宽 组成： QoE评估器：评估当前FOV质量=\u003eQ和重缓冲频率=\u003eF（近似为Q+F=QoE） FOV预测器：基于历史FOV信息预测短期未来的FOV=\u003eP 根据下载和播放日志：计算传输效率=\u003eE并估计带宽=\u003eB 控制器 任务：控制传输过程中的推流 目标：保证QoE在可接受的范围之内、最大化传输效率 详细：基于FOV预测将tile划分成3种类型：FOV、OOS、Base 输入：Q、F、E、B（QoE+传输效率和带宽） 过程：Rainbow-DQN 输出：决定每个tile流的码率和缓冲区大小（作为下载器的输入） 下载器 输入：tile码率和缓冲区大小 过程：基于HTTP/2进行并行下载 输出：下载好的tile 视频缓冲区 任务：解码、同步、存储下载好的tile等待渲染器消耗，大小供控制器调节 随着FOV的切换缓冲区内容可能被循环利用 全景渲染器 任务：将同步好的tile拼接，tile质量：FOV\u003eOOS\u003eBase 投影方式：ERP ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:3:2","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"控制器 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:4:0","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"控制过程 设定QoE的可接受范围。 将网络带宽和用户FOV设定为外部因素而非环境 为什么：因为这两个因素变化太快，在面对不同传输条件时，直接作为环境会导致决策过程的不稳定性并且难以收敛。 最优化的对象只是最大化累积的传输效率。 为什么：简单 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:4:1","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"tile聚合和决策 tile分类原则： 控制器无需为每个tile独立决定码率Q和缓冲区大小L FOV内的tile应该被分配相近的码率，FOV内的tile应该聚集成一组，OSS和Base同理 为什么：避免相邻tile的锐利边界，只考虑3组而非所有tile降低了计算复杂性和决策延迟 （能否实现独立的tile码率计算或更细粒度的划分值得调研？与内容感知的方案结合？） 基于距离的tile分类实现方式： 使用评估器预测出的FOV坐标来分类FOV和OOS的tile tile出现在未来FOV的可能性由距离计算 tile中心点坐标$(\\omega_i, \\mu_i)$、FOV坐标$(\\hat{U}, \\hat{V})$ 距离的变化区间内存在一个临界点，临界点之内的划分为FOV，之外的划分为OOS 度量距离的方式： $$ \\Delta Dis_U = min{|\\omega_i - \\hat{U}|, |1+\\omega_i - \\hat{U}|} $$ （这里为何不直接使用$|\\omega_i - \\hat{U}|$？） $$ Dis_i = \\begin{cases} {\\sqrt{({\\Delta Dis_{U}})^2 + {(\\mu_i - \\hat{V})}^2},\\ \\frac{R}{H} \\le \\hat{V} \\le 1 - \\frac{R}{H}} \\ {\\Delta Dis_U + |\\mu_i - \\hat{V}|,\\ Others} \\end{cases} $$ 因为ERP的投影方式会在两级需要更多的tile，因此使用一个矩形来代表两极的FOV （可以深入调研ERP在两极处的处理方式） $Dis_i$使用曼哈顿距离来测量。临界点初始化为$2\\cdot R$，并随着FOV中心和两极的垂直距离增长。 FOV看作是半径为R的圆，使用欧式距离测量。临界点初始化为$R$ 聚合tile的决策 使用2个变量：$K$作为FOV和非FOV的tile的带宽分配比率；$Len$作为tile缓冲区的大小。 $K$确定之后，分配给FOV内tile的带宽被均匀分配（可否非均匀分配） $K$不直接与网络状况相关因此可以保持控制的稳定性 $Len$：所有传输的tile的缓冲区长度$l_i$都被设为$Len$ （文中并没有这样做的原因解释） ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:4:2","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"基于DRL的传输控制算法 相关术语解释：Rainbow DQN、RL Dictionary、PER、TD-Error 控制过程 首先调整buffer长度Len，并划分FOV与非FOV的带宽分配。 等viewport预测完成之后，tile被分类为属于FOV和OOS的tile。 FOV的带宽被平均分给其中每一个tile并决定FOV内tile的质量等级$q_i$。 非FOV的带宽按照与FOV的距离分配，每超过一个距离单位$Dis_i$就降低一级质量$q_i$。 最终的输出是请求序列，每个请求序列中包括质量等级$q_i$和预期的缓冲区大小$l_i$。 根据输出做出调整之后，接收奖励反馈并不断完成自身更新。 状态设计 状态设计为5元组：$\u003cK, Len, Q, F, E\u003e$（传输控制参数$K$，$Len$、QoE指标：FOV质量Q和重缓冲频率$F$、传输效率$E$） 没有直接使用带宽$B$和viewport轨迹$V$，因为： 随机性强与变化幅度较大带来的不稳定性（如何定义随机性强弱和变化幅度大小？） 希望设计的模型有一定的通用性，可以与不同的网络情况和用户轨迹相兼容 动作设计 两种动作：调整$K$和$Len$（两者的连续变化区间被离散化，调整的每一步分别用$\\Delta k$和$\\Delta l$表示） 调整的方式被形式化为二元组：$\u003cn_1, n_2\u003e$，$n_1$和$n_2$分别用于表示$K$和$Len$的调整 -n 0 n K 减少n$\\Delta k$ 不变 增加n$\\Delta k$ Len 减少n$\\Delta l$ 不变 增加n$\\Delta l$ 奖励函数 因为QoE的各项指标权重难以确定，没有使用传统的基于加权的方式。 设定了能接受的QoE范围和在此基础上最大化的传输效率作为最后的性能指标，形式化之后如下： $$ Reward = \\begin{cases} -INF,\\ F \\ge F^{max} \\ -INF,\\ E \\le E^{min} \\ E,\\ Others \\end{cases} $$ $-INF$意味着终止当前episode；动作越能使系统满足高QoE的同时高效运行，得分越高； 为了最大化传输效率，使用$E$作为奖励回报。 FOV质量$Q$并没有参与到奖励函数中，因为：高Q意味着高性能，但是低Q不一定意味着低性能，详细解释如下： 在带宽不足的情况下，低Q可能已经是这种条件下的满足性能的最好选择。 高传输效率意味着传输了更多的FOV数据，也能满足高FOV质量的目标。 模型设计 基于Rainbow-DQN模型： 输入是5元组$\u003cK, Len, Q, F, E\u003e$。 神经网络使用64维的3隐层模型。 为了提高鲁棒性，神经网络的第3层使用Dueling DQN的方式，将Q值$Q(s, a)$分解为状态价值$V(s)$和优势函数$A(s,a)$： $$ Q(s, a) = V(s) + A(s, a) $$ $V(s)$表示系统处于状态$s$时的性能；$A(s,a)$表示系统处于状态$s$时动作$a$带来的性能； 为了避免价值过高估计，使用Double DQN的方式，设计了两个独立的神经网络：评估网络和目标网络。 评估网络用于动作选择；目标网络是评估网络从最后一个episode的拷贝用于动作评估。 为了缓解神经网络的不稳定性（更快收敛），使用大小为$v$的回放池来按照时间序列保存客户端的经验。 因为网络带宽和FOV轨迹在短期内存在特定的规律性，回放池中有相似状态和相似采样时间的样本更加重要，出现了优先级 所以使用优先经验回放PER，而优先级使用时间查分误差TD-error定义 $$ \\delta_i = r_{i+1} + \\gamma Q(s_{i+1}, arg\\underset{a}{max}Q(s_{i+1}, a; \\theta_i); \\theta_i^{'}) - Q(s_i, a_i; \\theta_i) $$ $r_i$是奖励；$\\gamma$是折扣因子 损失函数使用均方误差定义 $$ J = \\frac{1}{v} \\sum_{i=1}^{v} \\omega_i(\\delta_i)^2 $$ $\\omega_i$是回放缓冲中第i个样本的重要性采样权重 ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:4:3","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"实验验证 环境设定 传输控制模块：基于TensorForce（配置教程：用TensorForce快速搭建深度强化学习模型）； 开发工具集：OpenAI Gym 数据来源：使用全景视频播放设备收集，加入高斯噪声来产生更多数据。 结果分析 与其他DQN算法的对比——DQN、Double DQN、Dueling DQN 对比训练过程中每个episode中的最大累计奖励：$MAX_{reward}$ 对比模型收敛所需要的最少episode：$MIN_{episode}$ 相同的带宽和FOV轨迹 与其他策略对比性能——高QoE和高传输效率 随机控制策略：随机确定K和Len 固定分配策略：固定K和Len的值 只预测Viewport策略：使用LSTM做预测，不存在OSS与Base，所有带宽都用于FOV 带宽和FOV轨迹的均值和方差相等 与其他全景视频推流系统的对比 DashEntire360：使用Dash直接传送完整的360度视频，使用线性回归来估计带宽并动态调整视频比特率 360ProbDash：在DashEntire360的基础上划分tile基于Dash传输，使用可能性模型为tile分配比特率 DRL360：使用DRL来优化多项QoE指标 实现三种系统、使用随机网络带宽和FOV轨迹。 使用DRL360中提出的方式测量QoE： $$ V_{QoE} = \\eta_1 Q - \\eta_2 F - \\eta_3 A $$ $A$是viewport随时间的平均变化，反映FOV质量Q的变化； $\\eta_1, \\eta_2, \\eta_3$分别是3种QoE指标的非负加权，使用4种加权方式来训练模型并对比： $\u003c1, 1, 1\u003e$，$\u003c1, 0.25, 0.25\u003e$，$\u003c1, 4, 1\u003e$，$\u003c1,1,4\u003e$ 在不同环境下的性能评估——带宽是否充足、FOV轨迹是否活跃（4种环境） ","date":"2021-12-11","objectID":"/2021/12/note-for-rainbowdqn-tiles/:5:0","tags":["Immersive Video","DRL","Rainbow-DQN"],"title":"Note for RainbowDQN and Multitype Tiles","uri":"/2021/12/note-for-rainbowdqn-tiles/"},{"categories":["Immersive Video"],"content":"论文概况 Link: 360ProbDASH: Improving QoE of 360 Video Streaming Using Tile-based HTTP Adaptive Streaming Level: ACM MM 17 Keyword: Pre-fetch tiles, QoE-driven optimization, Probabilistic model, Rate and Viewport adaptation ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:1:0","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"工作范围与目标 应用层-\u003e基于tile-\u003eviewport预测的可能性模型+预期质量的最大化 针对小buffer提出了target-buffer-based rate control算法来避免重缓冲事件（避免卡顿） 提出viewport预测的可能性模型计算tile被看到的可能性（避免边缘效应） 形式化QoE-driven优化问题： 在传输率受限的情况下最小化viewport内的质量失真和空间质量变化（获取受限状态下最好的视频质量） ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:2:0","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"问题建模 形式化参数 $M*N$个tile，M指tile序列的序号，N指不同的码率等级 $r_{i, j}$指比特率，$d_{i, j}$指失真，$p_{i}$指被看到的可能性（$\\sum_{i=1}^{N}p_{i} = 1$） $\\Phi(X)$指质量失真，$\\Psi(X)$指质量变化 目标 找到推流段的集合：$X = {x_{i, j}}$，其中${x_{i, j}} = 1$指被第$\u003ci, j\u003e$个tile被选中；$x_{i, j} = 0$则是未选中。 $$ \\underset{X}{min}\\ \\Phi(X) + \\eta \\cdot \\Psi(X) \\ s.t. \\sum_{i=1}^{N}\\sum_{j=1}^{M}x_{i, j}\\cdot r_{i, j} \\le R, \\ \\sum_{j=1}^{M}x_{i, j} \\le 1, x_{i, j} \\in {0, 1}, \\forall i. $$ 整个公式即为前所述的问题的形式化表达的公式化结果。 模型细节 $\\Phi(X)$和$\\Psi(X)$的计算=\u003e通过考虑球面到平面的映射 通过计算球面上点的Mean Squared Error来得到S-PSNR进而评估质量：$d_{i, j}$来表示第${\u003ci, j\u003e}$个段的MSE $$ \\phi_i = \\frac{\\pi}{2} - h_i \\cdot \\frac{\\pi}{H}, \\Delta\\phi = \\Delta h \\cdot \\frac{\\pi}{H}, \\ \\theta_i = w_i \\cdot \\frac{2\\pi}{W}, \\ \\Delta\\theta = \\Delta w \\cdot \\frac{2\\pi}{W}, $$ $H$和$W$分别指按照ERP格式投影之后的视频高度和宽度 第$i$个tile的空间面积用$s_i$表示： $$ s_i\\ =\\ \\iint_{\\Omega_i}Rd\\phi Rcos\\phi d\\theta \\ =\\Delta\\theta R^2[sin(\\phi_i + \\Delta\\phi) - sin\\phi_i], $$ $R$指球的半径（$R = W/2\\pi$），所以整体的球面质量失真$D_{i, j}$可以计算出来： $$ D_{i, j} = d_{i, j} \\cdot s_i, $$ 结合每个tile被看到的概率$p_i$可以得出$\\Phi(X)$和$\\Psi(X)$ $$ \\Phi(X)=\\frac{\\sum_{i=1}^N\\sum_{j=1}^MD_{i, j}\\cdot x_{i,j}\\cdot p_i}{\\sum_{i=1}^N\\sum_{j=1}^Mx_{i,j}\\cdot s_i},\\ \\Psi(X) = \\frac{\\sum_{i=1}^N\\sum_{j=1}^Mx_{i, j}\\cdot p_i \\cdot\\ (D_{i,j}-s_{i} \\cdot \\Phi(X))^2}{\\sum_{i=1}^N\\sum_{j=1}^Mx_{i,j}\\cdot s_i}. $$ Viewport的可能性模型 方向预测=\u003e线性回归模型 将用户的欧拉角看作是$yaw(\\alpha)$，$pitch(\\beta)$和$rool(\\gamma)$，应用线性回归做预测 $$ \\begin{cases} \\hat{\\alpha}(t_0 + \\delta) = m_{\\alpha}\\delta+\\alpha(t_0),\\ \\hat{\\beta}(t_0 + \\delta) = m_{\\beta}\\delta+\\beta(t_0),\\ \\hat{\\gamma}(t_0 + \\delta) = m_{\\gamma}\\delta+\\gamma(t_0). \\end{cases} $$ 预测错误的分布=\u003e高斯分布，根据公式均值和标准差都能从统计信息中计算出来 收集5名志愿者的头部移动轨迹并投影到3个方向上绘制成图，实验结果为预测错误呈现高斯分布（样本数可能不够？） $$ \\begin{cases} P_{yaw}(\\alpha) = \\frac{1}{\\sigma_{\\alpha}\\sqrt{2\\pi}}exp{-\\frac{[\\alpha-(\\hat{\\alpha}+\\mu_{\\alpha})]^2}{2\\sigma_{\\alpha}^2}},\\ P_{pitch}(\\beta) = \\frac{1}{\\sigma_{\\beta}\\sqrt{2\\pi}}exp{-\\frac{[\\beta-(\\hat{\\beta}+\\mu_{\\beta})]^2}{2\\sigma_{\\beta}^2}},\\ P_{roll}(\\gamma) = \\frac{1}{\\sigma_{\\gamma}\\sqrt{2\\pi}}exp{-\\frac{[\\gamma-(\\hat{\\gamma}+\\mu_{\\gamma})]^2}{2\\sigma_{\\gamma}^2}}. \\end{cases} $$ 3个方向各自独立，因此最终的预测错误$P_E(\\alpha,\\beta,\\gamma)$可以表示为： $$ P_E(\\alpha, \\beta, \\gamma) = P_{yaw}(\\alpha)P_{pitch}(\\beta)P_{roll}(\\gamma). $$ 球面上点被看到的可能性 球面坐标为$(\\phi, \\theta)$点的可能性表示为$P_s(\\phi, \\theta)$ 因为一个点可能在多个不同的viewport里面，所以定义按照用户方向从点$(\\phi, \\theta)$出发能看到的点集$L(\\phi, theta)$ 因此空间点$s$被看到的可能性可以表示为： $$ P_s(\\phi, \\theta) = \\frac{1}{|L(\\phi, \\theta)|}\\sum_{(\\alpha, \\beta, \\gamma) \\in L(\\phi, \\theta)}P_E(\\alpha, \\beta, \\gamma), $$ 球面上tile被看到的可能性 tile内各个点被看到的可能性的均值即为tile被看到的可能性（可否使用其他方式？） $$ p_i = \\frac{1}{|U_i|} \\sum_{(\\phi, \\theta) \\in U_i} P_s(\\phi, \\theta). $$ $U_i$表示tile内的空间点集 Target-Buffer-based Rate Control 因为长期的头部移动预测会产生较高的预测错误，所以不能采用大缓冲区（没有cite来证明这一点） 将处于相同时刻的段集合成一个块存储在缓冲区中。 在自适应的第k步，定义$d_k$作为此时的buffer占用情况（等到第k个块被下载完毕） $$ b_k = b_{k-1} - \\frac{R_k \\cdot T}{C_k} + T $$ $C_k$表示平均带宽，$R_k$表示总计的码率 为了避免重新缓冲设定目标buffer占用$B_{target}$，并使buffer占用保持在$B_{target}$（$b_k = B_{target}$） 因此总计的码率需要满足： $$ R_k = \\frac{C_k}{T} \\cdot (b_{k-1} - B_{target} + T), $$ 这里的$C_k$表示可以从历史的段下载信息中估计出来的带宽 设定$R$的下界$R_{min}$之后（没有说明为何需要设定下界），公式12可以修正为如下： $$ R_k = max{\\frac{C_k}{T} \\cdot (b_{k-1} - B_{target} + T), R_{min}}. $$ ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:3:0","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"实现 ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:4:0","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"服务端 视频裁剪器 将视频帧切割成tile 编码器 对tile进行划分并将其编码成多种码率的段 MPD产生器 添加SRD特性来表示段之间的空间关系 添加经度和纬度属性来表示 添加质量失真和尺寸属性 Apache HTTP服务器 存储视频段和mpd文件，向客户端推流 ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:4:1","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"客户端 基础：dash.js 额外的模块 QoE-driver Optimizer $$ Output = HTTP\\ GET请求中的最优段 $$ $$ Input = Output\\ of\\ \\begin{cases} Target\\ buffer\\ based\\ Rate\\ Controller\\ Viewport\\ Probabilistic\\ Model\\ QR\\ Map \\end{cases} $$ Target-buffer-based Rate Controller $$ Output = 总计的传输码率，按照公式13计算而来 $$ $$ Input = Output\\ of\\ {Bandwidth\\ Estimation\\ module $$ Viewport Probabilistic Model $$ Output = 每个tile被看到的可能性，按照公式10计算而来 $$ $$ Input = Output\\ of\\ \\begin{cases} Orientation\\ Prediction\\ module\\ SRD\\ information \\end{cases} $$ QR MapQR=\u003eQuality-Rate $$ Output = 所有段的QR映射 $$ $$ Input = MPD中的属性 $$ Bandwidth Estimation（没有展开研究，因为不是关键？） $$ Output = 前3秒带宽估计的平均值 $$ $$ Input = 下载段过程中的吞吐量变化 $$ 可以通过onProgess()的回调函数XMLHttpRequest API获取 Orientation Prediction $$ Output = 用户方向信息的预测结果（yaw, pitch, roll） $$ $$ Input = Web\\ API中获取的DeviceOrientation信息，使用线性回归做预测 $$ ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:4:2","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"评估 整体设定 将用户头部移动轨迹编码进播放器来模拟用户头部移动 积极操控网络状况来观察不同方案对网络波动的反应 详细设定 服务端 视频选择 2880x1440分辨率、时长3分钟、投影格式ERP 切分设置 每个块长1s（$T=1$）、每个块被分成6x12个tile（$N=72$） 每个段的码率设置为${20, 50, 100, 200, 300}$，单位kpbs 视频编码 开源编码器x264 视频分包 MP4Box 注意事项 每个段的确切尺寸可能与其码率不同，尤其对于长度较短的块。 为了避免这影响到码率自适应，将段的确切尺寸也写入MPD文件中 客户端 缓冲区设定（经过实验得出的参数） $B_{max}=3s$，$B_{target}=2.5s$，$R_{min}=200kbps$，$权重\\eta=0.0015$ 高斯分布设定 Yaw Pitch Roll $\\mu_{\\alpha}=-0.54,\\ \\sigma_{\\alpha}=7.03$ $\\mu_{\\beta}=0.18,\\ \\sigma_{\\beta}=2.55$ $\\mu_{\\gamma}=2.16,\\ \\sigma_{\\gamma}=0.15$ 比较对象 ERP：原始视频格式 Tile：只请求用户当前viewport的tile，不使用viewport预测，作为baseline Tile-LR：使用线性回归做预测，每个tile的码率被平均分配 性能指标 卡顿率：卡顿时间占播放总时长的比例 Viewport PSNR：直接反应Viewport内的视频质量 空间质量差异：Viewport内质量的协方差 Viewport偏差：空白区域在Viewport中的比例 ","date":"2021-12-09","objectID":"/2021/12/note-for-360probdash/:5:0","tags":["Immersive Video"],"title":"Note for 360ProbDASH","uri":"/2021/12/note-for-360probdash/"},{"categories":["Immersive Video"],"content":"论文概况 Link: https://dl.acm.org/doi/10.1145/3232565.3234686 Level: SIGCOMM 18 Keyword: UDP+FOV-aware+FEC ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:1:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"工作范围 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:2:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"目标 在给定序列的帧中，为每个tile设定FEC冗余，根据其被看到的可能性的加权最小化平均质量降低。 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:3:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"问题建模 输入 估计的丢包率$p$、发送速率$f$、有$n$个tile的$m$个帧($\u003ci, j\u003e$来表示第$i$个帧的第$j$个tile 第$\u003ci, j\u003e$个tile的大小$v_{i, j}$、第$\u003ci, j\u003e$个tile被看到的可能性$\\gamma_{i, j}$、 如果第$\u003ci, j\u003e$ 个tile没有被恢复的质量降低率、最大延迟$T$ 输出 第$\u003ci, j\u003e$个tile的FEC冗余率$r_{i, j} = \\frac{冗余包数量}{原始包数量}$ 最优化问题的形式化 $$ minimize\\ \\sum_{0\u003ci\\le m}\\sum_{0\u003cj\\le n} \\gamma_{i, j}d_{i, j}(p, r_{i, j}) $$ $$ subject\\ \\ to\\ \\ \\frac{1}{f}\\sum_{0\u003ci\\le m}\\sum_{0\u003cj\\le n}v_{i, j}(1+r_{i, j}) \\le T $$ $$ r_{i, j} \\le 0 $$ （1）：最小化最终被看到的tile的质量衰减的加权和，权重按照被看到的可能性分配。 （2）：经过重新编码的包和原始的包需要在T时刻之前发出。 ​ Dante将1个GOP(Group of Pictures)中的所有帧当作一批处理，$T$作为GOP的持续时间 ​ $f$：使用TCP Friendly Rate Control algorithm，基于估计的丢包率和网络延迟来计算得出 （3）：确保冗余率总是非负的。 关键变量是$d_{i, j}(p, r)$：丢包率是p情况下，采用r作为冗余率的第$\u003ci, j\u003e$个tile的质量衰减 $$ d_{i, j}(p, r) = \\delta_{i, j},\\ if\\ r \u003c \\frac{1}{1-p}; 0, otherwise. $$ 假设帧中有k个原始包，质量衰减发生在丢失的包不能被恢复的情况下。 FEC可以容忍 $r \\cdot k$ 个丢包=\u003e即当 $p(rk+k)$ 大于 $rk$ 时会发生质量衰减。 过多的丢包会导致依赖链上所有帧的质量衰减，因此考虑帧之间的依赖关系之后，可以重新计算质量衰减： $$ d^{*}{i, j}(p, r) = \\sum{0\u003cc\\le i}w_{c, i}d_{c, j}(p, r) $$ $w_{c, i}$ 编码帧i对帧c的依赖作为单独的第c个帧的质量衰减的权重； 最终第i个帧的第j个tile的最终质量衰减就是所有依赖的质量衰减的和。 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:4:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"FEC冗余的自适应逻辑 关于$d_{i, j}(p, r)$ ：因为是分段函数，所以其值会因为r和p的大小关系而急剧改变。 利用背包问题的思想可以将其规约成NP完全问题： 将每个tile看作是一个物品，共有m*n个。 如果$r_{i, j} \u003c \\frac{1}{1-p}$ ，则表示不把第\u003ci,j\u003e和物品放入背包；否则就是将其放入背包。 公式1可以转化为：最大化所有物品二元变量的线性组合； 公式2可以转化为：二元变量的另一个线性组合必须低于阈值约束。 因此整个问题就能被完全转化为0-1背包问题 算法 整体上是背包问题的标准解法，能以线性复杂度（因为变量只是B)解决问题。 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:5:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"原型设计 使用基于TCP和UDP的两条连接来分别传输控制信息（双向：到客户端的播放会话的起至点和到服务端的网络信息反馈）和视频数据包 服务端根据反馈的网络信息，在每个GOP的边界时刻运行算法1来确定下一个GOP的帧和tile的FEC冗余。 确定之后服务端使用RS码来插入冗余包，和原始视频数据包一起重新编码，并使用基于TFRC的发送率发送数据。 Dante的实现是对应用程序级比特率适配策略的补充，并且可以通过对视频播放器进行最小更改来替换现有的底层传输协议来部署。 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:6:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"实验评估 环境：使用Gilbert模型来模拟实现丢包事件（而非使用统一随机丢包） 创造了两种网络条件good（丢包率0.5%）和bad（丢包率2%） ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:7:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"局限性 效果主要依赖于Viewport预测的结果是否准确 ","date":"2021-12-08","objectID":"/2021/12/note-for-dante/:8:0","tags":["Immersive Video","UDP","Heuristic"],"title":"Note for Dante","uri":"/2021/12/note-for-dante/"},{"categories":["Immersive Video"],"content":"度量指标 viewport预测精度。 使用预测的viewport坐标和实际用户的viewport坐标的大圈距离来量化。 视频质量。 viewport内部的tile质量（1～5）。 tile在最高质量层之上花费的时间。 根据用户视线的分布而提出的加权质量度量。 ","date":"2021-11-22","objectID":"/2021/11/note11/:1:0","tags":["Immersive Video"],"title":"沉浸式流媒体传输的实际度量","uri":"/2021/11/note11/"},{"categories":["Immersive Video"],"content":"度量参数 分块策略 带宽 延迟 viewport预测 HTTP版本 持久化的连接数量 ","date":"2021-11-22","objectID":"/2021/11/note11/:2:0","tags":["Immersive Video"],"title":"沉浸式流媒体传输的实际度量","uri":"/2021/11/note11/"},{"categories":["Immersive Video"],"content":"背景 大多数的HAS方案使用HTTP/1.1协议进行请求-回应的事务来取得需要的资源、缓冲取到的视频段并以线性的顺序播放。传统的HAS中，只需要1个GET请求来取得下一个视频的暂时的部分。只要视频段的持续时间比网络内的时延高，这种方法就可行。 在基于VR的HAS方案中，播放1条视频片段就需要取得多种资源：1次GET请求需要同时请求基础的tile层和每个空间视频tile。使用4x4的tile方案时，客户端需要发起不少于17次GET请求。使用 1 s 数量级的分段持续时间，即使是 20 ms 的微小网络延迟也会显着阻碍客户端和服务器之间的整体吞吐量，因此会导致较低的视频质量。 ","date":"2021-11-15","objectID":"/2021/11/note10/:1:0","tags":["Immersive Video"],"title":"沉浸式推流中应用层的优化","uri":"/2021/11/note10/"},{"categories":["Immersive Video"],"content":"解决方案 ","date":"2021-11-15","objectID":"/2021/11/note10/:2:0","tags":["Immersive Video"],"title":"沉浸式推流中应用层的优化","uri":"/2021/11/note10/"},{"categories":["Immersive Video"],"content":"使用多条持久的TCP连接 大多数的现代浏览器都支持同时建立并维持多达6条TCP连接来减少页面加载时间，并行地获取请求的资源。这允许增加整体吞吐量，并部分消除网络延迟引入的空闲 RTT 周期。 类似地，基于 VR 的 HAS 客户端可以使用多个 TCP 连接并行下载不同的tile。 ","date":"2021-11-15","objectID":"/2021/11/note10/:2:1","tags":["Immersive Video"],"title":"沉浸式推流中应用层的优化","uri":"/2021/11/note10/"},{"categories":["Immersive Video"],"content":"使用HTTP/2协议的服务端push特性 HTTP/2协议引入了请求和相应的多路复用、头部压缩和请求优先级的特性，这可以减少页面加载时间。 服务端直接push短视频片段可以减少视频的启动时间和端到端延迟。 并且，服务端push特性可以应用在基于tile的VR视频推流中，客户端可以向服务器同时请求一条视频片段的所有tile。 服务端可以使用特制的请求处理器，允许客户端为每个tile定义一系列质量等级。 因此可以将应用的启发式自适应的速率的决定传达给服务器，这允许客户端以期望的质量级别取得所有图块。 ","date":"2021-11-15","objectID":"/2021/11/note10/:2:2","tags":["Immersive Video"],"title":"沉浸式推流中应用层的优化","uri":"/2021/11/note10/"},{"categories":["Immersive Video"],"content":"最终的目标 主要的挑战是用户的临场感，这可以通过避免虚拟的线索来创造出接近真实的世界。 ","date":"2021-11-14","objectID":"/2021/11/note9/:1:0","tags":["Immersive Video"],"title":"沉浸式流媒体面临的挑战和启示","uri":"/2021/11/note9/"},{"categories":["Immersive Video"],"content":"具体的任务 从360度视频的采集到显示的过程中，引入了好几种失真。 应该重点增加新的拼接、投影和分包方式以减少噪音。 除了捕获和使用360度视频来表示真实世界和实际交互内容之外，环境中还包括3D对象。 3D对象的合并对于真实的视图而言是一个挑战。 因为在推流会话中，用户的头部移动高度可变，所以固定的tiling方案可能会导致非最优的viewport质量。 推流框架中的tile数量应该被动态选择，进而提高推流质量。 自适应的机制应该足够智能来根据环境因素精确地做出适应。 应该制定基于深度强化学习的策略，来给360度视频帧中不同区域的tile分配合适的比特率。 用户在360度视频中的自由导航很容易让其感觉忧虑自己错过了什么重要的东西。 在360度视频中导航的时候，需要支持自然的可见角度方向。 丰富的环境应配备新颖的定向机制，以支持360度视频，同时降低认知负荷，以克服此问题。 真实的导航依赖viewport预测机制。 现代的预测方式应该使用时空图像特性以及用户的位置信息，采用合适的编解码器卷积LSTM结构来减少长期预测误差。 沉浸式的场景随着用户的交互应该发生变化。 由于用户与场景的交互而产生的新挑战是通过编码和传输透视图创建的。 因此预测用户的行为来实现对交互内容的高效编码和推流非常关键。 对360度视频的质量获取方法和度量手段需要进一步研究。 360度视频中特殊的音效需要引起注意。 ","date":"2021-11-14","objectID":"/2021/11/note9/:2:0","tags":["Immersive Video"],"title":"沉浸式流媒体面临的挑战和启示","uri":"/2021/11/note9/"},{"categories":["Immersive Video"],"content":"背景 空间音频是一种全球状空间环绕的声音方式，采用多个声音通道来模拟现实世界中听到的声音。 360度视频由于空间音频而变得更加可靠，因为声音的通道特性使其能够穿越时间和空间。 360度视频显示系统在制作空间音频音轨方面的重要性无论怎样强调都不为过 ","date":"2021-11-14","objectID":"/2021/11/note8/:1:0","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"空间音频的再现技术 ","date":"2021-11-14","objectID":"/2021/11/note8/:2:0","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"物理重建 物理重建技术用于合成尽可能接近所需信号的整个声场。 立体声配置在最流行的声音再现方法中使用两个扬声器，以促进更多的空间信息（包括距离、方向感、环境和舞台合奏）。而多信道再现方法在声学环境中使用，并在消费类设备中流行。 多信道再现技术 同样的声压场也通过其他物理重建技术产生，如环境中存在的环境声学和波场合成（WFS）。 需要麦克风阵列来捕获更多的空间声场。 因为不能直接用于声场特性分析，麦克风记录的内容需要后期处理。 麦克风阵列用于语音增强、声源分离、回声消除和声音再现。 ","date":"2021-11-14","objectID":"/2021/11/note8/:2:1","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"感知重建 心理声学技术用于感知重建，以产生对空间声音特征的感知。 感知重建技术复制空间音频的自然听觉感受来表示物理音频。 双耳录制技术 双耳录制技术是立体声录制的一种扩展形式，提供3D的听觉体验。 双耳录制技术通过使用两个360度麦克风尽可能的复制人耳，这与使用定向麦克风捕捉声音的常规立体声录音相同。 假人头部的360度麦克风用作人耳的代理，因为它提供了耳朵的精确几何坐标。 假人头部还产生与人头轮廓相互作用的声波。借助360度麦克风，与任何其他记录方法相比，空间立体图像的捕获更精确。 头部相关传递函数（HRTF） 用于双耳音频的实时技术中，以再现复杂的线索，帮助我们通过过滤音频信号来定位声音。 多个因素（如耳朵、头部和听力环境）会影响线索，因为在现实中，我们会重新定位自己以定位声音。 选择合适的录音/重放技术对于使听到的声音与真实场景中的体验相同至关重要。 ","date":"2021-11-14","objectID":"/2021/11/note8/:2:2","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"环境声学 ","date":"2021-11-14","objectID":"/2021/11/note8/:3:0","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"概述 环境声学也被称为3D音频，被用于记录、混成和播放一个中心点周围的360度音频。 ","date":"2021-11-14","objectID":"/2021/11/note8/:3:1","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"区别 环境音频和传统的环绕声技术不同。 双声道和传统环绕声技术背后的原理是相同的，都是通过将声音信号送到特定的扬声器来创建音频。 环境音频不受任何特定扬声器的预先限制，因为它在即使音域旋转的情况下，也能创造出平滑的音频。 传统环绕声的格式只有在声音场景保持静态的情况下才能提供出色的成像效果。 环境音频提供一个完整的球体，将声音均匀地传播到整个球体。 ","date":"2021-11-14","objectID":"/2021/11/note8/:3:2","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"格式 环境音频有6种格式，分别为：A、B、C、D、E、G。 ","date":"2021-11-14","objectID":"/2021/11/note8/:3:3","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"用途 一阶环境音频的用途 第一阶的环境音频或B格式的环境音频，其麦克风用于使用四面体阵列表示线性VR。 此外，这些在四个通道中进行处理，例如提供非定向压力水平的“W”。同时，“X、Y和Z”分别促进了从前到后、从侧到侧以及从上到下的方向信息。 一阶环境音频仅适用于相对较小的场景，因为其有限的空间保真度会影响声音定位。 高阶环境音频的用途 高阶环境音频通过增加更多的麦克风来增强一阶环境音频的性能效率。 ","date":"2021-11-14","objectID":"/2021/11/note8/:3:4","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"总结 ","date":"2021-11-14","objectID":"/2021/11/note8/:4:0","tags":["Immersive Video"],"title":"360度视频的音频处理","uri":"/2021/11/note8/"},{"categories":["Immersive Video"],"content":"概述 在360度视频的推流过程中，根据用户头部的运动自适应地动态选择推流的区域，调整其比特率，以达到节省带宽的目的。 ","date":"2021-11-14","objectID":"/2021/11/note7/:1:0","tags":["Immersive Video"],"title":"自适应策略之viewport依赖型","uri":"/2021/11/note7/"},{"categories":["Immersive Video"],"content":"通常的实现方式 在服务端提供几个自适应集，来在遇到用户头部的突然运动的情况时，能保证viewport的平滑转换。 提出QER(Quality-focused Regios)的概念使viewport内部的视频分辨率高于viewport之外的视频分辨率。 非对称的方式以不同的空间分辨率推流来节省带宽。 在播放过程中，客户端根据用户的方向来请求不同分辨率版本的视频。 优点是即使客户端对用户的方面做了错误预测，低质量的内容仍然可以在viewport中生成。 缺点是在大多数场景下，这种方案需要巨大的存储开销和处理负载。 ","date":"2021-11-14","objectID":"/2021/11/note7/:2:0","tags":["Immersive Video"],"title":"自适应策略之viewport依赖型","uri":"/2021/11/note7/"},{"categories":["Immersive Video"],"content":"自适应推流参数 可用带宽和网络吞吐量 Viewport预测的位置 客户端播放器的可用缓冲 ","date":"2021-11-14","objectID":"/2021/11/note7/:3:0","tags":["Immersive Video"],"title":"自适应策略之viewport依赖型","uri":"/2021/11/note7/"},{"categories":["Immersive Video"],"content":"参数计算公式 第n个估计的Viewport：$V^e(n)$ $V^e(n) = V_{fb}$ $V_{fb}$是最新报告的viewport位置 第n个估计的吞吐量：$T^e(n)$ $T^e(n) = T_{fb}$ $T_{fb}$是最新报告的吞吐量 比特率：$R_{bits}$ $R_{bits} = (1-\\beta)T^e(n)$ $\\beta$是安全边缘 第n个帧的客观度量质量：$VQ(k)$和最终客观度量质量$VQ$ $VQ=\\frac{1}{L}\\sum^L_{k=1}VQ(k)$ $VQ(k) = \\sum_{t=1}^{T^n}w_k(k) * D^n_t(V_t, k)$ $w_k = \\frac{A(t,k)}{A_{vp}}$ $L=总帧数$ $w_k$表示在第k个帧中与viewport所重叠的tile程度 $A(t,k)$表示第k个帧中tile $t$ 重叠的区域 $A_{vp}$表示viewport中总共的区域 ","date":"2021-11-14","objectID":"/2021/11/note7/:4:0","tags":["Immersive Video"],"title":"自适应策略之viewport依赖型","uri":"/2021/11/note7/"},{"categories":["Immersive Video"],"content":"OMAF(Omnidirectional Media Format) OMAF是第1个国际化的沉浸式媒体格式，描述了对360度视频进行编码、演示、消费的方法。 OMAF与与现有格式兼容，包括编码（例如HEVC），文件格式（例如ISOBMFF），交付信号（例如DASH，MMT）。 OMAF中还包括编码、投影、分包和viewport方向的元数据。 ","date":"2021-11-11","objectID":"/2021/11/note6/:1:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"OMAF+DASH-\u003eMPD OMAF与DASH相结合，再加上一些额外的描述构成了MPD文件格式，用于向客户端通知360度媒体的属性。 OMAF规定了9中媒体配置文件，包括3种视频配置文件：基于HEVC的viewport独立型、基于HEVC的viewport依赖型、基于AVC的viewport依赖型。 OMAF为视角独立型的推流提供了无视viewport位置的连续的视频帧质量。 常规的HEVC编码方式和DASH推流格式可以用于viewport独立型的推流工作。 但是使用HEVC/AVC编码方式的基于viewport的自适应操作是OMAF的一项技术开发，允许无限制地使用矩形RWP来增强viewport区域的质量。 ","date":"2021-11-11","objectID":"/2021/11/note6/:2:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"CMAF(Common Media Application Format) 致力于提供跨多个应用和设备之间的统一的编码格式和媒体配置文件。 CMAF使请求低延迟的segment成为可能。 ","date":"2021-11-11","objectID":"/2021/11/note6/:3:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"ISOBMFF(ISO Base Media File Format) ISOBMFF是用于定时数据交换、管理和显示的最流行的文件格式。 文件由一系列兼容并且可扩展的文件级别的box组成。 每个box表示1个由4个指针字符代码组成的数据结构。 ISOBMFF的媒体数据流和元数据流被分别分发。 媒体数据流中包括编码过的音频和视频数据。 元数据流中包括媒体类型、编码属性、时间戳、大小等元数据，也包括全向内容的额外信息如投影格式、旋转、帧分包、编码和分发等元数据。 ISOBMFF为了访问方便，保证有价值信息能灵活聚合。 ","date":"2021-11-11","objectID":"/2021/11/note6/:4:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"3DoF(3 Degree of Freedom) 在3DoF场景中，用户可以自由的移动头部以三个方向：摆动、俯仰、旋转。 ","date":"2021-11-11","objectID":"/2021/11/note6/:5:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"3DoF+ 用户的头部可以以任意方向移动：上下、左右、前后 ","date":"2021-11-11","objectID":"/2021/11/note6/:6:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"6DoF 不只用户的头部，用户的身体也是自由的。同时支持方向与位置的自由。 ","date":"2021-11-11","objectID":"/2021/11/note6/:7:0","tags":["Immersive Video"],"title":"沉浸式流媒体现有标准","uri":"/2021/11/note6/"},{"categories":["Immersive Video"],"content":"背景 用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。 沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的消极影响。 目前主要面临的挑战有以下4个： ","date":"2021-11-04","objectID":"/2021/11/note5/:0:0","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"Viewport预测 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:0","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"背景 HMD的本质特征是快速响应用户头部的移动。当用户改变viewport时HMD处理交互并检测相关的viewport来精确播放器的信息，这样视野就能以正常的可视角度被提供给用户。Viewport预测在优化的360度视频推流中非常必要。配备有位置传感器的可穿戴HMD允许客户端更新其视角方向相应的视角场景。 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:1","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"分类 内容不可知的方式基于历史信息对viewport进行预测。 内容感知的方式需要视频内容信息来预测未来的viewport。 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:2","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"内容不可知方式 分类 平均线性回归LR 航位推算DR 聚类 机器学习ML 编解码器体系结构 现有成果 Qian’s work——LR 使用平均线性回归和加权线性回归模型来做viewport预测，之后对与预测区域重叠的tile进行整体推流。 当预测后0.5s、1s、2s加权线性回归表现更好 Petrangeli’s work——LR 将被划分成tile的等矩形的帧分成3个区域：viewport区、相邻区、其他区。 结合观察者头部的移动，将可变比特率分配给可见和不可见区域。 作者利用最近（100毫秒）用户观看历史的线性外推来预测未来的注视点。 Mavlankar and Girod’s work——运动向量 使用运动向量比如观察者的平移、倾斜、缩放等方向上的速度和加速度，来执行视角区域预测。 La Fuente’s work——运动向量 考虑了两种预测变体：角速度和角加速度，从用户以前的方向数据来估计未来的头部方向。按照预测结果分配不同的量化参数到每个tile上。 当进行进一步的预测时（超过2s），这种方式限制了预测的精度。 如果视频tile被基于错误的预测而被请求，用户的实际viewport可能会被没有请求因而没有内容的黑色tile所覆盖。 Ban’s work——KNN+LR 使用KNN算法利用跨用户观看历史，使用LR模型利用户个体化的行为。 就视角预测的准确率而言，分别取得了20%和48%的绝对和相对改进。 Liu’s work——cluster 提出了使用数据融合方法，通过考虑几个特征来估计未来视角位置。特征例如：用户的参与度、用户观看同一视频的行为、单个用户观看多个视频的行为、最终用户设备、移动性水平。 Petrangeli’s work——cluster 基于车辆轨迹预测的概念，考虑了类似的轨迹形成一个簇来预测未来的viewport。 结果表明这种方法为更长的视野提高了精确度。 检查了来自三个欧拉角的不同轨迹，这样做可能导致性能不足。 Rossi’s work——cluster 提出了一种聚类的方法，基于球形空间中有意义的viewport重叠来确认用户的簇。 基于Bron-Kerbosch（BK）算法的聚类算法能够识别大量用户，这些用户观看的是相同的60%的3s长球形视频块。 与基准相比，该方法为簇提供了可兼容且重要的几何viewport重叠。 Jiang’s work 背景： LR方法对于长期的预测视野会导致较差的预测精度。长短时记忆（LSTM）是一种递归神经网络（RNN）架构，适用于序列建模和模式开发。 方法： 为了在FoV预测中获取比LR方法更高的精确度，开发了一种使用带有128个神经元的LSTM模型的viewport预测方法。 分析了360度数据集，观察到用户在水平方向头部有快速转向，但是在垂直方向几乎是稳定的。 实验表明，这种方法同时考虑水平和垂直方向的头部移动时，比LR等方法产生了更少的预测错误。 Bao’s work 背景： 对150个用户进行了16个视频剪辑的主观实验，并对其行为进行了分析。 使用3个方向的欧拉角$\\theta$, $\\phi$, $\\psi$来表示用户在3D空间中头部的移动，结果表明不同方向的动作有强自相关性和消极的互相关性。因此多个角度的预测可以分开进行。 方法： 开发两个独立的LSTM模型来分别预测$\\theta$和$\\phi$，之后将预测结果应用于目标区域流来有效利用可用网络资源。 Hou’s work 提出一种基于深度学习的视角产生方法来只对提前预测的360度视频和3自由度的VR应用的viewport tile进行抽取和推流。（使用了大规模的数据集来训练模型） 使用包含多层感知器和LSTM模型来预测6自由度的VR环境中头部乃至身体的移动，预测的视野被预渲染来做到低延迟的VR体验。 Heyse’s work 背景： 在某些例子中，用户的移动在视频的不同部分中非常不稳定。这增加了机器学习方式的训练压力。 方法： 提出了一个基于RL模型的上下文代理，这个模型首先检测用户的显著移动，然后预测移动的方向。这种分层自学习执行器优于球形轨迹外推法（这种方法将用户运动建模为轨迹的一部分，而不是单位球体上的完整轨迹） Qian’s work 提出了一种叫做Flare的算法来最小化实际viewport和预测viewport之间的不匹配。 应用了一种ML方法来执行频繁的viewport预测，包括从130名用户收集的1300条头部运动轨迹的4个间隔。 使用viewport轨迹预测，Flare可以将错误预测替换成最新预测。 Yu and Liu’s work 背景： LSTM网络本身具有耗时的线性训练特性。编解码器的LSTM模型把训练过程并行化，相比于LR和LSTM本身而言，改善了预测精度。 方法： 使用基于注意力的LSTM编解码器网络体系结构来避免昂贵的递归并能更好地捕获viewport变化。 提出的体系结构相比于传统的RNN，获得了更高的预测精度，更低的训练复杂度和更快的收敛。 Jamali’s work 提出使用LSTM编解码器网络来做长期的viewport预测（例如3.5s）。 收集了低延迟异质网络上跨用户的方向反馈来调整高延迟网络上目标用户的预测性能。 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:3","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"内容感知方式 背景 内容感知方式可以提高预测效率。 具体方法 Aladagli’s work 提出了一个显著性驱动的模型来提高预测精度。 没有考虑用户在360度视频中的视角行为。 viewport预测错误可以通过理解用户对360度视频独特的可见注意力最小化。 Nguyen’s work 背景： 大多数现存的方法把显著性图看作是360度显示中的位置信息来获得更好的预测结果。 通用的显著性和位置信息体系结构基于固定预测模型。 方法： 提出了PanoSalNet来捕获用户在360度帧中独特的可见注意力来改善显著性检测的性能。 同时使用HMD特性和显著性图的固定预测模型获得了可测量的结果。 Xu’s work 提出了两个DRL(Deep Reinforcement Learning)模型用于同时考虑运动轨迹和可见注意力特性的viewport预测网络。 离线模型基于内容流行度检测每个帧里的显著性。 在线模型基于从离线模型获得的显著性图和之前的viewport预测信息预测viewport方向和大小。 这个网络只能预测30ms的下一个viewport位置。 Xu’s work 收集了大规模的被使用带有眼部轨迹跟踪的HMD的45个观测者观察的动态360度视频数据集，提出了基于历史扫描路径和图像特征预测注视位移的方法。 在与当前注视点、viewport和整个图像相关的三个空间尺度上执行了显著性计算。 可能的图像特性被通过向CNN喂图像和相应的显著性图，同时LSTM模型捕获历史信息来抽取出来。 之后将LSTM和CNN特性耦合起来，用于下一次的用户注视信息预测。 Fan’s work 用户更容易被运动的物体吸引，因此除了显著性图之外，Fan等人也考虑了使用预训练 的CNN来估计用户未来注视点的内容运动图。 由于可能存在多个运动，这让预测变得不可靠，因此运动贴图的开发还需要进一步的研究。 Yang’s work 使用CNN模型基于历史观测角度信息预测了单viewport。 接着考虑了一种使用内容不可知和内容感知方法如RNN和CFVT模型的融合层的viewport轨迹预测策略。 融合模型使其同时支持更好地预测并且提高了大概40%的精度。 Ozcinar’s work 将viewport轨迹转换为基于viewport的视觉注意图，然后对不同大小的tile进行推流以保证更高的编码效率。 Li’s work 现有的预测模型对未来的预测能力有限，Li等人提出了两种模型，分别用于viewport相关和基于tile的推流系统。 第一个模型应用了基于用户轨迹的LSTM编解码网络体系结构。 第二个模型应用了卷积LSTM编解码体系结构，使用序列的热图来预测用户的未来方向。 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:4","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"总结 精确的方向预测使360度视频的客户端可以以高分辨率下载最相关的tile。 当前采用显著性和位置信息的神经网络模型的性能比直接利用当前观察位置进行未来viewport位置估计的简单无运动的基线方法表现差。估计的显著性中的噪音等级限制了这些模型的预测精度。并且这些模型也引入了额外的计算复杂度。 对于360度视频注意点的可靠预测和用户观看可能性与显著性图之间关系的理解，显著性模型必须被改善并通过训练大规模的数据集来适应，尤其是被配备了不同摄像机旋转的镜头所捕获的数据。 另一方面，卷积LSTM编解码器和基于轨迹的预测方法适合长期预测，并能带来相当大的QoE改进，特别是在协作流媒体环境中。 ","date":"2021-11-04","objectID":"/2021/11/note5/:1:5","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"QoE评估 ","date":"2021-11-04","objectID":"/2021/11/note5/:2:0","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"背景 由于全方位视频非常普遍，因此，通过这种类型的视频分发来确定用户的特定质量方面是至关重要的。QoE在视频推流应用中扮演着重要角色。在传统视频推流中，QoE很大程度上被网络负载和分发性能所影响。现有的次优目标度量方法并不适用于全向视频，因为全向视频受网络状况和用户视角行为的影响很大。 ","date":"2021-11-04","objectID":"/2021/11/note5/:2:1","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"主观质量评估 主观质量评估是估计360度视频推流质量的现实并且可靠的方法。 Upenik’s work 用一台MergeVR HMD执行了主观测试来体验360度图像。 实验数据包括主观分数、视角轨迹、在每个图像上花费的时间由软件上获得。 视角方向信息被用于计算显著性图。 但是这项研究没有考虑对360度视频的评估。 Zhang’s work 为了弥补360度视频和常规视频度量方式之间的性能差距，为全景视频提出了一种主观质量评估方法，称为SAMPVIQ。 23位参与者被允许观看4个受损视频，整体视频质量体验的评分在0～5分之间。 参与者之间存在较大的评分差异。 Xu’s work 提出两种主观测量方式：总体区分平均意见分数(O-DMOS)和矢量区分平均意见分数(V-DMOS)来获得360度视频的质量损失。 类似于传统食品的DMOS度量方式，O-DMOS度量方式计算主观测试序列的总计区分分数。 Schatz’s work 研究了使用HMD观看360度内容时停顿事件的影响。 沉浸式内容的主观质量评估并非不重要，可能导致比实际推荐更多的开放性问题。 通常来讲人们的期望于传统的HAS相似，即如果可能的话，根本没有停顿。 可用的开源工具 AVTrack360，OpenTrack和360player能捕获用户观看360度视频的头部轨迹。 VRate是一个在VR环境中提供主观问卷调查的基于Unity的工具。 安卓应用*MIRO360*，支持未来VR主观测试的指南开发。 Cybersickness Cybersickness是一种获得高QoE的潜在障碍，它能引起疲劳、恶心、不适和呕吐。 Singla’s work 使用受限的带宽和分辨率，在不同的延迟情况下进行了两个主观实验。 开发了主观测试平台、测试方法和指标来评估viewport自适应360度视频推流中的视频感知等级和Cybersickness。 基于tile的推流在带宽受限的情况下表现很好。 47ms的延迟实际上不影响感知质量。 Tran’s work 考虑了几个影响因子例如内容的空间复杂性，数量参数，分辨率特性和渲染模型来评估cybersickness，质量，可用性和用户的存在。 VR环境中快速移动的内容很容易引发cybersickness。 由于高可用性和存在性，用户的cybersickness也可能加剧。 Singla’s work 评估了28名受试者在Oculus Rift和HTC Vive头戴式电脑上观看6个全高清和超高清分辨率YouTube视频时的观看不适感。 HMD的类型轻微地影响感知质量。 分辨率和内容类型强烈影响个人体验。 女性用户感到cybersickness的人数更多。 空间存在感 空间存在感能增强沉浸感。 Zou’s work 方法： 提出了一个主观框架来测量25名受试者的空间存在感。 提出的框架包括三层，从上到下分别为：空间存在层、感知层、科技影响层。 心理上的空间存在感形成了空间存在层。 感知层以视频真实感、音频真实感和交互元素为特征。 科技影响层由几个模块组成，这些模块与感知层相连，以反映传感器的真实性。 Hupont’s work 应用通用感知的原则来研究在Oculus HMD和传统2D显示器上玩游戏的用户的空间存在感。 与2D显示器相比，3D虚拟现实主义显示出更高的惊奇、沉浸感、存在感、可用性和兴奋感。 生理特征度量 Salgado’s work 方法： 捕获多种多样的生理度量，例如心率HR，皮肤电活性EDA、皮肤温度、心电图信号ECG、呼吸速率、血压BVP、脑电图信号EEG来评价沉浸式模拟器的质量。 Egan’s work 基于HR和EDA信号评估VR和非VR渲染模式质量分数。 相比于HR，EDA对质量分数有强烈的影响。 技术因素感知 不同的技术和感知特征，如失真、清晰度、色彩、对比度、闪烁等，用于评估感知视频质量。 Fremerey’s work 确定了可视质量强烈地依赖于应用的运动插值（MI）算法和视频特征，例如相机旋转和物体的运动。 在一项主观实验中，12位视频专家回顾了使用FFmpeg混合、FFmpeg MCI（运动补偿插值）和butterflow插值到90 fps的四个视频序列。作者发现，与其他算法相比，MCI在QoE方面提供了极好的改进。 总结 主观测试与人眼直接相关，并揭示了360度视频质量评估的不同方面的影响。 在这些方面中，空间存在感和由佩戴VR头戴设备观看360度视频导致的cybersickness极为重要，因为这些效果并不在传统的2D视频观看中出现。 主观评估需要综合的手工努力并因此昂贵耗时并易于出错，相对而言，客观评估更易于管理和可行。 ","date":"2021-11-04","objectID":"/2021/11/note5/:2:2","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"客观质量评估 由于类似的编码结构和2D平面投影格式，对360度内容应用客观质量评估很自然。 计算PSNR 现有投影方式中的采样密度在每个像素位置并不均匀。 Yu’s work 为基于球形的PSNR计算引入S-PSNR和L-PSNR。 S-PSNR通过对球面上所有位置的像素点做同等加权来计算PSNR。 利用插值算法，S-PSNR可以完成对支持多种投影模式的360度视频的客观质量评估。 L-PSNR通过基于纬度和访问频率的像素点加权测量PSNR。 L-PSNR可以测量viewport的平均PSNR而无需特定的头部运动轨迹。 Zakharchenko’s work 提出了一种Craster Parabolic Projection-PSNR (CPP-PSNR) 度量方式来比较多种投影方案，通过不改变空间分辨率和不计算实际像素位置的PSNR，将像素重新映射成CPP投影。 CPP投影方式可能使视频分辨率大幅下降。 Sun’s work 提出了一种叫做weighted-to-spherically-uniform PSNR (WS-PSNR)的质量度量方式，以此来测量原始和受损内容之间的质量变化。 根据像素在球面上的位置考虑权重。 计算SSIM SSIM是另一种质量评估指标，它通过三个因素反映图像失真，包括亮度、对比度和结构。 Chen’s work 为2D和360度视频分析了SSIM结果，引入了球型结构的相似性度量（S-SSIM）来计算原始和受损的360度视频之间的相似性。 在S-SSIM中，使用重投影来计算两个提取的viewport之间的相似性。 Zhou’s work 考虑相似性的权重提出了WS-SSIM来测量投影区域中窗口的相似性。 性能评估表明，与其他质量评估指标相比，WS-SSIM更接近人类感知。 Van der Hooft’s work 提出了ProbGaze度量方式，基于tile的空间尺寸和viewport中的注视点。 考虑外围tile的权重来提供合适的质量测量。 相比于基于中心和基于平均的PSNR和SSIM度量方式，ProbGaze能估计当用户突然改变viewport位置时的视频质量变化。 Xu’s work 引入了两种客观质量评估度量手段：基于内容感知的PSNR和非内容感知的PSNR，用于编码360度视频。 第一种方式基于空间全景内容对像素失真进行加权。 第二种方式考虑人类偏好的统计数据来估计质量损失。 基于PSNR和SSIM方式的改进 尽管各种基于PSNR和SSIM的方式被广阔地应用到了360度视频的质量评估中，但这些方式都没有真正地捕获到感知质量，特别是当HMD被用于观看视频时。因此需要为360度内容特别设计一种优化的质量度量方式。 Upenik’s work 考虑了一场使用4张高质量360度全景图像来让45名受试者在不同的编码设定下评估和比较客观质量度量方式性能的主观实验。 现有的客观度量方式和主观感知到的质量相关性较低。 Tran’s work 论证主观度量和客观度量之间相关性较高，但是使用的数据集较小。 基于ML的方式 基于ML的方式可以弥补客观评估和主观评估之间的差距。 Da Costa Filho’s work 提出了一个有两个阶段的模型。 首先自适应VR视频的播放性能由机器学习算法所确定。 之后模型利用估计的度量手段如视频质量、质量变化、卡顿时间和启动延迟来确定用户的QoE。 Li’s work 引入了基于DRL的质量获取模型，在一次推流会话中同时考虑头部和眼部的移动。 360度视频被分割成几个补丁。 低观看概率的补丁被消除。 参考和受损视频序列都被输入到深度学习可执行文件中，以计算补丁的质量分数。 之后分数被加权并加到一起得到最终的分数。 Yang’s work 考虑了多质量等级的特性和融合模型。 质量特性用region of interest(ROI)图来计算，其中包括像素点等级、区域等级、对象等级和赤道偏差。 混合模型由后向传播的神经网络构造而成，这个神经网络组合了多种质量特性来获取整体的质量评分。 ","date":"2021-11-04","objectID":"/2021/11/note5/:2:3","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"总结 精确的QoE获取是优化360度视频推流服务中重要的因素，也是自适应分发方案中基础的一环。 单独考虑VR中的可视质量对完整的QoE框架而言并不足够。 为能获得学界的认可，找到其他因素的影响也很必要，例如cybersickness，生理症状，用户的不适感，HMD的重量和可用性，VR音频，viewport降级率，网络特性（延迟，抖动，带宽等），内容特性（相机动作，帧率，编码，投影等），推流特性（viewport偏差，播放缓冲区，时空质量变化等）。 ","date":"2021-11-04","objectID":"/2021/11/note5/:2:4","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"低延迟推流 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:0","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"背景 360度全景视频推流过程中的延迟由几部分组成：传感器延迟、云/边处理延迟、网络延迟、请求开销、缓冲延迟、渲染延迟和反馈延迟。 低延迟的要求对于云VR游戏、沉浸式临场感和视频会议等更为严格。 要求极低的终端处理延迟、快速的云/边计算和极低的网络延迟来确保对用户头部移动做出反馈。 现代HMD可以做到使传感器延迟降低到用户无法感知的程度。 传输延迟已经由5G移动和无线通信技术大幅减少。 但是，对于减少处理、缓冲和渲染延迟的工作也是必要的。 许多沉浸式应用的目标是MTP的延迟少于20ms，理想情况是小于15ms。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:1","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"减少启动时间 减少初始化请求的数据量 通常来讲，较小的视频segment能减少启动和下载时间。 Van der Hooft’s work 考虑了新闻相关内容的推流，使用的技术有： 服务端编码 服务端的用户分析 服务器推送策略 客户端积极存储视频数据 取得的效果： 降低了启动时间 允许不同网络设定下的快速内容切换 较长的响应时间降低了性能 Nguyen’s work 基于viewport依赖的自适应策略分析了自适应间隔延迟和缓冲延迟的影响。 使用服务端比特率计算策略来最小化响应延迟的影响。 根据客户端的响应估计可用的网络吞吐量和未来的viewport位置。 服务端的决策引擎推流合适的tile来满足延迟限制。 取得的效果： 对于viewport依赖型推流方案而言，较少的自适应和缓冲延迟不可避免。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:2","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"降低由tile分块带来的网络负载 在HTTP/1.1中，在空间上将视频帧分成矩形tile会增加网络负载，因为每个tile会产生独立的网络请求。 请求爆炸的问题导致了较长的响应延迟，但是可以通过使用HTTP/2的服务器推送特性解决。这个特型使服务器能使用一条HTTP请求复用多条消息。 Wei’s work 利用HTTP/2协议来促进低延迟的HTTP自适应推流。 提出的服务端推送的策略使用一条请求同时发送几个segment避免多个GET请求。 Petrangeli’s work 结合特定请求参数与HTTP/2的服务端推送特性来促进360度视频推流。 客户端为一个segment发送一条call，服务器使用FCFS策略传送k个tile。 利用HTTP/2的优先级特性可以使高优先级的tile以紧急的优先级被获取，进而改善网络环境中的高往返时间的性能。 Xu’s work 为360度内容采用了k-push策略：将k个tile推送到客户端，组成一个单独的时间段。 提出的方法与QoE感知的比特率自适应算法一起，在不同的RTT设定下，提高了20%的视频质量，减少了30%的网络传输延迟。 Yahia’s work 使用HTTP/2的优先级和多路复用功能，在两个连续的viewport预测之间，即在交付相同片段之前和期间，组织紧急视频块的受控自适应传输。 Yen’s work 开发了一种支持QUIC的体系结构来利用流优先级和多路复用的特性来实现360度视频的安全和低优先级的传输。 当viewport变化发生时，QUIC能让常规的tile以低优先级推流，viewport内的tile以高优先级推流，都通过一条QUIC连接来降低viewport tile的缺失率。 作者说测试表明基于QUIC的自适应360度推流比HTTP/1.1和HTTP/2的方案表现更好。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:3","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"使用移动边缘计算降低延迟 Mangiante’s work 提出了利用基于边缘处理的viewport渲染方案来减少延迟，同时利用终端设备上的电源和计算负载。 但是作者没有给出有效的算法或是建立一个实践执行平台。 Liu’s work 采用远端渲染技术，通过为不受约束的VR系统获取高刷新率来隐藏网络延迟。 采用60GHz的无线链路支持的高端GPU，来加快计算速度和4K渲染，减少显示延迟。 尽管提供了高质量和低延迟的推流，但是使用了昂贵的带宽连接，这通常并不能获得。 Viitanen’s work 引入了端到端的VR游戏系统。通过执行边缘渲染来降低延迟，能源和计算开销。 为1080p 30fps的视频格式实现了端到端的低延迟（30ms）的系统。 前提是有充足的带宽资源、终端设备需要性能强劲的游戏本。 Shi’s work 考虑了不重视viewport预测的高质量360度视频渲染。 提出的MEC-VR系统采用了一个远端服务器通过使用一个自适应裁剪过滤器来动态适应viewport覆盖率，这个过滤器按照观测到的系统延迟增加viewport之外的区域。 基于viewport覆盖率的延迟调整允许客户端容纳和补偿突然的头部移动。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:4","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"共享VR环境中的延迟处理 共享VR环境中用户的延迟取决于用户的位置和边缘资源的分发。 Park’s work 通过考虑多个用户和边缘服务器之间的双向通信，提出了一种使用线性蜂窝拓扑中的带宽分配策略，以最小化端到端系统延迟。确定了推流延迟强烈地依赖于： 边缘服务器的处理性能 多个交互用户之间的物理和虚拟空间 Perfecto’s work 集成了深度神经网络和毫米波多播传输技术来降低协同VR环境中的延迟。 神经网络模型估计了用户即将来临的viewport。 用户被基于预测的相关性和位置分组，以此来优化正确的viewport许可。 执行积极的多播资源调度来最小化延迟和拥塞。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:5","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"总结 在单用户和多用户的环境中，边缘辅助的解决方式对于控制延迟而言占主要地位。 此外还有服务端的viewport计算、服务端push机制和远程渲染机制都能用于低延迟的控制。 现有的4G网络足以支持早期的自适应沉浸式多媒体，正在成长的5G网络更能满足沉浸式内容的需求。 ","date":"2021-11-04","objectID":"/2021/11/note5/:3:6","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"360度直播推流 ","date":"2021-11-04","objectID":"/2021/11/note5/:4:0","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"背景 传统的广播电视频道是直播推流的流行来源。现在私人的360度直播视频在各个社交媒体上也有大幅增长。 因为视频生产者和消费者之间在云端的转码操作，360度视频推流是更为延迟敏感的应用。 现有的处理设备在诸如转码、渲染等实时处理任务上受到了限制。 内容分发 Hu’s work 提出了一套基于云端的直播推流系统，叫做MELiveOV，它使高分辨率的全向内容的处理任务以毛细管分布的方式分发到多个支持5G的云端服务器。 端到端的直播推流系统包括内容创作模块、传输模块和viewport预测模块。 移动边缘辅助的推流设计减少了50%的带宽需求。 Griwodz’s work 为360度直播推流开发了优化FoV的原型，结合了RTP和基于DASH的pull-patching来传送两种质量等级的360度视频给华为IPTV机顶盒和Gear VR头戴设备。 作者通过在单个H.265硬件解码器上多路复用多个解码器来实现集体解码器的想法，以此减少切换时间。 视频转码 Liu’s work 研究表明只转码viewport区域有潜力大幅减少高性能转码的计算需求。 Baig’s work 开发了快速编码方案来分发直播的4K视频到消费端设备。 采用了分层视频编码的方式来在高度动态且不可预测的WiGig和WiFi链路上分发质量可变的块。 Le’s work 使用RTSP网络控制协议为CCTV的360度直播推流提出了实时转码和加密系统。 转码方式基于ARIA加密库，Intel媒体SDK和FFmpeg库。 系统可以管理并行的转码操作，实现高速的转码性能。 内容拼接缝合 相比于其他因素如捕获、转码、解码、渲染，内容拼接在决定整体上的推流质量时扮演至关重要的角色。 Chen’s work 提出了一种内容驱动的拼接方式，这种方式将360度帧的语义信息的不同类型看作事件，以此来优化拼接时间预算。 基于VR帧中的语义信息，tile执行器模块选择合适的tile设计。 拼接器模块然后执行基于tile的拼接，这样，基于可用资源，事件tile有更高的拼接质量。 评估表明系统通过实现89.4%的时间预算，很好地适应了不同的事件和时间限制。 ","date":"2021-11-04","objectID":"/2021/11/note5/:4:1","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"总结 相比于点播式流媒体，360度直播推流面临多个挑战，例如在事先不知情的情况下处理用户导航、视频的首次流式传输以及实时视频的转码。在多用户场景中，这些挑战更为棘手。 关于处理多个用户的观看模式，可伸缩的多播可以用于在低带宽和高带宽网络上以接近于按需推流的质量等级。 基于ROI的tile拼接和转码可以显著地减少延迟敏感的交互型应用的延迟需求。 ","date":"2021-11-04","objectID":"/2021/11/note5/:4:2","tags":["Immersive Video"],"title":"自适应360度视频推流挑战","uri":"/2021/11/note5/"},{"categories":["Immersive Video"],"content":"概况 现有的沉浸式流媒体应用都对带宽、QoS和计算需求有着高要求，这主要得益于5G网络。 传统的中心化云计算和云存储体系结构不适于实时的高码率内容分发。 边缘缓存和移动边缘计算成为了推动沉浸式流媒体发展的关键技术。 解决方案 ","date":"2021-10-30","objectID":"/2021/10/note4/:0:0","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Immersive Video"],"content":"360度视频的边缘协助推流 ","date":"2021-10-30","objectID":"/2021/10/note4/:1:0","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Immersive Video"],"content":"背景 主要的视频内容可以被传送到边缘节点乃至下游客户端来满足高分辨率等级和严格的低延迟要求。 在边缘计算中，处理和存储的任务被从核心网转移到边缘节点例如基站、微型数据中心和机顶盒等。 Hou’s work 提出边缘/云服务器渲染可以使计算更加轻便，可以让无线VR/AR体验可行并且便携。 Zhang’s work 为VR多人游戏提出了一种混合边缘云基础架构，中心云负责更新全局游戏事件，边缘云负责管理视图更新和大规模的帧渲染任务，以此来支持大量的在线联机人数的低延迟游戏。 进一步陈述了一种服务器选择算法，它基于QoS和玩家移动的影响确保所有VR玩家之间的公平性。 Lo’s work 考虑了为360度视频渲染提供边缘协助的设备的异质性。 边缘服务器将 HEVC tile流转码为viewport视频流并传输到多个客户端。 最优化算法根据视频质量、HMD类型和带宽动态决定边缘节点服务哪个客户端。 边缘缓存策略 背景 传统视频的缓冲方案并不能直接应用到360度视频上。 为了在启用边缘缓存的网络中促进360度视频的传输，两个传输节点之间的代理缓存被部署来使用户侧的内容可用。 边缘缓存能从实质上减少重复的传输并且可以使内容服务器更加可扩展。 Mahzai’s work 基于其他用户的观看行为为360度视频的流行内容提出了一种缓存策略。 与最不常用 (LFU) 和最近最少使用 (LRU) 缓存策略相比，在缓存使用方面的性能分别提高了至少 40% 和 17%。 Papaioannou’s work 提出了基于tile分辨率和需求统计信息的缓存策略，用最少的错误，提高要求tile的和缓存tile这两种版本的viewport覆盖率。 不同缓存和传输延迟的实验评估表明提高了缓存命中率，特别是对于分层编码的tile。 Liu’s work 背景： 边缘缓存可以被在Evolved Packet Core处执行，因为packet大小很小所以这样可能会产生次优的性能。 另一种替换的方式是在Radio Access Network处缓存数据。但这样由于数据隧道和分包会变得更加复杂。 研究内容： 为移动网络提出了一种同时使用RAN和EPC的基于tile的缓存方案，以此在视频流延迟的约束下节省传输带宽。 为EPC和RAN的缓存节点分别被部署在Packet Data Network Gateway和eNodeBs。 EPC中的内容控制实体负责为tile内容改善缓存利用率。 这种联合的tile缓存设计能以优秀的可伸缩性为回程网络显著地减少带宽压力。 Maniotis’s work 为了利用协作传输的机会，提出了一种在包含宏蜂窝基站(MBS)和多个小基站(SBS)的蜂窝网络中的tile级别的视频流行度感知缓存和传输方案。 应用了一种高级的编码方式来创建灵活的tile编码结构，使在每个SBS中能协同缓存。 这种协同允许在 SBS 只存储可能被观看的图块，而其他图块可以通过回程链路获取。 Chen’s work 为被捕获内容从Drone base station到小基站的联合缓存和分发提出了一种echo-liquid状态的 DRL 模型，使用高频毫米波通信技术。 为了满足即时延迟的目标，基站可以从数据中缓存流行内容。 但是，小基站的广泛部署实际上消耗了很多能源。 Yang’s work 在计算资源受限制的MEC架构中，利用缓存和计算资源来降低对通信资源的要求。 但是这种结构需要资源敏感的任务调度来平衡通信开销和延迟。 Chakareski’s work 为multi-cell网络环境中的AR/VR应用探索了最前沿的缓存、计算和通信机制。 提出的框架允许基站利用适当的计算和缓存资源来最大化总计的回报。 只关注了缓存和渲染，没有考虑用户视角的感受以及处理事件。 Sun’s work 在内容到达终端之前，同时利用FoV(Field of View)缓存和必要的计算操作来节省通信带宽而不牺牲响应时间。 对于同质的FoVs，联合缓存和计算框架执行关于缓存和后期处理的最优决策。 对于异质的FoVs，应用凹凸表达式来得到有吸引力的结果。 Rigazzi’s work 基于一个开源项目Fog05提出了一个三层(3C)解决方案来分发密集的任务（例如编解码和帧重建），穿越中心云层，受约束的雾层和边缘节点层。 利用了系统可伸缩性、互操作性和360度视频推流服务的生命周期循环。 实验性的评估表明在带宽、能源消耗、部署开销和终端复杂性方面取得了显著的减少。 Elbamby’s work 通过在延迟和可靠性的约束下，应用积极的计算和毫米波传输，为交互式的VR游戏提出了一个联合框架。 对视频帧做预计算和存储来减少VR流量。 评估表明这种联合机制可以减少多达30%的端到端延迟。 边缘计算的优势 减少延迟 传统的云端节点距离用户较远，边缘计算使用户可以共享多个服务器池的协同计算资源。 降低能耗 根据网络架构和资源供应将计算卸载到分布式计算集群，能显著提高移动设备的性能。 负载均衡 边缘节点例如基站、小蜂窝和终端设备可以在用户端存储内容，降低了核心网的负载。 现有利用边缘计算的解决方案 大多数任务卸载的MEC方案只致力于优化带宽、能源或延迟。 发展中的方案同时致力于许多其他重要的目标：可靠性、可移动性、QoS、部署成本、安全性。 利用带缓存的边缘计算的能力可以增强可移动性、位置感知能力、高效的数据分发、网络上下文理解和提供服务的安全性。 层级化的边缘-云体系结构对于适应360度视频快速动态传输是必要的。 相比于单静态层，多个动态缓存模型可以帮助管理唐突的viewport和网络变化来改善多用户的viewport命中率。 无论环境怎样，主动缓存都可以通过采用预测机制来预取和缓存部分视频来提高感知质量。 ","date":"2021-10-30","objectID":"/2021/10/note4/:1:1","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Immersive Video"],"content":"360度视频的协同传输 ","date":"2021-10-30","objectID":"/2021/10/note4/:2:0","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Immersive Video"],"content":"背景 360度视频推流有较大的用户需求并且在逐渐增长。 目前推流viewport之外的冗余信息会浪费重要的网络带宽。 相同的360度视频内容，在带宽受限的网络之上被推流给多个用户时，码率的需求变得更难满足。 几个方法应用了360度视频的协同传输，进而改善传输效率。 ","date":"2021-10-30","objectID":"/2021/10/note4/:2:1","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Immersive Video"],"content":"方案 Ahmadi’s work 引入了基于DASH的加权tile方法来优化子用户组请求的tile编码性能。 提出了多播流方案基于被用户看到的可能性对tile分配适当的权重。 接着基于可用带宽和tile权重为每个子用户组选择tile的码率。 实际上因为相邻tile的不同质量导致了空间质量变化，最终造成糟糕的推流体验。 不必要的离散优化问题巨大，不能保证有积极的表现。 Bao’s work 基于动作预测和并发观看用户的信道条件提出了一种多播框架，来只分发可能被看到的360度视频块。 没有在无线多播传输中考虑优化资源分配。 Guo’s work 为每个用户假设了一种随机动作模式和不稳定的信道条件，并且开发了多播机会来避免冗余数据传输。 作者考虑了两个非凸的问题： 在给定视频质量的约束下，最小化平均传输时间和能源消耗。 在给定的传输时间和能源预算下，最大化每个用户的视频质量。 Long’s work 考虑了传输时间、视频质量的平滑性和能源限制，在单服务器多用户无线网络环境中优化多个用户的聚合效用。 为了减少传输复杂性，作者准备了多种质量的tile，并为每组用户将tile划分到不相邻的子集中。 Zhang’s work 引入了一种使用SVC质量自适应方法的协同推流策略，来改善移动自组网环境中，观看360度内容的多个用户间的带宽共享。 当遇到可用网络资源限制时，提出的启发性方式基于被看到的可能性和聚合的组级别偏好设置选择最优的tile子集。 Kan’s work 提出了一种服务端混合多播-单播协同推流方案来分发不同质量的360度视频到多个用户。 基于用户的观看行为对其进行分簇，以此来轻松共享相同的视频内容。 为每个tile联合选择传输模式和适当的码率来提高整体的QoE。 Huang and Zhang’s work 设计了一种MIMO网络中的MAC调度方式。 资源分配策略基于三个主要的函数 基于延迟的Motion-To-Photon(MTP)VR帧权重计算。 基于最大Aggregate Delay-Capacity Utility（ADCU）的用户选择。 用于平衡VR数据传输的极高需求的链路自适应方法。 Li and Gao’s work 提出了多用户VR框架，其中边缘云自适应地存储和重用冗余VR帧，以减少计算和传输负载。 两级cache的设计：用户端的小型本地cache和边缘的大型中央cache。 通过为所有用户产生背景视图和无论何时都重用帧，使得减少了内存需求。 评估表明帧相关数据和计算负载分别减少了95%和90%。 总结 对推流到多个临近用户的流行内容共享例如360度视频是一种自然的选择。 然而非协作式的用户对带宽的竞争会快速使整个网络瘫痪。 为了为多个用户获得改善的QoE，研究者从以下几个方面做了努力： 确定多个用户可能的需求来公平地分配可用的网络资源。 分析跨用户的行为来精确传输要求的子帧到终端用户。 由于侧信道攻击，保护VR帧传输到多个终端用户。 ","date":"2021-10-30","objectID":"/2021/10/note4/:2:2","tags":["Immersive Video"],"title":"沉浸式流媒体网络问题的相关解决方案","uri":"/2021/10/note4/"},{"categories":["Programming Language"],"content":"常见的坑 所有标准库容器都支持迭代器，而只有少数几种支持下标运算符。 string虽然不是容器，但是支持很多容器的操作。 容器不为空时：begin()返回的是容器中第一个元素的位置；end()返回的是容器中最后一个元素的后一个位置。 容器为空时：begin()和end()返回的都是最后一个元素的后一个位置。 任何可能改变容器大小的操作都会使容器的迭代器失效。 ","date":"2021-10-28","objectID":"/2021/10/iterator/:1:0","tags":["C++"],"title":"重学C++：容器和迭代器","uri":"/2021/10/iterator/"},{"categories":["Programming Language"],"content":"必须要理解的点 和指针类似的是，迭代器支持对对象的间接访问。 和指针不同的是，获取迭代器不使用取地址符，有迭代器的类型都拥有返回迭代器的成员函数，如begin(), end()。 所有迭代器都支持的运算： 运算符 例子 含义 * *iter 返回迭代器iter指向元素的引用 -\u003e iter-\u003emem 解引用iter并获取该元素名为mem的成员，即(*iter).mem ++ ++iter 令iter指向当前元素的后一个元素 – --iter 令iter指向当前元素的前一个元素 == iter1 == iter2 如果两个迭代器指向相同的元素返回true，否则返回false != iter1 != iter2 上面例子的反面 迭代器的类型有两种：iterator和const_iterator。 vector\u003cint\u003e::iterator itv; // 可用于读写vector\u003cint\u003e中的元素 string::iterator its; // 可用于读写string对象中的元素 vector\u003cint\u003e::const_iterator citv; // 只能读取元素 string::const_iterator cits; // 只能读取元素 begin()和end()返回哪一种取决于对象本身是否被const修饰。 C++11中引入了cbegin()和cend()来专门返回const_iterator。 认定一种类型是迭代器当且仅当它支持一套操作，这套操作能使我们访问容器内的元素或从某一个元素移动到另一个元素。 vector和string的迭代器支持的额外的运算： 运算 含义 iter + n 运算得到一个新迭代器，指向当前元素的后n个元素的位置 iter - n 运算得到一个新迭代器，指向当前元素的前n个元素的位置 iter += n 运算得到的新迭代器赋值给iter iter -= n 同上 iter1 - iter2 两个迭代器之间的距离，可正可负 \u003e, \u003c, \u003c=, \u003e= 同两类型的下标运算符中的数字的关系，位置靠前的较小 ","date":"2021-10-28","objectID":"/2021/10/iterator/:2:0","tags":["C++"],"title":"重学C++：容器和迭代器","uri":"/2021/10/iterator/"},{"categories":["Programming Language"],"content":"建议 一般不在意迭代器的类型，因此使用auto来标注。 循环结束的判断条件习惯使用迭代器和!=，这样可以不用在意容器类型。 凡是使用了迭代器的循环体中都不能有改变容器大小的操作如push_back()。 ","date":"2021-10-28","objectID":"/2021/10/iterator/:3:0","tags":["C++"],"title":"重学C++：容器和迭代器","uri":"/2021/10/iterator/"},{"categories":["Programming Language"],"content":"常见的坑 vector的默认初始化是否合法取决于vector内对象所属的类是否要求显式初始化。 使用()和{}对vector执行初始化含义不同。 using std::vector; vector\u003cint\u003e v1{10}; // 存储1个int对象，值为10 vector\u003cint\u003e v2(10); // 存储10个int对象，值为0 vector\u003cint\u003e v3(10, 1); // 存储10个int对象，值都是1 vector\u003cint\u003e v4{10, 1}; // 存储2个int对象，值分别是10和1 使用{}执行列表初始化时按照顺序遵守2个守则： 如果{}内容可以用于初始化，则采用{}默认的初始化含义。 如果{}中的内容无法用{}默认的初始化含义做出解释，则会按照()的初始化含义去解释{}。 using std::vector; using std::string; vector\u003cstring\u003e v1{\"hi\"}; // 存储1个值为hi的string对象 vector\u003cstring\u003e v2{10}; // 存储10个值为空的string对象 vector\u003cstring\u003e v3{10, \"hi\"}; // 存储10个值为hi的string对象 与string相同，vector也有size_type作为其size()的返回值类型。 但是使用时必须首先指定vector由哪个类型定义。 std::vector\u003cint\u003e::size_type a; // 正确 std::vector::size_type a; // 错误 只有vector内元素的类型可以被比较时才能做比较运算，对于自定义类型需要手动定义运算符重载。 增加vector中的元素只能使用push_back()，而不能使用对下标赋值的方式。 ","date":"2021-10-28","objectID":"/2021/10/vector/:1:0","tags":["C++"],"title":"重学C++：标准库类模板Vector","uri":"/2021/10/vector/"},{"categories":["Programming Language"],"content":"必须理解的点 vector是类模板而非类型。 vector中只能容纳对象，不能容纳引用。 vector对象能高效增长，增加vector中的元素需要使用push_back()成员函数。 vector的成员函数（empty(), size()）和各种运算符（赋值、关系、下标）的操作使用方法和规则基本同string。 ","date":"2021-10-28","objectID":"/2021/10/vector/:2:0","tags":["C++"],"title":"重学C++：标准库类模板Vector","uri":"/2021/10/vector/"},{"categories":["Programming Language"],"content":"建议 不需要在创建vector时确定其中的元素及其大小。 在循环体内部包含向vector对象添加元素的操作时，不应该使用foreach循环。 ","date":"2021-10-28","objectID":"/2021/10/vector/:3:0","tags":["C++"],"title":"重学C++：标准库类模板Vector","uri":"/2021/10/vector/"},{"categories":["Programming Language"],"content":"常见的坑 string.size()和string.length()等价。 string.size()和其他STL容器的命名风格相一致（如vector, map）。 string.length()出现主要是因为这样的命名符合人的直觉，有更好的可读性。 string::size_type是无符号类型，和int不同，能存放下任何string对象的大小。 +两边至少有一端需要是string对象，不允许两个字符串字面量单独相加。 using std::string; string a = \"a\"; string b = a + \"b\" + \"c\"; // 正确，从左到右运算时能保证至少一段是string对象 string c = \"b\" + \"c\" + a; // 错误，从左到右运算时第一个+左右都是字符串字面量 ","date":"2021-10-28","objectID":"/2021/10/string/:1:0","tags":["C++"],"title":"重学C++：标准库类型string","uri":"/2021/10/string/"},{"categories":["Programming Language"],"content":"必须要理解的点 string的初始化方式有两种，一种是默认初始化，另一种是拷贝初始化。 string.size()返回值类型为string::size_type，出现这种类型是为了体现标准库类型和机器无关的特性。 string对象的比较运算完全实现了运算符重载（==, !=, \u003c,\u003c=, \u003e, \u003e=）。 ==表明两个对象的内容和长度完全一致，反之任一不同则!=。 不等关系运算符比较的法则： 如果两个对象长度不同，但是从前到后内容一致，则长度较短的对象较小。 如果两个对象从前到后有对应位置的字符不同，则这个位置的两个字符的大小关系就是两个对象的大小关系。 string对象赋值操作就是内容的替换。 string对象相加操作就是内容的拼接，+=操作同理。 string对象可以与字符串字面量相加。 形如cname的C++头文件兼容形如ctype.h的C头文件，C++头文件中定义的名字可以在std中找到。 ","date":"2021-10-28","objectID":"/2021/10/string/:2:0","tags":["C++"],"title":"重学C++：标准库类型string","uri":"/2021/10/string/"},{"categories":["Programming Language"],"content":"建议 表达式中出现string.size()函数时就不应该使用int类型，这样可以避免int和unsigned混用的问题。 C++和C兼容的头文件作选择时，选择C++的头文件。 处理string对象中每一个字符时，使用foreach语句。 #include \u003ciostream\u003e#include \u003ccctype\u003e using std::string; string str{\"Some String\"}; for (auto c : str) { std::cout \u003c\u003c c \u003c\u003c std::endl; } // 使用引用来改变原字符串内容 for (auto \u0026c : str) { c = std::toupper(c); } std::cout \u003c\u003c str \u003c\u003c std::endl; 处理string对象中特定字符时使用[]（下标运算符）或者迭代器。 使用[]访问字符之前检查string对象是否为空。 std::string s = \"a\"; if (!s.empty()) { std::cout \u003c\u003c s[0] \u003c\u003c std::endl; } string对象下标使用string::size_type作为类型而非int。 using std::string; string a = \"Hello, world!\"; string::size_type index_of_space = a.find(\" \"); ","date":"2021-10-28","objectID":"/2021/10/string/:3:0","tags":["C++"],"title":"重学C++：标准库类型string","uri":"/2021/10/string/"},{"categories":["Programming Language"],"content":"常见的坑 auto可以在一条语句中声明多个变量，但是所有变量的类型必须一致。 decltype在分析表达式类型时并不执行表达式。 decltype处理解引用操作之后返回的是引用类型，而引用类型的变量必须初始化。 decltype((variable))的结果永远是引用。 decltype(variable)的结果只有当variable是引用时才是引用。 ","date":"2021-10-26","objectID":"/2021/10/auto/:1:0","tags":["C++"],"title":"重学C++：类型推导","uri":"/2021/10/auto/"},{"categories":["Programming Language"],"content":"必须要理解的点 auto用于变量初始化时的类型推导，decltype用于分析表达式的类型。 auto对引用类型推导时实际上用的是引用对象的值。 auto与const：详见重学C++：Const二三事。 decltype与const：详见重学C++：Const二三事。 ","date":"2021-10-26","objectID":"/2021/10/auto/:2:0","tags":["C++"],"title":"重学C++：类型推导","uri":"/2021/10/auto/"},{"categories":["Programming Language"],"content":"建议 auto尽量只在类型较长但比较清晰时使用。 decltype尽量不要使用。 ","date":"2021-10-26","objectID":"/2021/10/auto/:3:0","tags":["C++"],"title":"重学C++：类型推导","uri":"/2021/10/auto/"},{"categories":["Programming Language"],"content":"常见的坑 仅用const修饰的对象只在单个文件中有效，如果想在多个文件之间共享const对象，必须在对象定义的前面加extern。 允许为一个常量引用绑定非常量的对象、字面量和表达式。 int i = 42; const int \u0026r1 = i; // 正确 const int \u0026r2 = 42; // 正确 const int \u0026r3 = r1 * 2; // 正确 int \u0026r4 = r1 * 2; // 错误 int \u0026r5 = i; r5 = 0; // 正确 r1 = 42; // 错误 指向常量的指针和常量指针： int err_numb = 0; const double pi = 3.1415; int *const cur_err = \u0026err_numb; const double *mut_pi_pointer = \u0026pi; const double *const pi_pointer = \u0026pi; 从声明语句的变量符号开始，自右向左看： cur_err首先是一个不可变对象，其次是一个指向int类型可变对象的指针。 mut_pi_pointer首先是一个可变对象，其次是一个指向double类型不可变对象的指针。 pi_pointer首先是一个不可变对象，其次是一个指向double类型不可变对象的指针。 当typedef遇到const时容易出现错误理解： typedef char *pstring; const pstring cstr = 0; const pstring *ps = 0; pstring是char *的别名，即指向char的指针。 const修饰的是pstring，因此cstr是：初始化值为nullptr的不可变指针。 错误理解会用char *替换掉pstring，即： const char *cstr = 0; 这样从cstr开始自右向左读的话，cstr就会被理解成：指向字符常量的可变指针。 constexpr属于顶层const，因此constexpr修饰指针意味着指针本身不可变。 auto默认会去除顶层const，保留底层const，如果需要顶层const则需要显式加入。 int i = 0; const int ci = i, \u0026cr = ci; auto b = ci; // b是一个初始化值为0的可变int对象 auto c = cr; // c同b auto d = \u0026i; // d是一个初始化为指向可变int类对象i的可变指针对象 auto e = \u0026ci; // e是一个初始化为指向不可变int类对象ci的可变指针对象 const auto f = ci; // f是一个初始化值为0的不可变int对象 decltype不会去除顶层const。 const int ci = 0; decltype(ci) x = 0; // x的类型是const int ","date":"2021-10-26","objectID":"/2021/10/const/:1:0","tags":["C++"],"title":"重学C++：Const二三事","uri":"/2021/10/const/"},{"categories":["Programming Language"],"content":"必须要理解的点 const对象在创建时必须进行初始化。 常量引用即对const对象的引用。 常量引用绑定不可变对象和可变对象时含义不同。 可变对象 不可变对象 用常量引用绑定 可以 必须 常量引用的含义 不能通过此引用改变对象的值 不可以改变对象的值 常量引用绑定到可变对象上：对原有可操作性质的窄化，减少操作肯定不会引发错误，所以是允许的。 非常量引用绑定到不可变对象上：对原有可操作性质的拓宽，增加不允许的操作会出错、，所以不可变对象必须使用常量引用。 因为指针是对象，而引用不是对象，所以const和指针的组合有2种情况，const和引用的组合只有1种情况。 指针 指向常量的指针（pointer to const）：不能通过此指针修改对应的量。 常量指针（const pointer）：指针本身的值不可变，即不能用指针指向其他对象，这种不可重新绑定的特性类似于引用。 引用 常量引用：不能通过此引用修改对应的量。 顶层const表示指针本身是常量，推广之后可以指任意对象是常量； 底层const表示指针指向的对象是常量，推广之后主要于指针和引用等复合类型的基本类型部分有关。 常量表达式指：值不会改变，在编译过程中就能得到计算结果的表达式。 为什么需要constexpr？ 因为实际中很难判断一个初始值是否为常量表达式。 使用constexpr相当于把验证变量的值是否是一个常量表达式的工作交给了编译器。 用constexpr声明的变量一定是一个变量，并且必须用常量表达式来初始化。 ","date":"2021-10-26","objectID":"/2021/10/const/:2:0","tags":["C++"],"title":"重学C++：Const二三事","uri":"/2021/10/const/"},{"categories":["Programming Language"],"content":"建议 如果认定变量是一个常量表达式，那就将其声明成constexpr类型。 ","date":"2021-10-26","objectID":"/2021/10/const/:3:0","tags":["C++"],"title":"重学C++：Const二三事","uri":"/2021/10/const/"},{"categories":["Programming Language"],"content":"常见的坑 \u0026和*在不同的上下文里面其含义并不相同，因此完全可以当成不同的符号看待。 int i = 42; int \u0026r = i; // \u0026在类型名后出现，是声明的一部分，表明r是一个引用 int *p; // *在类型名后出现，是声明的一部分，表明p是一个指针 p = \u0026i; // \u0026在表达式中出现，是取地址符 *p = 43; // *在表达式中出现，是解引用符 int \u0026r2 = *p; // \u0026是声明的一部分，*是解引用符 指针可以用0进行初始化成空指针，但是不可以用0赋值。 指针之间使用==来比较时，如果结果是true，对应多种情况： 都是空指针 都是同一个地址 都指向同一个对象 一个指针指向某一个对象，另一个指针指向另一对象的下一地址 ","date":"2021-10-26","objectID":"/2021/10/reference-and-pointer/:1:0","tags":["C++"],"title":"重学C++：引用和指针","uri":"/2021/10/reference-and-pointer/"},{"categories":["Programming Language"],"content":"必须要理解的点 引用和指针——都可以用于间接访问对象 引用 指针 复合类型 ✅ ✅ 表示符号 \u0026 * 含义 变量的别名 变量在内存中的地址 初始化和赋值时是否需要类型匹配 必须匹配（除常量引用） 必须匹配（除void*和指向常量的指针） 是否需要初始化 必须初始化 无需初始化 可否重新绑定其他变量 不可以 可以 可否嵌套定义 不可以 可以 引用： 引用只能绑定在对象上，不能绑定在字面量或者表达式上。 引用只是原有对象的别名，并非对象，因此不可以定义引用的引用。 定义引用时并不开辟新的内存空间，因此不可以定义引用的指针。 指针： 指针本身就是一个对象，能执行的操作自由度远超过引用。 可以实现嵌套定义，即指针的指针。 可以实现指针的引用。 int i = 42; int *p; // p是int型指针 int *\u0026r = p; // r是指针p的引用，从r开始自右向左读，\u0026表明r是一个引用，引用的是指针，指针指向的类型是int r = \u0026i; // r是p的别名，即给p赋值为i的地址，即令p指向i *r = 0; // r是p的别名，对r解引用即对p解引用，即将p所指向的地址处变量的值赋值为0 指针初始化和赋值时需要使用\u0026运算符取得对象的地址。 指针值的情况： 指向一个对象。 指向紧邻对象所占空间的下一个位置。 空指针，没有指向任何对象。 无效指针，除上述情况之外。 对第4种无效指针的操作是未定义的，后果无法预计。 2、3两种值虽然有效，但是因为没有指向任何对象，所以对其操作的后果同样无法预计。 void*眼中内存空间仅仅是内存空间，并不能访问内存空间中的对象。 ","date":"2021-10-26","objectID":"/2021/10/reference-and-pointer/:2:0","tags":["C++"],"title":"重学C++：引用和指针","uri":"/2021/10/reference-and-pointer/"},{"categories":["Programming Language"],"content":"建议 初始化所有的指针，并且在对象定义完成之后再定义指向它的指针。 避免使用0和NULL初始化空指针，应该使用nullptr。 在使用指针之前检查其是否为nullptr。 记住赋值改变的永远是等号左侧的对象。 面对复杂的指针或引用的声明语句时，从变量名开始自右向左阅读来弄清楚其真实含义。 ","date":"2021-10-26","objectID":"/2021/10/reference-and-pointer/:3:0","tags":["C++"],"title":"重学C++：引用和指针","uri":"/2021/10/reference-and-pointer/"},{"categories":["Immersive Video"],"content":"概述 360度视频的推流手段逐渐从视角独立型方案变成基于tile的视角依赖型方案。 相比于常规视频，360度视频被编码成全向的场景。 自适应360度视频推流利用DASH框架来实现比特率的自适应。 ","date":"2021-10-25","objectID":"/2021/10/note3/:1:0","tags":["Immersive Video"],"title":"自适应360度视频推流方案","uri":"/2021/10/note3/"},{"categories":["Immersive Video"],"content":"分类 ","date":"2021-10-25","objectID":"/2021/10/note3/:2:0","tags":["Immersive Video"],"title":"自适应360度视频推流方案","uri":"/2021/10/note3/"},{"categories":["Immersive Video"],"content":"Viewport-Independent Streaming 服务端的任务 使用如ERP、CMP等视角独立型的投影方式，360度视频被投影到一个球体上。 客户端的任务 投影之后的视频直接被传送到客户端，并不需要来自传感器的方向信息。 客户端需要支持对应的投影格式。 客户端像处理传统视频一样完成比特率自适应。 基于网络特征向将要到来的segment请求相同投影格式的表示 DASH插件需要支持相同质量视频的推流。 应用 视角独立型推流主要用于体育、教育和旅游视频内容。 优点 简单 缺点 相比于视角依赖型方案视频编码效率低了30%。 为不可见的区域要求大量带宽和解码资源。 ","date":"2021-10-25","objectID":"/2021/10/note3/:2:1","tags":["Immersive Video"],"title":"自适应360度视频推流方案","uri":"/2021/10/note3/"},{"categories":["Immersive Video"],"content":"Viewport-Dependent Streaming 终端设备的任务 只接受特定的视频帧内容，包括等于或大于视角角度的可见信息。 监测相关的视角作为用户头部移动的回应，并且向服务端发送信号来精确播放器信息。 为服务端准备和用户方向相关的几个自适应集。 客户端的任务 根据网络情况和估计的视角位置决定获取哪个自适应集。 难点 可视区域的确定 与用户头部移动的同步 质量调整 提供平滑的播放体验 现有的工作 各种投影方式在实际推流中表现如何？ 相比于金字塔格式，为视角依赖型投影方案提出的多分辨率变体有最好的研究和开发(RD)性能。 偏移CMP获得了5.6%到16.4%的平均可见质量。 提出的框架可以基于已知的网络资源和未来的视角位置适应视角的尺寸和质量。 相比于理想的下载过程，这种二维自适应策略可以花费20%的额外网络带宽下载超过57%的额外视频块。 如何在网络资源受限的情况下提供高质量的推流？ 为视角依赖型推流产生不同质量的segment。 当流中只有有限的representation时，利用Quality Emphasized Regions策略来缩放特定区域的分辨率。 在拥塞网络条件下，执行了基于网络回应的视角大小和比特率的联合适应，结果显示，相比于传送全部的360度场景，动态的视角覆盖率提供了更好的画面质量。 这种基于网络回应的自适应也确保基于整体拥塞变化做调整时能改善视频质量。 为立体视频的背景和前景视图采用不对称质量。 可以分别为背景块和前景块分别节省15%和41%的比特率。 DASH需要做什么？ manifest中需要包含视角位置信息和投影元数据。 优化获取random access point的周期来优化视角分辨率自适应体验。 考虑低延迟和活跃的视角切换。 ","date":"2021-10-25","objectID":"/2021/10/note3/:2:2","tags":["Immersive Video"],"title":"自适应360度视频推流方案","uri":"/2021/10/note3/"},{"categories":["Immersive Video"],"content":"Tile-based Streaming 传统视频被分成多个块，360度视频在块的基础上还被分成多个大小相等或者不等的tile，以此更加精确地调整画面的细节质量。 分块策略 基本完全交付 高级完全交付 部分交付 分块模式 1x1，3x2，5x3，6x4，8x5 其中6x4的模式实现了较好的带宽消耗和编码效率的折中。 在不同的带宽条件下，基本完全交付策略获得了大约65%的带宽节约。 具体方案 ClusTile 基于分簇的方式，推送满足最小带宽需求的tile来克服编码效率和计算开销。 相比于传统和高级的基于tile的推流方案，分别实现了72%和52%的带宽节约。 当实际看到的和下载的tile有差异时，基于分簇的tile选取可能会导致选择不当。 Ghosh’s work 提议以最低可获得的质量下载周围和远处的tile。 相比于其他算法，视角及其周边区域的可变质量提高了20%的QoE水平。 Ozcinar’s work 介绍了一种自适应 360° 视频流框架。 利用视觉注意力度量来计算每个帧的最佳平铺模式。 使用选中的模式，为不同区域的tile分配非统一的比特率。 比特率的选取取决于估计的视角和网络状况。 因为很大部分的带宽被用于传输非视角内的tile，框架难以优化视角内的质量。 Xie’s work 提出了一套优化框架，以此来最小化预取tile的错误，改善与不同比特率相关联的tile边界的平滑程度。 定义了两个QoE函数，目标是最小化： 预期质量失真$\\Phi(X)$ 当考虑tile看到概率时视角的空间质量方差$\\Psi(X)$： $$ \\Phi(X) = \\frac{\\sum_{i=1}^{N}\\sum_{j=1}^{M}D_{i,j} * x_{i,j} * p_{i,j}}{\\sum_{i=1}^{N}\\sum_{j=1}^{M}x_{i,j} * s_{i}} $$ $$ \\Psi(X) = \\frac{\\sum_{i=1}^{N}\\sum_{j=1}^{M}x_{i,j}*p_i * (D_{i,j} - s_i * \\Phi(X))^{2}}{\\sum_{i=1}^{N}\\sum_{j=1}^{M}x_{i,j}*s_i} $$ 基于目标缓冲区的自适应方法用于在需要短期视口预测的小缓冲区下进行平滑播放 在自适应的第k步，当第k个segment集合下载完成时，缓冲区占用率$b_k$由下面的式子给出： $$ b_k = b_{k-1} - \\frac{R_k*T}{C_k} + T $$ 为了避免用尽所有块，缓冲区的占用率被通过设定一个目标缓冲区水平$B_{target}$所控制，即$b_k = B_{target}$。 平均空间质量方差是0.97，比其他基于tile的策略小。 所提出的概率自适应框架在感知质量上实现了约 39% 的增益，平均降低了 46% 的空间质量方差。 Vander Hooft’s work 将360度帧划分成视角内区域和视角外区域。 首先为所有区域都选择最低质量，然后提高视角内tile的质量。 如果带宽依然可用，接着提高剩下的tile的质量。 启发式的方式在带宽可用的基础上积极提高视角内tile的质量。 没有考虑视角比特率调整时视角预测的错误。 Nguyen’s work 提出了一种新的自适应机制，它在每个segment中同时考虑头部移动和视角的预测错误，动态地决定视角内的比特率。 联合适应扩展块的覆盖范围和比特率。 在不同记录的用户头部运动下的实验评估表明，在不获取非视角内区域过多带宽利用率的情况下，视角内容质量有所提高。 DASH SRD扩展 DASH的SRD扩展提供了多种版本的tile的关联来节省更多的比特率。 Le Feuvre and Concolato’s work 他们应用了这个SRD特性，引入了同时为独立的和运动受限的HEVC tile的不同优先级设定，以此来高效地实现基于tile的方案。 使用开源的GPAC多媒体框架开发了一个DASH客户端，以此来执行带有可配置参数的基于tile的推流。 D’Acunto’s work 提出了一种 MPEG-DASH SRD 方法来促进可缩放和可平移视频的平滑推流。 总是下载低分辨率的tile来避免用户移动视角时的重新缓冲。 当前视野区域被上采样并展示给用户，以此来支持高质量的缩放功能。 用JavaScript实现了SRD视频播放器。 Hosseini’s work 基于SRD实现了视角内容、相邻tile和剩余tile的优先级推流。 用6个3D网格构建了一套3D座标系来在3D空间中平滑地表示tile。 相比于基础的方式，这种区分质量的推流方案节省了72%的带宽。 Kim and Yang’s work 使用改进的MPEG-DASH SRD来在质量可变的tile层中作选择。 基于他们之前的工作设计并实现了一个支持多层渲染的 360° VR 播放器，以支持高度不可预测的头部运动数据的高分辨率和低延迟流。 Motion-Constrained TileSet 在HEVC中，运动约束贴图集(MCTS)是将整个帧表示为子视频的相邻分割，并为自由选择的贴图集提供解码支持。 Zare’s work 将MCTS的概念应用到了全景视频推流中。 将两个质量版本的视频分割成tile，以原始的分辨率推流视角内的tile，以低分辨率推流剩余的tile。 它已经表明，选定图块的可变比特率会降低 30% 到 40% 的比特率。 Skupin’s work 陈述了一种使用HEVC编码器的基于tile的可变分辨率的推流系统。 使用立方贴图投影的360度视频被分割成24个网格，每个代表了一个独立的比特流。 两种不同质量的版本被推流到客户端，例如8个tile以高质量推送，16个tile以低质量推送。 Son’s work 在基于视角的移动VR推流中，为独立的tile提取和传输实现了基于MCTS的HEVC和可缩放的HEVC编解码器。 节省了超过47%的带宽。 相比于原始的HM和SHM编码器表现不佳，因为MCTS限制了时间运动信息。 Lee’s work 用MCTS编码360度视频tile，并使用显著性检测网络将混合质量的视频tile推流给终端用户。 通过显著性模型改进MCTS的使用，可以在不增加任何复杂性的情况下灵活地对感兴趣的tile区域进行解码支持。 Scalable Video Code 可伸缩视频编码SVC是实现viewport自适应的一种替代策略。 基础层总被需要并且能从客户端预取来避免重新缓冲事件。 提高层改善viewport质量并且可以在带宽充足的时候被请求。 SVC促进了一种高效的网络内缓存支持来减少多个客户端请求相同内容时的分发开销。 Nasrabadi’s work 使用了一种可伸缩编码方案来解决360度视频推流的重新缓冲的问题。 存在质量波动的问题，因为没有使用任何机制来处理viewport的预测错误。 Nguyen’s work 建议使用SVC协同viewport预测来克服网络信道和头部运动的随机性。 实验表明，所提出的平铺层更新和后期平铺终止特征可使viewport质量提高17%。 AI方法的应用 背景：传统视频推流中使用强化学习来高效调整视频比特率和实现长期的QoE回报。 和传统视频内容不同，360度视频包含几个新的方面比如tile大小、viewport预测等。 直接将现有的强化学习自适应策略应用到360度视频上可能会降低推流性能。 Fu’s work 为360度视频提出了称为360SRL的一种序列化强化学习方法，它基于之前决策的QoE回报而非估计的带宽状况做出自适应决策。 360SRL使用基于tile的推流模拟器来增强训练阶段。 跟踪驱动的评估表明，360SRL比基线适应方法取得了12%的QoE改善。 Jiang’s work 基于历史带宽、缓冲区空间、tile大小和viewport预测错误等，利用强化学习来做viewport和非viewport内tile的比特率选择。 所提出系统的架构由状态缓冲区、视口预测 (VPP) 和tile比特率选择 (TBS) 代理组成。 状态缓冲区向VPP和TBS代理提供用户查看模式和网络状态。 VPP代理然后使用LSTM模型估计下一个viewport位置。 TBS 代理由 Asynchronous Advantage Actor-Critic (A3C)算法训练以执行合适的比特率决策。 Quan’s work 通过卷积神经网络(CNN)提取像素运动来分析用户QoE，并使用它对tile动态分组，从而在视频质量和编码效率之间提供重要的平衡。 使用了基于强化学习的自适应代理，它可以智能地使每个图块的质量适应动态环境。 使用真实LTE带宽跟踪验证该方案，在感知质量方面表现出了卓越的性能，同时也节省了带宽资源。 背景：深度学习使强化学习能够使用多方面的状态和动作空间进一步优化聚合回报。 Kan and Xiao’s work 设计了一套深度强化学习的框架，基于对环境因素的探索和开发，自适应地调整推流策略。 这两种方案都采用DRL的A3C算法来进行比特率决策，因为A3C算法能使代理变得越来越智能化。 性能评估表明，所提出的系统平衡了各种 QoE 指标，包括平均视觉质量、平均质量波动和重新缓冲事件等。 Zhang’s work 提出了一个深度强化学习模型，它考虑viewport预测准确度和网络状况，使用基于LSTM的ACTOR-CRITIC(AC)网络动态地学习适应比特率分配。 方案能够很好地适应广泛的动态特性，并且与传统方法相比，提供了20%到30%的改进QoE","date":"2021-10-25","objectID":"/2021/10/note3/:2:3","tags":["Immersive Video"],"title":"自适应360度视频推流方案","uri":"/2021/10/note3/"},{"categories":["Immersive Video"],"content":"概述 自适应方案可以在处理不同目标对象时帮助改善推流体验。 目标主要包括视频质量、功耗、负载均衡等在移动无线网和有线网接入的情形。 适应性的视频比特率需要同时匹配网络条件和质量目标的需求。 ","date":"2021-10-21","objectID":"/2021/10/note2/:1:0","tags":["Immersive Video"],"title":"自适应视频推流方案","uri":"/2021/10/note2/"},{"categories":["Immersive Video"],"content":"分类 ","date":"2021-10-21","objectID":"/2021/10/note2/:2:0","tags":["Immersive Video"],"title":"自适应视频推流方案","uri":"/2021/10/note2/"},{"categories":["Immersive Video"],"content":"服务端适应 大多数服务端适应的方案要求客户端发送系统或网络相关信息。 质量导向的适应方案（Quality-Oriented Adaptive Scheme/QOAS） 向终端用户提供了高知觉质量的媒体内容。 QOAS是C-S架构，决策在服务器端产生。 QOAS基于客户知觉质量的反馈，提供对推流质量等级的调整。 智能优先级适应方案（intelligent Prioritized Adaptive Scheme/iPAS） 专用于802.11网络。 iPAS服务器上的基于固有印象的带宽分配模块被用于组合QoS相关的参数和视频内容特征来进行内容的优先级分类和带宽份额分配。 通过区分多媒体流，iPAS提供可用无线信道的优先级分配。 设备导向的适应方案（Device-Oriented Adaptive multimedia Scheme/DOAS） 专用于LTE网络，建立在LTE下行链路调度机制之上。 DOAS专门根据设备特性实现适配，尤其为多屏终端用户提供了卓越的QoE。 ","date":"2021-10-21","objectID":"/2021/10/note2/:2:1","tags":["Immersive Video"],"title":"自适应视频推流方案","uri":"/2021/10/note2/"},{"categories":["Immersive Video"],"content":"客户端适应 基于吞吐量的自适应方案 这类方案基于估计的网络吞吐量从服务端选择视频的比特率。 HTTP客户端通过之前的观察记录来估计网络的吞吐量。 通过测量端获取时间（segment fetch time/SFT）来代表发起和收到回复的瞬时HTTP GET请求之间的时间段，以此来确定一个推流会话中吞吐量的变化，进而独立地做出适应决策。 在分布式网络中，同时考虑并发和顺序的SFT。通过比较实际的和理想的SFT来选择未来的segment的质量等级。 FESTIVE算法 适用于多个HAS客户端共享一个常见的拥塞带宽链路的情形。 以效率、稳定性、公平性为度量因素的适应性算法。 探索了一种为分段调度、吞吐量估计和比特率选择而生的健壮的机制。 包含一个随机调度器来调度下一个视频块的下载。 多个客户端共享容量为$W$的满带宽链路，每个客户端$x$在$t$时刻播放的视频比特率为$b_x,_t$ ，需要避免以下3种问题： Inefficiency：多个HAS客户端必须能选择最可能的表示来提高QoE。 $$ Inefficiency = \\frac{|\\sum_{x}b_x,_t - W|}{W} $$ 低Inefficiency值表明多个客户端对带宽实现了最有效的利用。 Unfairness：可用带宽应该被均等地分配。 $$ Unfairness = \\sqrt{1-JainFair} $$ 低Unfairness值表明多个客户端有相近的比特率。 Instability：不必要的比特率切换会损害推流体验 $$Instability = \\frac{\\sum_{d=0}^{k-1}|b_{x,t-d} - b_{x,t-d-1}|*w(d)}{\\sum_{d=1}^{k}b_{x,t-d} * w(d)}$$ Probe AND Adapt(PANDA)算法 用于检测网络状况，考虑未来比特率选择的平均目标数据比特率。 目标是当多个HAS客户端共享一个拥塞带宽信道时，通过正确探测网络，进而最小化比特率震荡。 PANDA算法在性能上击败了FESTIVE算法，并且PANDA算法在这些解决方案中表现出了最好的适应性，在不同带宽情况和播放器设置下实现了最优的效率、公平性和稳定性。 整体上的推流质量不只依赖于本地的吞吐量测量，还依赖服务端的网络容量。 利用服务器发起的推送机制来降低DASH内容推流到移动客户端的端到端延迟。 利用HTTP/2的流终止特性来实现中间质量调整。 基于估计的用户QoE，功耗和可用资源来改善用户端的推流体验。 虽然有证据表明性能得到了提高，但是评估工作只是在受控的LAN环境下有效。 Cross Session Stateful Predictor(CS2P)方案 一种数据驱动的吞吐量估计方案，以克服不准确的 HAS 流量预测问题。 将共享相似特性的推流会话分簇，然后对每个簇使用隐马尔科夫模型预测相应的吞吐量样本。 在一个大规模数据集上实验性的评估表明：CS2P高效地估计了可用的网络吞吐量，进而改善了整体上的视频比特率的适应性。 CFA和Pytheas等方案和CS2P类似，也使用数据驱动的控制器来估计可用的吞吐量。 但是这些工作不支持异构系统并且需要额外的训练复杂性，使其不够具有吸引力。 基于吞吐量的适应性方案主要的挑战在于对吞吐量的精确估计。 为360度视频采用一个没有经过精巧设计的吞吐量估计机制可能会导致不稳定性和较差的QoE，在高度动态化的无线和蜂窝网络中尤甚。 基于缓冲区的自适应方案 客户端会在播放视频时根据当前缓冲区的占用情况请求将要到来的segment。 如何克服不完整的网络信息的限制 在多客户端启用缓存的环境中，结合客户端测量工具集和补偿算法构造模型。 这个模型可以高效探测比特率切换时间并通过选择切换适当的比特率来进行补偿，最终实现了可达20%的比特率改善。 Buffer Based Adaptation(BBA)方法 应用于Netfix客户端时可以减少可达20%的重新缓冲事件。 BBA方法考虑的缓冲区较大，因此对于比较短的视频不一定有这样的性能。 Buffer Occupancy-based Lyapunov Algorithm(BOLA) 把比特率适应性问题看作是与播放质量和重新缓冲时间相关的最优化问题。 BOLA旨在通过把缓冲区大小保持在设定的目标水平来避免重新缓冲。 对于缓冲区级别的突然下降，BOLA通过请求最低可用视频比特率来避免停顿事件的频率。 如何优化缓冲区利用率 Adaptation and Buffer Management Algorithm(ABMA+) 基于重新缓冲事件的可能性确定未来representation的下载时间。 通过基于预先计算的缓冲区大小和segment下载时间选择最大比特率来确保流畅的播放。 这样可以实现低计算开销的良好部署。 Scalable Video Coding(SVC)/Bandwidth Independent Efficient Buffering(BIEB) 基于层分发获取视频块，进而维持稳定的缓冲区大小来避免频繁的中断。 没有考虑QoE模型中的卡顿和质量切换。 涉及额外的编码和处理开销。 使用PID控制器的控制论方法 强制执行缓冲区设置点来使缓冲区保持在最佳水平。 略微降低视频比特率，以防止不必要的视频比特率调整。 在多个客户端竞争的情况下，不能保证公平性。 如何降低DASH流的排队延迟 DASH流会经历最长可达1s的排队延迟和严重拥塞，导致缓冲区膨胀问题，而这会严重损害实时多媒体服务的QoE。 旨在减少网络拥塞的主动队列管理 (AQM) 策略并没有充分减少这种不必要的延迟。 DASH客户端根据网络设备的队列大小动态接收窗口大小可以显著减轻缓冲区膨胀效应。 由于长期的viewport预测的高度不确定性，充足的缓冲区空间对于360度视频的流畅播放来说并不可行。 通常小于3s的缓冲区大小对于短期的viewport预测来讲比较适合。 由于小缓冲区很有可能造成播放卡顿，因此较短持续时间的segment可以被用于基于tile的流中，但是相比于长持续时间的segment，这样也会降低编码效率。 混合自适应方案 客户端同时考虑吞吐量和播放缓冲信号来确定即将到来的segments的视频比特率。 Model Predictive Control(MPC) 利用良好定义的参数集合来估计可用的网络和缓冲区资源，进而为高QoE的比特率做出最优调整的控制论方法。 提出的QoE模型采用视频的平均质量$R_k$，平均比特率切换，重新缓冲事件，和初始延迟$T_s$作计算： $$ QoE_1^K = \\sum_{k=1}^{K}q(R_k) - \\lambda\\sum_{k=1}^{K-1}|q(R_{k+1}) - q(R_k)| - \\mu\\sum_{k=1}^{K}(d_k(R_k)/C_k - B_k)_+ - \\mu_sT_s $$ $C_k$：第k个块的可用带宽，$B_k$：第k个块的可用缓冲区大小 $\\lambda, \\mu, \\mu_s$：可以根据用户兴趣进行调整的权重 MPC用调和平均的方法来估计吞吐量，并且能够明确管理复杂的控制对象。 只研究了单播放器的情况，因此没有公平性的考量。 Throughput and Buffer Occupancy-based Adaptation(TBOA) 选择合适的视频比特率来获得单个或多个客户端环境中改进的推流体验。 激进地提高了比特率来最高效地利用可用的带宽。 等待缓冲区超过某个级别，然后降低比特率以获得稳定的性能。 为缓冲区等级设置三个阈值，例如： $0 \u003c B_{min} \u003c B_{low} \u003c B_{high}$ 目标区间在$B_{low}$和$B_{high}$之间。 算法努力使最优区间$B_{opt}满足$ $B_{opt} = B_{low} + B_{high} \\over 2$。 通过控制$B_{low}$和$B_{high}$的阈值，使缓冲区和比特率的变化稳定来应对未知的TCP吞吐量。 算法表现的流畅而公平，但是没有把用户满意度的度量考虑在内。 fuzzy logic-based DASH 控制重新缓冲事件和视频推流的质量。 考虑了平均吞吐量的估计方法，获得了更高的视频比特率和更少的质量波动。 没有考虑QoE度量。 为了更好地调整比特率做出的改进： 用Kaufman’s Adaptive Moving Average/KAMA测量法估计吞吐量。 用Grey Prediction Model/GPM来估计缓冲区等级。 竞争流模拟环境中，改进所取得的效果： 平均情况下达到50%的公平性。 最好情况下达到17%的更好的接收质量。 Spectrum-based Quality Adaptation(SQUAD)算法 解决吞吐量预测和缓冲区等级估计的不连续性。 吞吐量和缓冲区等级反馈信号都被用于选择恰当的质量。 在一开始获取最低质量的segment来减少启动时间。 在视频质量切换频率和幅度方面性能显著提高。 尚未有方案讨论如何在视频质量和带宽利用率之间做出很好的平衡。 Throughput Friendly DASH/TFDASH 获得多个竞争客户端情形下的公平性、稳定性和效率。 通过避免OFF端获得了最大并且公平的带宽利用率。 双阈值的缓冲区保证播放时的稳定性。 在单客户端的环境中，混合适应方案表现的很合理。 但是多个客户端一起竞争带宽时会迅速扼杀整个网络。 当客户端的缓冲区达到了最大阈值时，客户端进入了ON-OFF阶段，此时客户端只对自己的视频比特率","date":"2021-10-21","objectID":"/2021/10/note2/:2:2","tags":["Immersive Video"],"title":"自适应视频推流方案","uri":"/2021/10/note2/"},{"categories":["Immersive Video"],"content":"360度流媒体视频框架 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:0","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Immersive Video"],"content":"视频采集和拼接 使用不同的360度视频采集相机可以将视频内容存储为3D的球形内容 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:1","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Immersive Video"],"content":"使用不同的投影策略实现降维 策略主要分为2种：视角独立型和视角依赖型 视角独立型 整个3D的视频内容被按照统一的质量投影到2D平面上 主要包括等距长方形投影和立方贴图投影 等距长方形投影(ERP) 使用左右偏向和俯仰值将观察者周围的球体展平到二维表面上 视角范围：左180度～右180度、上90度～下90度 缺点： 极点处会使用比赤道处更多的像素进行表示，会消耗有限的带宽 由于图像失真导致压缩效率不足 立方贴图投影(CMP) 六面立方体组合用于将球体的像素映射到立方体上的相关像素 在游戏中被广泛应用 优点： 节省空间，相比于等距长方形投影视频体积能减少25% 缺点： 只能渲染有限的用户视野 视角依赖型 视角内的内容比之外的内容有更高保真度的表示 主要包括金字塔投影、截断方形金字塔投影(TSP)和偏移立方贴图投影 金字塔投影 球体被投影到一个金字塔上，基础部分有最高的质量，大多数的投影区域属于用户的视角方向 优点： 节省空间，降低80%的视频体积 缺点： 用户以120度旋转视角时，视频的质量会像旋转180度一样急速下降 截断方形金字塔投影 大体情况和金字塔投影相同，区别在与使用了被截断的方形金字塔 优点： 减少了边缘数据，提高了高码率视频的推流性能 缺点： 使边缘更加锐利 偏移立方贴图投影 与原始的立方贴图投影类似，球体的像素点被投影到立方体的6个面上 优点： 视角方向的内容会有更高的质量，提供平滑的视频质量变化 缺点： 存储开销很大 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:2","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Immersive Video"],"content":"编码视频内容 目前主要的编码方式有AVC/H.264和HEVC/H.265。 H.264 使用16x16的宏块结构对帧编码。 因为使用了编码器的动作预测的特性，编码的数据大小得到减少。 H.265 相比于同质量的H.264编码方式，H.265编码减少了50%的比特率。 H.265支持tiling特性来实现高效视频推流。 每个tile在物理上被分割然后在普通的流中拼接，并且使用一个解码器来解码。 VVC 相比于H.265，下一代标准VVC有望提高30%的压缩效率。 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:3","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Immersive Video"],"content":"分包和传输 分包 使用DASH协议分包。 传输 依赖于雾计算和边缘计算等技术可以缩短分发中心和客户端之间的距离进而实现快速响应和低缓冲时间。 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:4","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Immersive Video"],"content":"渲染和展示 客户端处理 主流方案是使用客户端处理，但是由于会处理不属于用户视角范围内的视频内容，所以会造成计算资源的浪费。 云端处理 另一种方案是使用云端处理，只有用户视角内的视频内容会被传输到客户端，没有更多的带宽和客户端硬件资源要求。 ","date":"2021-10-20","objectID":"/2021/10/note1/:1:5","tags":["Immersive Video"],"title":"360度流媒体面临的挑战、机遇和解决方案","uri":"/2021/10/note1/"},{"categories":["Programming Language"],"content":"常见的坑 int, short, long, long long都是带符号的，在前面添加unsigned就能得到无符号类型。 字符型被分为3种：char, signed char, unsigned char，前两种并不等价。 虽然有三种类型，但是实际上只有两种表现形式：有符号的和无符号的。 有符号类型在与无符号类型运算时会隐式转换为无符号类型。 虽然变量初始化时候使用了=号，但是初始化和变量赋值并不相同。 变量默认初始化： 变量类型 位置在函数内部 位置在函数外部 内置类型 undefined 0 自定义类型 由类决定 由类决定 #include \u003ciostream\u003e int default_initialize(int a) { // 输出必定是0 std::cout \u003c\u003c a \u003c\u003c std::endl; int b; return b; } int main() { int a; // 输出是随机值 std::cout \u003c\u003c default_initialize(a) \u003c\u003c std::endl; } 如果在函数体内部试图初始化一个extern标记的变量会引发错误。 在嵌套作用域中，内层作用域中的定义可以覆盖外层作用域中声明的变量。 可以显式使用域操作符::来指明使用哪层的变量。 ","date":"2021-10-18","objectID":"/2021/10/cpp-types/:1:0","tags":["C++"],"title":"重学C++：类型系统基础","uri":"/2021/10/cpp-types/"},{"categories":["Programming Language"],"content":"必须要理解的点 字面量的意思就是从这个表示形式就能推断其对应类型的量，不同表示形式的字面量和不同类型是多对一的关系。 变量的组成部分：类型和值。说白了就是一个定性一个定量。 类型决定变量在内存里面的存储方式，包括大小和布局方式，以及能参与的运算。 值在实际代码运行过程中则被各种函数使用参与运算。 变量声明和定义： 声明的意思就是：我要用这个变量。 定义的意思就是：我要对这个操作的变量做出定义，规定其具体的细节。 声明 定义 规定变量的类型和名字 ✅ ✅ 申请空间 ✅ 初始化 ✅ 执行多次 ✅ 用extern标记未初始化的变量来表明只对变量作声明： extern int i; //只声明不定义 int i; //声明并且定义 extern int i = 10; //声明并且定义 Q：为什么会有声明和定义这两个概念？ A：因为C++支持分离式编译机制，这允许程序被分割成若干个文件，每个文件可以被独立编译。如果要在多个文件中使用同一个变量，就必须要将声明和定义分离。变量的定义必须且只能出现在一个文件中，其他用到这个变量的文件必须对其进行声明，且绝对不能进行重复定义。 名字的作用域： 同一个名字在不同的作用域中可以指向不同的实体。 名字的有效区域始于声明语句，以声明语句所在的作用域末端结束。 ","date":"2021-10-18","objectID":"/2021/10/cpp-types/:2:0","tags":["C++"],"title":"重学C++：类型系统基础","uri":"/2021/10/cpp-types/"},{"categories":["Programming Language"],"content":"建议 明确数值不可能为负时使用unsigned类型。 使用int执行整数运算，范围不够时使用long long。 使用double执行浮点数运算。 算术表达式中不要使用bool和char。 避免写出依赖实现环境的代码，否则代码不可移植。 避免有符号类型和无符号类型之间的隐式类型转换。 C++11中引入了列表初始化，例如： // 传统的初始化方式 int units_sold = 0; int units_sold(0); // 现代的初始化方式 int units_sold{0}; int units_sold = {0}; 列表初始化在用于内置类型变量时，如果初始值存在丢失信息的风险，编译器会报错。 long double pi = 3.1415926536; int a{pi}, b = {pi}; // 错误：没有执行类型转换，因为可能丢失信息 int a(pi), b = pi; // 正确：执行了隐式类型转化，丢失了信息 对每个内置类型的变量都执行显式默认初始化以防止undefined行为。 在变量第一次使用的地方进行定义操作。 ","date":"2021-10-18","objectID":"/2021/10/cpp-types/:3:0","tags":["C++"],"title":"重学C++：类型系统基础","uri":"/2021/10/cpp-types/"},{"categories":["Immersive-Video"],"content":"原仓库地址：Immersive-Video-Sample 修改之后的仓库：Immersive-Video-Sample ","date":"2021-10-09","objectID":"/2021/10/immersive-video-deploy/:0:0","tags":["Immersive-Video"],"title":"Immersive Video OMAF-Sample Deploy","uri":"/2021/10/immersive-video-deploy/"},{"categories":["Immersive-Video"],"content":"Server 端搭建 ","date":"2021-10-09","objectID":"/2021/10/immersive-video-deploy/:1:0","tags":["Immersive-Video"],"title":"Immersive Video OMAF-Sample Deploy","uri":"/2021/10/immersive-video-deploy/"},{"categories":["Immersive-Video"],"content":"修改 Dockerfile 手动设置 wget 和 git 的 http_proxy 旧 package 目录 not found，修改为新 package 目录 因为找不到 glog 库因此加入软链接操作 ln -s /usr/local/lib64/libglog.so.0.6.0 /usr/local/lib64/libglog.so.0 ","date":"2021-10-09","objectID":"/2021/10/immersive-video-deploy/:1:1","tags":["Immersive-Video"],"title":"Immersive Video OMAF-Sample Deploy","uri":"/2021/10/immersive-video-deploy/"},{"categories":["Immersive-Video"],"content":"重新编译内核 运行脚本时显示 libnuma 错误因此推断与 numa 设置有关 执行numactl -H显示只有一个 node，报错输出显示需要至少两个 numa 节点 查询资料之后获知可以使用 fakenuma 技术创造新节点，但是 Ubuntu 默认的内核没有开启对应的内核参数 手动下载 Linux 内核源代码到/usr/src/目录 wget https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.11.1.tar.gz 解压 tar xpvf linux-5.11.1.tar.gz 复制现有内核配置 cd linux-5.11.1 \u0026\u0026 cp -v /boot/config-$(uname -r) .config 安装必要的包 sudo apt install build-essential libncurses-dev bison flex libssl-dev libelf-dev 进入内核配置界面 sudo make menuconfig 按下/键分别查询CONFIG_NUMA和CONFIG_NUMA_EMU位置 手动勾选对应选项之后保存退出 重新编译并等待安装结束 sudo make -j $(nproc) \u0026\u0026 sudo make modules_install \u0026\u0026 sudo make install 修改grub启动参数加入 fake numa 配置 sudo vim /etc/default/grub 找到对应行并修改为 GRUB_CMDLINE_LINUX=\"numa=fake=2\" 更新grub并重启 sudo update-grub \u0026\u0026 sudo reboot 执行numactl -H检查 numa 节点数目为 2 重新执行脚本如图说明一切正常 ","date":"2021-10-09","objectID":"/2021/10/immersive-video-deploy/:1:2","tags":["Immersive-Video"],"title":"Immersive Video OMAF-Sample Deploy","uri":"/2021/10/immersive-video-deploy/"},{"categories":["Immersive-Video"],"content":"Client 端搭建 需要 Ubuntu18.04 环境，虚拟机中安装之后按照 README 命令，执行脚本一切正常 ","date":"2021-10-09","objectID":"/2021/10/immersive-video-deploy/:2:0","tags":["Immersive-Video"],"title":"Immersive Video OMAF-Sample Deploy","uri":"/2021/10/immersive-video-deploy/"},{"categories":["GNU/Linux"],"content":"Delete old sync files sudo rm /var/lib/pacman/sync/* ","date":"2021-06-11","objectID":"/2021/06/how-to-fix-gpgme-error/:1:0","tags":["Archlinux"],"title":"How to Fix GPGME Error on Archlinux","uri":"/2021/06/how-to-fix-gpgme-error/"},{"categories":["GNU/Linux"],"content":"Re init pacman-key sudo pacman-key --init ","date":"2021-06-11","objectID":"/2021/06/how-to-fix-gpgme-error/:2:0","tags":["Archlinux"],"title":"How to Fix GPGME Error on Archlinux","uri":"/2021/06/how-to-fix-gpgme-error/"},{"categories":["GNU/Linux"],"content":"Populate key sudo pacman-key --populate ","date":"2021-06-11","objectID":"/2021/06/how-to-fix-gpgme-error/:3:0","tags":["Archlinux"],"title":"How to Fix GPGME Error on Archlinux","uri":"/2021/06/how-to-fix-gpgme-error/"},{"categories":["GNU/Linux"],"content":"Re sync sudo pacman -Syyy Now you can update successfully! ","date":"2021-06-11","objectID":"/2021/06/how-to-fix-gpgme-error/:4:0","tags":["Archlinux"],"title":"How to Fix GPGME Error on Archlinux","uri":"/2021/06/how-to-fix-gpgme-error/"},{"categories":["Programming Language"],"content":"Get Correct Version microsoft-edge-dev --version The output is Microsoft Edge 91.0.831.1 dev in my case. ","date":"2021-03-26","objectID":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/:1:0","tags":["Python"],"title":"Python selenium settings on microsoft-edge-dev","uri":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/"},{"categories":["Programming Language"],"content":"Get Corresponding WebDriver Find the corresponding version at msedgewebdriverstorage and download the zip. Extract it to you path like /usr/local/bin or $HOME/.local/bin. ","date":"2021-03-26","objectID":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/:2:0","tags":["Python"],"title":"Python selenium settings on microsoft-edge-dev","uri":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/"},{"categories":["Programming Language"],"content":"Write Code Following is a example. from msedge.selenium_tools import EdgeOptions, Edge options = EdgeOptions() options.use_chromium = True options.binary_location = r\"/usr/bin/microsoft-edge-dev\" options.set_capability(\"platform\", \"LINUX\") webdriver_path = r\"/home/ayamir/.local/bin/msedgewebdriver\" browser = Edge(options=options, executable_path=webdriver_path) browser.get(\"http://localhost:8000\") assert \"Django\" in browser.title ","date":"2021-03-26","objectID":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/:3:0","tags":["Python"],"title":"Python selenium settings on microsoft-edge-dev","uri":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/"},{"categories":["Programming Language"],"content":"Launch it ","date":"2021-03-26","objectID":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/:4:0","tags":["Python"],"title":"Python selenium settings on microsoft-edge-dev","uri":"/2021/03/python-selenium-settings-on-microsoft-edge-dev-on-linux/"},{"categories":["GNU/Linux"],"content":"文件和目录的权限 下图为使用exa命令的部分截图 上图中的 Permission 字段下面的字母表示权限 第一个字母表示 文件类型 ： 属性 文件类型 - 普通文件 d 目录文件 l 符号链接 符号链接文件剩余的属性都是 rwxrwxrwx，是伪属性值，符号链接指向的文件属性才是真正的文件属性 c 字符设备文件 表示以字节流形式处理数据的设备，如 modem b 块设备文件 表示以数据块方式处理数据的设备，如硬盘驱动或光盘驱动 剩下的 9 个位置上的字符称为 文件模式 ，每 3 个为一组，分别表示文件所有者、文件所属群组以及其他所有用户对该文件的读取、写入和执行权限 属性 文件 目录 r 允许打开和读取文件 如果设置了执行权限，允许列出目录下的内容 w 允许写入或截断文件，但是不允许重命名或删除文件 如果设置了执行权限，那么允许目录中的文件被创建、被删除和被重命名 x 允许把文件当作程序一样来执行 允许进入目录 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:1:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"id：显示用户身份标识 一个用户可以拥有文件和目录，同时对其拥有的文件和目录有控制权 用户之上是群组，一个群组可以由多个用户组成 文件和目录的访问权限由其所有者授予群组或者用户 下图为 Gentoo Linux 下以普通用户身份执行 id 命令的结果 uid 和 gid 分别说明了当前用户的用户编号与用户名、所属用户组的编号与组名 groups 后的内容说明了用户还属于哪些组，说明了其对应的编号和名称 许多类 UNIX 系统会将普通用户分配到一个公共的群组中如：users 现代 Linux 操作是创建一个独一无二的只有一个用户的同名群组 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:2:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"chmod：更改文件模式 chmod 支持两种标识方法 八进制表示法 八进制 二进制 文件模式 0 000 --- 1 001 \u0026##x2013;x 2 010 -w- 3 011 -wx 4 100 r-- 5 101 r-x 6 110 rw- 7 111 rwx 常用的模式有 7,6,5,4,0 符号表示法 符号 含义 u user：表示文件或目录的所有者 g group：文件所属群组 o others：表示其他用户 a all：u+g+o 如果没有指定字符默认使用 all ’+’表示添加一种权限 ’-’表示删除一种权限 例如： 符号 含义 u+x 所有者+可执行 u-x 所有者-可执行 +x 所有用户+可执行 o-rw 其他用户-读写 go=rw 群组用户和其他用户权限更改为读，写 u+x,go=rx 所有者+可执行，群组用户和其他用户权限更改为读，可执行 ’-R’=’\u0026##x2013;recursive’表示递归设置 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:3:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"umask：设置文件默认权限 使用八进制表示法表示从文件模式属性中删除一个位掩码 掩码的意思：用掩码来取消不同的文件模式 umask 可以看到输出为： 0022 不同 linux 发行版默认的文件权限不同，这里的输出是 Gentoo Linux 上普通用户对应的的输出 0022：先不看第一个 0,后面的 0|2|2 用二进制展开结果是：000|010|010 原始文件模式 --- rw- rw- rw- 掩码 000 000 000 010 结果 --- rw- rw- r-- 掩码中 1 对应位处的权限会被取消，0则不受影响 所以会有这样的结果： 再来谈最前面的 0:因为除了 rwx 之外还有较少用到的权限设置 setuid 位:4000(8 进制) 设置此位到一个可执行文件时，有效用户 ID 将从实际运行此程序的用户 ID 变成该程序拥有者的 ID 设置场景：应用于由 root 用户拥有的程序，当普通用户运行一个具有 setuid 位的程序时，这个程序会以超级用户的权限执行，因此可以访问普通用户无法访问到的文件和目录 设置程序 setuid： chmod u+s program_name 结果： -rwsr-xr-x 可以看到第二组权限中第一个符号是 s setgid 位:2000(8 进制) 有效组 ID 从该用户的实际组 ID 更改为该文件所有者的组 ID 设置场景：当一个公共组下的成员需要访问共享目录下的所有文件时可以设置此位 对一个目录设置 setgid 位，则该目录下新创建的文件将由该目录所在组所有 chmod g+s dir_name 结果： drwxrwsr-x 可以看到第二组权限中最后一个符号是 s(替换了 x) sticky 位:1000(8 进制) 标记一个可执行文件是“不可交换的”，linux 中默认会忽略文件的 sticky 位，但是对目录设置 sticky 位，能阻止用户删除或者重命名文件，除非用户是这个目录的所有者，文件所有者或者 root 用来控制对共享目录的访问 chmod +t dir_name 结果： drwxrwxrwt 可以看到第三组权限中最后一个符号是 t(替换了 x) ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:4:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"su：以另一个用户身份运行 shell ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:5:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"使用 su 命令登录 su [-[l]] [user] 如果包含“-l”选项，得到的 shell session 会是 user 所指定的的用户的登录 shell 即 user 所指定的用户的运行环境将会被加载，工作目录会更改为此用户的主目录 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:5:1","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"使用 su 命令执行单个命令 su -c 'comand' 命令内容必须用 ’’ 引用起来（也可以是双引号） ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:5:2","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"sudo：以另一个用户身份执行命令 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:6:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"sudo 和 su 的区别 sudo 比 su 有更丰富的功能，而且可以配置 通过修改配置文件来配置 sudo EDITOR=vim visudo 执行上面的命令可以用 vim 来编辑 sudo 的配置文件 常用的场景是在将用户加入到 wheel 组之后使 wheel 组的用户能够访问 root 权限 使用 sudo 命令输入的不是 root 的密码，而是自己的密码 可以使用 `sudo -l`来查看通过 sudo 命令能获得的权限 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:6:1","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"chown：更改文件所有者 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:7:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"用法 chown [owner][:[group]] file ... 第一个参数决定 chown 命令更改的是文件所有者还是文件所属群组，或者对两者都更改 参数 结果 bob 文件所有者=\u003ebob bob:users 文件所有者=\u003ebob 文件所属群组=\u003eusers :admins 文件所属群组=\u003eadmins bob: 文件所有者=\u003ebob 文件所属群组=\u003ebob 登录系统时的组 图中使用 root 用户在/home/ayamir 目录下创建了一个 foo.txt 文件，最后将此文件的所有者和所属组都改为了 ayamir（rg 是ripgrep） ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:7:1","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"chgrp：更改文件所属群组 这个命令是历史遗留问题，在早期的 UNIX 版本中，chown 只能更改文件的所有者，而不能改变文件的所属群组，因此出现了这个命令，事实上现在的 chown 已经能实现 chgrp 的功能，因此没必要再使用这个命令（其使用方式几乎与 chown 命令相同） ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:8:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"passwd：更改用户密码 ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:9:0","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"一般用法 passwd [user] 用来更改 user 用户的密码，如果想修改当前用户的密码则不需要指定 user 执行之后会提示输入旧密码和新密码，新密码需要再确认输入一次 拥有 root 用户权限的用户可以设置所有用户的密码 上图为 Gentoo Linux 下使用 passwd 命令修改 ayamir 用户密码的过程，这里可以看到 passwd 会强迫用户使用强密码，会拒绝短密码或容易猜到的密码（其他发行版可能输出会不一样） ","date":"2021-03-15","objectID":"/2021/03/linux-authority/:9:1","tags":["GNU/Linux"],"title":"Linux权限相关命令解读","uri":"/2021/03/linux-authority/"},{"categories":["GNU/Linux"],"content":"Arch Linux DNS设置 安装dnsmasq sudo pacman -S dnsmasq 配置/etc/resolv.conf中的域名代理服务器 # Tencent nameserver 119.29.29.29 nameserver 182.254.118.118 # Ali nameserver 223.5.5.5 nameserver 223.6.6.6 # OpenDNS IPv4 nameservers nameserver 208.67.222.222 nameserver 208.67.220.220 # OpenDNS IPv6 nameservers nameserver 2620:0:ccc::2 nameserver 2620:0:ccd::2 # Google IPv4 nameservers nameserver 8.8.8.8 nameserver 8.8.4.4 # Google IPv6 nameservers nameserver 2001:4860:4860::8888 nameserver 2001:4860:4860::8844 # Comodo nameservers nameserver 8.26.56.26 nameserver 8.20.247.20 # Generated by NetworkManager nameserver 192.168.1.1 防止/etc/resolv.conf被修改 sudo chattr +i /etc/resolv.conf 减少主机名查找时间 sudo echo \"options timeout:1\" \u003e /etc/resolv.conf.tail 启动dnsmasq sudo systemctl enable dnsmasq.service --now ","date":"2021-01-26","objectID":"/2021/01/dns-settings-on-archlinux/:1:0","tags":["Archlinux"],"title":"Dns Settings on Archlinux","uri":"/2021/01/dns-settings-on-archlinux/"},{"categories":null,"content":"个人概况 20 岁，北京邮电大学 18 级软件工程专业本科生，已推免至北京邮电大学网络智能中心。 目前主要的研究方向是全景视频的传输（VR or Metaverse）。 Life is hard, so any rational person will give up if you don’t have Passion. ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"友链 cl 的博客：https://clslaid.icu/ 黄鸡的博客：https://hyiker.com/ z217 的博客：https://z217blog.cn/ Tackoil 的博客：https://tackoil.github.io/ ","date":"0001-01-01","objectID":"/about/:2:0","tags":null,"title":"","uri":"/about/"}]