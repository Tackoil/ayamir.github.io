<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Ayamir&#39;s Blog</title>
        <link>https://ayamir.github.io/</link>
        <description>Welcome to Ayamir&#39;s blog.</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>miracle_l@bupt.edu.cn (Ayamir)</managingEditor>
            <webMaster>miracle_l@bupt.edu.cn (Ayamir)</webMaster><lastBuildDate>Mon, 29 Jan 2024 10:31:56 &#43;0800</lastBuildDate>
            <atom:link href="https://ayamir.github.io/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>孤儿进程</title>
    <link>https://ayamir.github.io/posts/development/orphan-process/</link>
    <pubDate>Mon, 29 Jan 2024 10:31:56 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/development/orphan-process/</guid>
    <description><![CDATA[<h2 id="问题背景">问题背景</h2>
<p>前两天室友问我，怎么 kill 掉在 Shell 脚本中调用的 Python 进程，我第一时间想到的是：打开 <code>htop</code>，把它调整成树形布局，然后搜索 Shell 脚本，选中之后把它 kill 掉，Python 进程应该也会被 kill 掉。</p>
<p></p>
<p>但是结果是 Python 进程并没有变红，而是成为了 init 进程的子进程。</p>
<h2 id="孤儿进程是怎么产生的">孤儿进程是怎么产生的</h2>
<p>大二学 OS 学到父进程和子进程的概念的时候，还是只是以为父进程和子进程之间应该存在牢固的控制关系，父进程退出时子进程也应该默认退出。</p>
<p>但是 OS 的实际行为不是这样，子进程和父进程只是说明了二者之间存在谁创建谁的关系，并不存在牢固的控制关系（而是类似于现实中的父子关系）。</p>
<ul>
<li>
<p>父进程结束时子进程并没有结束，子进程成为孤儿进程，会被 init 进程收养</p>
</li>
<li>
<p>父进程崩溃或异常终止</p>
</li>
<li>
<p>并发和竞争条件导致父子进程的结束顺序错误</p>
</li>
</ul>
<h2 id="如何避免孤儿进程的产生">如何避免孤儿进程的产生</h2>
<p>其实就是需要在程序设计时，考虑到上述的这几种可能导致孤儿进程产生的原因，然后对异常情况进行注册和处理。对于开始时的这个引入问题而言，答案可以写成以下两个脚本：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="cp">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="c1"># 定义一个函数来处理信号</span>
</span></span><span class="line"><span class="cl">cleanup<span class="o">()</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">	<span class="nb">echo</span> <span class="s2">&#34;捕捉到终止信号，正在终止 Python 进程...&#34;</span>
</span></span><span class="line"><span class="cl">	<span class="nb">kill</span> <span class="nv">$PYTHON_PID</span>
</span></span><span class="line"><span class="cl">	<span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 在接收到 SIGINT || SIGTERM || SIGKILL 时执行 cleanup 函数</span>
</span></span><span class="line"><span class="cl"><span class="nb">trap</span> <span class="s1">&#39;cleanup&#39;</span> SIGINT SIGTERM
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 启动 Python 脚本并获取其进程 ID</span>
</span></span><span class="line"><span class="cl">python example_python.py <span class="p">&amp;</span>
</span></span><span class="line"><span class="cl"><span class="nv">PYTHON_PID</span><span class="o">=</span><span class="nv">$!</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 等待 Python 进程结束</span>
</span></span><span class="line"><span class="cl"><span class="nb">wait</span> <span class="nv">$PYTHON_PID</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">signal</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">sys</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 定义信号处理函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">signal_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Python 脚本接收到终止信号，正在退出...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 设置 SIGINT SIGTERM 的处理器</span>
</span></span><span class="line"><span class="cl"><span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Python 脚本的主逻辑</span>
</span></span><span class="line"><span class="cl"><span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Python 脚本正在运行...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">pass</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>通过在父进程和子进程中都注册相应的事件，就可以保证 kill 作为父进程的 Shell 进程之后，作为子进程的 Python 进程也会终止。</p>
<p>实际演示：<code>chmod +x example.sh example_python.py &amp;&amp; bash example.sh</code></p>
<p></p>
<p>执行 <code>SIGTERM</code> 信号的 kill 之后，父子进程都被终止。</p>
<p></p>
<p>需要注意的是，如果使用 <code>kill -9 $PARENT_PID</code> 的形式来杀死父进程的话，子进程并不会被杀死。</p>
<p>因为 <code>9</code> 这个编号对应的是 <code>SIGKILL</code> 信号，<code>SIGKILL</code> 信号被设计为不能被捕捉、阻塞或忽略的。<code>SIGKILL</code> 的主要用途是允许操作系统或用户强制终止一个进程，即使该进程处于非响应状态。（类似的还有 <code>SIGSTOP</code> 信号，用于暂停一个进程的执行，也不能被捕捉、阻塞或忽略。）</p>
<p>所以我们也无法在 Python 脚本中注册监听这个信号（强行注册 Python 脚本会无法运行）。</p>
<p></p>
]]></description>
</item>
<item>
    <title>Git 常用用法记录</title>
    <link>https://ayamir.github.io/posts/development/git-usage/</link>
    <pubDate>Tue, 23 Jan 2024 09:50:29 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/development/git-usage/</guid>
    <description><![CDATA[<p>这篇博客用来记录平时用到的一些 Git 操作，用到之后会不定时更新。</p>
<h2 id="clone-相关">clone 相关</h2>
<p>克隆指定 branch ： <code>git clone --branch &lt;branch-name&gt; &lt;remote-repo-url&gt;</code></p>
<p>递归克隆（包括submodule）：<code>git clone --recursive</code></p>
<p>已经 clone 完的仓库：<code>git submodule update --init --recursive</code></p>
<h2 id="checkout-相关">checkout 相关</h2>
<p>切换分支：<code>git checkout &lt;branch-name&gt;</code> / <code>git switch &lt;branch-name&gt;</code></p>
<p>新建分支：<code>git checkout -b &lt;branch-name&gt;</code> / <code>git switch -c &lt;branch-name&gt;</code></p>
<p>切换到一个 tag ：<code>git fetch --all --tags --prune</code> -&gt; <code>git tag</code> -&gt; 使用 <code>/</code> 快速搜索 -&gt; <code>git checkout tags/&lt;tag-name&gt; -b &lt;branch-name&gt;</code></p>
<h2 id="协作相关">协作相关</h2>
<p>Review 并且 Commit 别人提出的 PR 的流程：</p>
<ol>
<li>
<p><code>git remote add &lt;remote-name&gt; &lt;remote-repo-url&gt;</code></p>
</li>
<li>
<p><code>git remote -v</code></p>
</li>
<li>
<p><code>git fetch &lt;remote-name&gt;</code></p>
</li>
<li>
<p><code>git checkout -b &lt;local-branch-name&gt; &lt;PR-branch-name&gt;</code></p>
</li>
<li>
<p><code>git commit -sm &quot;&lt;commit-message&gt;&quot;</code></p>
</li>
<li>
<p><code>git push &lt;remote-name&gt; HEAD:&lt;PR-branch-name&gt;</code></p>
</li>
</ol>
]]></description>
</item>
<item>
    <title>H264 Encode</title>
    <link>https://ayamir.github.io/posts/knowledge/h264-encode/</link>
    <pubDate>Tue, 23 Jan 2024 01:05:20 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/knowledge/h264-encode/</guid>
    <description><![CDATA[<h2 id="编码框架">编码框架</h2>
<p>编码器包含两个方向的码流分支：</p>
<p></p>
<p>从左到右的前向码流分支为编码过程；</p>
<p>从右到左的反向码流分支为重建过程。</p>
<h3 id="前向编码分支">前向编码分支</h3>
<p>以16x16像素的MB为单位进行处理，首先从当前输入的视频图像(Frame or Field)中取一个待编码宏块$F_n$，该宏块以帧内或者帧间的模式进行编码，生成一个预测宏块$P$。</p>
<p>如果是帧内编码，$P$由当前Slice里面已经编码、解码、重构并且还没进行去块滤波的宏块 $μF_n&rsquo;$ 使用帧内预测得到。当前宏块 $μF_n&rsquo;$ 减去预测宏块 $P$，得到残差块$D_n$，对残差块 $D_n$ 进行整数变换（一般是4x4，或者8x8）、量化后得到一组系数 $X$ ，再对 $X$ 进行重排序和熵编码，就完成了一个宏块的编码过程。对于P帧和B帧，如果ME时候找不到最佳匹配块那也会使用帧内预测编码。</p>
<p>经过熵编码的码流加上宏块解码所需的一些信息，如预测模式、量化步长、描述宏块运动预测补偿的运动矢量信息等，就组成了该宏块压缩后的码流，Slice中所有MB的码流加上Slice头信息就组成了Slice的编码码流，再通过NAL层进行传输或存储。图像参数集PPS和序列参数集SPS则由NAL单独进行传输。</p>
<h3 id="后向重建分支">后向重建分支</h3>
<p>在后向重建分支中，对量化后的宏块系数 $X$ 进行解码从而得到重建宏块，后续宏块进行编码需要从已重建的宏块中寻找参考块。宏块重建过程如下：
宏块系数 $X$ 经过反量化和反变换之后，得到残差宏块 $D_n$ 的近似值 $D_n&rsquo;$ ，预测块 $P$ 加上 $D_n&rsquo;$ 得到未滤波的重构宏块 $μF_n&rsquo;$ ，再做环路滤波来减少块效应，即得到了最终的重构宏块 $F_n&rsquo;$ ，当图像中所有宏块都重建完成后，就形成了重建图像。</p>
<p>后向重建分支其实就是包含在编码中的完整解码流程，与真正解码器的唯一区别是： 其预测块P直接从前向编码分支中得到，而真正的解码器需要利用码流中解出的预测块信息获得预测块P。当前图像的已重建宏块会被用做帧内预测的参考，而完整的重建图像会被加入参考帧列表，作为未来编码图像帧预测的参考图像。</p>
<h2 id="预测编码">预测编码</h2>
<p>预测编码（Prediction Coding）利用相邻像素之间的空间和时间相关性，用已传输的像素对当前正在编码的像素进行预测，然后对预测值和真实值的差值——预测误差进行编码和传输。</p>
<p>消除空间冗余：利用一帧图像已经编码的部分来预测还没有被编码的部分</p>
<p>消除时间冗余：利用之前编码过的图像来预测当前图像需要编码的部分</p>
<p>通过预测可以得到预测值，预测值通常不等于实际值，所以用实际值减去预测值可以得到预测残差。预测方法越好，残差越小，因而对残差进行编码得到的码流要比对实际值直接进行编码的码流要小</p>
<p>在解码端可以解码出残差，使用与编码端相同的预测过程来获取预测值，加上残差便可以得到相应的实际值。</p>
<p>目前使用较广的预测方法是线性预测。用已传像素的线性组合对正在编码的像素进行预测。</p>
<p>编码器输出预测值和实际值之间的差值，选择最优的预测系数，使预测误差的分布在0附近。经过非均匀量化之后，最终传输的是量化之后的预测误差。</p>
<p>重建的图像与编码前的图像之间的区别是量化带来的。</p>
<p>如果取消量化操作，那么预测编码和解码就是一个无失真的编解码系统，但是这样的压缩率要远远低于使用量化的压缩率。</p>
<p>量化的事实依据是图像中存在人眼感知并不明显的区域，通过非均匀量化可以过滤掉这部分数据（也被称为量化噪声），能达到提高压缩率但不降低主观质量的效果。</p>
<h2 id="帧间预测">帧间预测</h2>
<p>帧间预测消除的是时间冗余，主要利用的是运动估计和运动补偿。</p>
<p>运动估计ME的过程其实就是计算运动向量MV的过程：</p>
<p>寻找当前编码的块在已编码图像中的最佳对应快，并且计算出对应块的偏移量：运动向量</p>
<p>假设当前编码块是 $B$ ，在参考帧 $P_r$ 中寻找与 $B$ 块相减残差最小的块 $B_r$ ， $B_r$ 就是 $B$ 块的最佳匹配块。</p>
<p>$$
MV=B_r-B=(x_r  - x,y_r  - y)
$$</p>
<p>$B_r$ 块就是 $B$ 块的参考块， $B_r$ 的像素值就作为 $B$ 块像素值的预测值。
运动向量MV也需要用合适的方式编码到码流中。</p>
<p>运动补偿MC：根据MV和帧间预测方法，求出当前帧的估计值的过程。</p>
<p>当前帧的估计值是对当前图像的描述，用来说明当前图像的每一个像素怎么由它的参考图像的像素块得到。</p>
<p>ME是动态的过程，MC是静态的描述。</p>
<ul>
<li>
<p>ME设计很多算法和技巧。</p>
</li>
<li>
<p>MC可以看作是索引表，一个描述像素块的最佳匹配块分布情况的索引表。</p>
</li>
</ul>
<p>实际计算过程中会对树状结构分块的8种模式都尝试一遍。
H264支持亮度1/4像素、色度1/8像素的运动估计，在亚像素ME之前需要先用插值法得到亚像素值。</p>
<ul>
<li>
<p>在噪声大的视频中，提高搜索精度没法提高预测精确度。</p>
</li>
<li>
<p>在噪声小的视频中，1/4像素精度可以达到比较好的预测效果。</p>
</li>
<li>
<p>视频会议里1/2像素精度基本可以满足需求。</p>
</li>
</ul>
<h3 id="运动估计算法">运动估计算法</h3>
<p>假设匹配误差随着离全局误差最小点的距离增加而单调增加，从原点开始，采用固定的搜索模板和搜索策略得到最佳匹配块。</p>
<p>理论最优的算法是全搜索法，但是计算量巨大，效率低, 一般作为其他搜索算法的一种效率参考。</p>
<p>还有其他的快速法：X264里面主要使用的是钻石搜索法DIA、六边形搜索法HEX和UMH。</p>
<p>钻石搜索法以搜索起点为中心，先用 LDSP 进行搜索，直到最佳匹配点位于大菱形的中心位置，然后再用小菱形搜索，直至最佳匹配点位于小菱形的中心位置。</p>
<p>六边形搜索法采用 1 个大模板（六边形模板）和 2 个小模板（小菱形模板和小正方形模板）。</p>
<ul>
<li>步骤1：以搜索起点为中心，采用图中左边的六边形模板进行搜索。计算区域中心及周围6个点处的匹配误差并比较，如最小MBD 点位于模板中心点，则转至步骤2；否则以上一次的MBD 点作为中心点，以六边形模板为模板进行反复搜索。</li>
<li>步骤2：以上一次的MBD 点为中心点，采用小菱形模板搜索，计算各点的匹配误差，找到MBD 点。然后以MBD点为中心点，采用小正方形模板搜索，得到的MBD点就是最优匹配点。</li>
</ul>
<p>UMH是基于 MV 具有时空相关性，所以可以结合上一帧和上一步中 MV 的方向和角度，来修改多层六边形的形状，UMH算法包含四中搜索模式:不均匀交叉搜索、多六边形网格搜索、迭代六边形搜索、菱形搜索。</p>
<ul>
<li>步骤1：进行一次小菱形搜索，根据匹配误差值和两个门限值（对于一种尺寸的宏块来说是固定大小的threshold1和threshold2）之间的关系作相应的处理，可能用到中菱形模板或者正八边形模板，也有可能直接跳到步骤1。</li>
<li>步骤2：使用非对称十字模板搜索。“非对称”的原因是一般水平方向运动要比垂直方向运动剧烈，所以将水平方向搜索范围定为W，垂直方向搜索范围定为W/2。</li>
<li>步骤3：使用5x5逐步搜索模板搜索。</li>
<li>步骤4：使用大六边形模板搜索。</li>
<li>步骤5：使用六边形搜索算法找到最优匹配点。</li>
</ul>
<p>码率不变的前提下，“Dia”、“HEX”、“UMH”编码获得的质量依次提高，速度依次降低。快速算法（“Dia”、“HEX”、“UMH”）的编码质量比全搜索算法低不了太多，但是速度却高了很多倍。</p>
<h3 id="多参考帧预测">多参考帧预测</h3>
<p>编码端存储参考帧的缓冲区就是DPB，主要有三种参考帧：短期参考帧、长期参考帧和非参考帧。</p>
<ul>
<li>短期参考帧就是和当前帧相邻的帧，按照从近到远的顺序排序。</li>
<li>长期参考帧是较早之前的帧，按照从远到近的方式排列。</li>
<li>不使用的参考帧是因为某些原因废弃了的参考帧，并且没有被新的参考帧替换掉。比如遇到IDR帧的时候DPB里面的所有参考帧都会标记成非参考状态。所以I帧之后的P帧也可以参考这个I帧之前的图像。</li>
</ul>
<h3 id="mv预测和skip模式">MV预测和Skip模式</h3>
<p>需要对MV进行压缩，方式是使用临近分块MV之前的相关性对当前块的MV进行预测，只对预测残差MVD进行编码。</p>
<p>Skip模式：Skip模式只针对宏块编码，也就是完全不用编码只需要在码流里面标明是SKIP宏块就行。P_Skip宏块就是COPY宏块，既没有MVD，也不编码量化残差，解码时候直接用MVp作为运动向量得到像素的预测值作为像素重建值。B_Skip宏块也是既没有MVD也没有量化残差，解码时候通过Direct预测模式计算出前向和后向MV，然后得到像素预测值作为重建值。</p>
<ul>
<li>
<p>P_Skip：最佳模式是Inter16x16、参考帧是List0里面的第一个参考帧、MVD=0、变换系数被量化成0，或者在RDO模型中被抛弃。</p>
</li>
<li>
<p>B_Skip：最佳模式是B_direct_16x16，变换系数要么全是0要么被算法抛弃。</p>
</li>
</ul>
<h3 id="加权预测">加权预测</h3>
<p>用来应对明暗/亮度变化的场景，使用两种预测模式：显式模式(P帧、B帧)和隐式模式(B帧)。</p>
<ul>
<li>显式模式：加权系数由编码器决定并且在Slice Header里面传输。</li>
<li>隐式模式：加权系数由参考图像的时间位置推算，越接近当前图像，加权系数越大。</li>
</ul>
<p>步骤：</p>
<ol>
<li>
<p>亮度变化检测：</p>
<p>使用直方图计算前后两幅图像在各个灰度级别SAD，然后采用阈值法判断有没有发生亮度变化。</p>
</li>
<li>
<p>计算加权系数：
第一种方法：计算参考帧和当前帧的亮度均值比值，利用比值作为加权系数（全局加权补偿的效果有限）</p>
<p>第二种方法：全局补偿，但是使用使前后图像MSE和偏移量最小的加权系数：使MSE的表达式（加权系数$W_1$和偏移量$W_2$）分别基于$W_1$和$W_2$的偏微分等于0。</p>
</li>
<li>
<p>亮度补偿：</p>
<p>原则上需要做到宏块级别的亮度补偿，但是为了降低复杂度只做帧级亮度补偿。</p>
<p>根据求出的加权系数和偏移量进行全局亮度补偿得到新图像。</p>
<p>把新图像存到一个列表中作为带亮度补偿运动估计的参考帧。</p>
</li>
</ol>
<h2 id="帧内预测">帧内预测</h2>
<p>帧内预测实质是消除空间冗余，利用已编码的块的像素的来预测未编码的像素值。</p>
<p>未编码的块像素的实际值-预测值=残差，传输只需要传输残差。</p>
<p>H264引入了基于空域的帧内预测技术，在空域中利用当前块的相邻像素直接对每个像素做预测，并对预测残差进行变换、量化。</p>
<p>H264帧内预测中，色度和亮度信息是被分开预测的。</p>
<ul>
<li>对于亮度待编码块，可以按照4x4块方式预测(I4MB)或16x16宏块方式预测(I16MB)。
<ul>
<li>4x4预测时有9种模式（水平、垂直、DC、6个方向），用于图像细节部分的预测。</li>
<li>16x16预测时有4种模式（水平、垂直、DC、平面），用于图像平坦区域的预测。</li>
</ul>
</li>
<li>对于色度待编码块，基于8x8块进行预测。
<ul>
<li>8x8预测有4种模式（水平、垂直、DC、平面）。</li>
</ul>
</li>
</ul>
<p>亮度和色度的最佳帧内预测模式相互独立：</p>
<ul>
<li>
<p>色度的只需要比较4种模式的代价，选择最小的。</p>
</li>
<li>
<p>亮度的需要：算出代价最小的Intra4x4模式、算出代价最小的Intra16x16模式、取两者最小的。</p>
<ul>
<li>Intra4x4：用RDO模型也就是拉格朗日模型计算代价。</li>
<li>Intra16x16：用SATD，变换使用哈达马变换（看作是简单的时频变换，可以反映生成码流的大小）</li>
</ul>
</li>
</ul>
<h2 id="变换编码">变换编码</h2>
<p>变换编码（Transform Coding）将空间域描述的图像，经过某种变换形成变换域中的数据，达到改变数据分布，减少有效数据量的目的。</p>
<p>变换编码中主要使用方式是正交变换。正交变换不会改变信源的熵值，变换之后图像的信息量并没有损失，完全可以通过反变换得到原来的图像值。</p>
<p>正交变换可以改变数据的分布，将数据集中分布之后就可以使用进一步的量化操作来去除大部分的0值和接近0的值。</p>
<p>正交变换中的理论最优变换是K-L变换。</p>
<p>实际中常用的正交变换有 DCT变换，DFT变换(离散傅里叶变换)，Hadamard变换。</p>
<p>因为DCT系数主要集中在低频区域，越是高频区域系数值越小，通过设置不同的视觉阈值的量化电平，将许多能量较小的高频系数量化为0，可以增加变换系数中0的个数，同时保留能量较大的系数分量，对量化之后的系数进行熵编码可以获得进一步的压缩。</p>
<p>H264使用的是整数变换，变换核只用加减法和左移操作实现，不需要乘法器。</p>
<p>各种变换的比较：</p>
<ul>
<li>压缩比和重建质量：
<ul>
<li>较小分块时，DCT的MSE接近K-L变换。</li>
<li>块大小超过16x16时，除傅里叶变换之外，其他几种变换的MSE下降很慢。</li>
<li>大方块尺寸时，傅里叶变换趋向于K-L变换。</li>
</ul>
</li>
<li>计算复杂度：
<ul>
<li>Hadamard计算复杂度最小。</li>
<li>其次是DFT和DCT，具有固定的核函数。</li>
<li>K-L变换的核函数与输入相关，计算量很大，不实用。</li>
</ul>
</li>
</ul>
<p>变换编码中的失真还是由量化器引起，正反变换和变长编解码都是无损处理。</p>
<h3 id="dct变换">DCT变换</h3>
<p>离散余弦变换与 DFT变换相似，但是DCT变换只使用实数。</p>
<p>DCT变换具有能量集中性，大多数的声音和图像信号的能量都集中在DCT变换之后的低频部分。</p>
<p>当信号具有接近马尔可夫过程的统计特性时，DCT变换的去相关性接近于 K-L变换。</p>
<p>图像处理领域中，DCT变换的效果要强于 DFT变换，因而图像处理中更多应用的是DCT变换。</p>
<p>DCT产生的系数很容易被量化，因而可以获得较好的块压缩。</p>
<p>DCT算法的性能好，有快速算法，采用快速傅里叶变换可以进行高效的运算。</p>
<h2 id="量化">量化</h2>
<p>量化的思想就是映射一个输入间隔到一个整数，减少信源编码的bit数。</p>
<p>量化器的设计就是率失真优化问题，在允许一定失真的条件下，获得尽可能高的压缩比。</p>
<p>量化步长决定量化器的编码压缩率和图像精度。</p>
<p>量化最简单的方法就是均匀（线性）量化，但均匀量化的效果往往并不好，因为它没有考虑到量化对象的概率分布。</p>
<p>对DCT系数这样的数据而言，其分布大部分集中在直流和低频附近，如果采用非均匀量化，对低频区域进行细量化，对高频区域进行粗量化，在相同的量化步长的条件下，非均匀量化比均匀量化所造成的量化误差要小得多。</p>
<p>量化之后，熵编码之前，可以根据从高到低的统计特性，对系数进行Zigzag锯齿扫描和游程长度编码。这样做的原因在于：量化之后的DCT系数更为稀疏，只有少数的AC系数不为0，Zigzag扫描能增加连0的长度，减少统计事件的个数，从而进一步增加对DCT系数熵编码的压缩率。</p>
<p>量化区间上的最优量化值应该是区间的期望值，所以需要知道残差变换系数的统计分布。</p>
<p>引入量化偏移量f来进行非均匀量化，在帧内预测时f=Qstep/3，帧间预测时f=Qstep/6.</p>
<p>f可以控制量化死区大小，f变大，量化死区减少，f变小，量化死区增加。死区大小直接影响图像的主观质量。</p>
<h2 id="去块滤波不是很了解细节">去块滤波（不是很了解细节）</h2>
<p>环路滤波器是被放置在编解码的图像重建环路当中。</p>
<p>在启用了环路滤波的编解码环境中，无论是编码器还是解码器，都是在图像被重建后才进行滤波。</p>
<p>在编码器中，滤波后的图像会作为后续编码运动补偿的参考图像；</p>
<p>在解码器中，滤波后的图像会被输出显示并且作为后续图像解码重建的参考图像。</p>
<h3 id="块效应出现的原因">块效应出现的原因</h3>
<ol>
<li>基于块的量化会破坏相邻块之间的相关性，并且在低码率情况下会放大这种误差。</li>
<li>运动补偿加剧了由变换量化导致的块效应。因为运动补偿块的匹配不可能绝对准确，各个块的残差大小程度存在差异，尤其是当相邻两个块用的参考帧不同、运动矢量或参考块的差距过大时，块边界上产生的数据不连续就更加明显。</li>
</ol>
<h3 id="过程">过程</h3>
<p>估算边界强度、区分真假边界、滤波运算</p>
<h2 id="熵编码">熵编码</h2>
<p>主要利用信源的统计特性进行码率压缩，是无损压缩编码方法。</p>
<p>H264支持CAVLC（变长编码）和CABAC（二进制算术编码）。</p>
<p>CAVLC本质是哈夫曼编码，所以必须为所有可能的长度为N的序列设计和存储编码表，复杂度随N指数增长。</p>
<p>CABAC的思想是用0到1区间上的一个数来表示整个字符输入流，而不是为输入流中的每个字符分别指定码字。</p>
<ul>
<li>算术编码用区间递进的方法为输入流寻找码字，从第一个符号确定的初始区间开始，逐个读入输入流，在每个新的字符出现后递归地划分当前区间，划分的依据是各个字符的概率，将当前区间按照各个字符的概率划分成若干子区间，将当前字符对应的子 2 区间取出，作为处理下一个字符时的当前区间。到处理完最后一个字符后，得到了最终区间，在最终区间中任意挑选一个数作为输出。在解码时候也采用相同的方法和步骤，但是解码器每划分一个子区间就能得到输入流中的一个字符。</li>
<li>在实际过程中，输入流中字符的概率分布是动态改变的，这需要维护一个概率表去记录概率变化的信息。在作递进计算时，通过对概率表中的值估计当前字符的概率，当前字符处理后，需要重新刷新概率表。这个过程表现为对输入流字符的自适应。编码器和解码器按照同样的方法估计和刷新概率表，从而保证编码后的码流能够顺利解码。</li>
</ul>
<p>一般来讲，只要计算量允许，就应该选择使用算术编码。</p>
<p>H264对不同的数据采用不同的熵编码模式，对于宏块和子块的残差数据经过变换之后的系数采用CAVLC，对于其他相对重要的语法元素使用指数哥伦布编码。在CABAC方案里，对不同的语法元素也使用了不同的编码树结构。</p>
<h2 id="gopframesliceibp">GOP/Frame/Slice/I/B/P</h2>
<p>帧Frame包含切片Slice，Slice包含宏块Macroblock(MB)。</p>
<p>一个Frame至少包含一个Slice，一个Slice至少包含一个MB。</p>
<p>Slice是MB的载体，出现的原因是为了防止误码的扩散和传播。</p>
<p>每个Slice都是互相独立被传输的，某个Slice不能以其他Slice中的MB为参考。</p>
<p>Slice存储在NAL单元NALU中，是NALU的有效载荷Payload。</p>
<p>Slice中包含Slice Header和Slice Payload。</p>
<p>Slice Header中存放的是Slice类型、Slice中的宏块类型、Slice属于哪个Frame、对应的帧的设置和参数等信息，Slice Payload中存放的是MB</p>
<p>MB中包含了MB类型、预测类型、Coded Block Pattern(CBP)、量化参数QP、像素的亮度和色度数据等信息</p>
<p>GOP由IDR帧开始，中间存在多个P帧或B帧（基本档次Baseline Profile不存在）</p>
<p>I帧只进行帧内编码，IDR帧是每个GOP的第一个帧，IDR帧是I帧，I帧不一定是IDR帧</p>
<p>P帧参考前面的I帧或者P帧进行编码；</p>
<p>B帧参考前向、后向的I帧或P帧进行编码；</p>
<p>P/B帧进行编码时候只能参考当前GOP的I/P帧，不能越过当前GOP开始时的IDR帧，但是I帧之后的P帧也可以参考这个I帧之前的图像。</p>
<h2 id="spsppsdtspts">SPS/PPS/DTS/PTS</h2>
<p>SPS：序列参数集，描述的是整个视频序列的参数信息，如图像的宽度、高度、帧率、色度空间等，一个视频序列只有一个SPS，用于描述整个视频序列的基本特性。SPS一般在视频码流的开头发送，是一种全局静态的描述方式。当然，如果编码器在编码过程中改变了SPS中描述的参数如分辨率时也需要发送新的SPS。</p>
<p>PPS：图像参数集，描述的是一个序列中一个或多个图像的参数，例如编码图像的配置、QP这些，可以在视频序列的任何时刻发送，PPS相对与SPS来说比较灵活动态。</p>
<p>发I帧之前至少要发一次SPS和PPS</p>
<p>DTS：解码时间序列，编码帧时的顺序</p>
<p>PTS：展示时间序列，展示帧时的顺序，当有B帧时PTS不等于DTS</p>
<p>编码之后的VCL数据被封装进NALU中，构成了h264原始码流</p>
<p></p>
<h2 id="nalu">NALU</h2>
<p>NALU 是视频编码的基本单位，同时也是后续进行视频传输的基本单位。</p>
<p>不同应用需求采用不同的传输方式，NALU 根据传输方式可以以两种方式应用于传输业务。</p>
<ul>
<li>
<p>一类是字节流，即把 NALU 按照解码顺序生成连续的比特流进行传输和处理。</p>
</li>
<li>
<p>一类是分组流应用，也是本文使用的实时视频通信的应用场景，网络可以根据不同网络分组的重要性优化视频流的服务质量，分组流通过将编码后得到的 NALU 作为网络传输的载荷。</p>
</li>
</ul>
<p>NALU由NAL Header和RBSP组成，Header占一个字节，分为3个部分。</p>
<p>第1个部分是第0位，禁止位，值为0，值为1表示语法错误。</p>
<p>第2个部分是第1~2位，表示当前NAL的优先级。值越高表示当前NAL越重要，越需要优先保护。SPS/PPS/IDR帧非常重要，I/P帧重要，B帧/SEI不重要</p>
<p>第3个部分是第3~7位，表示当前NALU的类型：</p>
<p></p>
<p>RBSP：原始字节序列载荷，是NALU数据部分的封装格式，封装的数据来自于SODB（原始数据比特流）。</p>
<p>SODB是编码后的原始数据。SODB到RBSP的过程：
如果SODB是空的，生成的RBSP也是空的。
否则：
RBSP的第一个字节直接取自SODB的第1~8个bit，（RBSP字节内的bit按照从左到右对应位从高到低的顺序排列），RBSP其余的每个字节都直接取自SODB的相应bit。RBSP的最后一个字节包含SODB的最后几个Bit和rbsp_trailing_bits()
rbsp_trailing_bits的第一个bit是1，接下来填充0直到字节对齐。
最后添加几个cabac_zero_word，值为0x0000.</p>
<p>NALU主要涉及到SPS/PPS/SEI和Slice这几种类型。</p>
<p>SEI是补充增强信息，提供了向视频码流中加入额外信息的方法，不是解码过程中的必须选项，可能对解码过程有帮助，集成在视频码流中。</p>
<p>RBSP 字节流加上0x0300就得到 NALU 载荷字节流：</p>
<p></p>
<h2 id="profilelevel">Profile/Level</h2>
<p>Profile主要对视频编码的特性做了差异化支持。</p>
<p></p>
<p>H264中的常用Profile有Baseline，Extended，Main和High</p>
<p>Baseline Profile：基本画质，只支持I/P帧和CAVLC和无交错</p>
<p>Extended Profile：进阶画质，支持I/P/B/SP/SI，只支持CAVLC和无交错</p>
<p>Main Profile：主流画质，支持I/P/B帧和，交错和无交错、CAVLC和CABAC</p>
<p>High Profile：高级画质：在Main的基础上增加了8x8内部预测、自定义量化和更多的yuv格式。</p>
<p>Baseline Profile主要用于实时视频通信，Main Profile和High Profile主要用于流媒体领域。</p>
<p>Level主要根据设备能力来确定编解码时的码率/分辨率上限支持</p>
<h2 id="cbrvbrabrcrf">CBR/VBR/ABR/CRF</h2>
<p>CBR：恒定码率，每秒传输的bit数固定，每个视频帧都被分配相同数量的bit，和复杂度无关，适用于要求网络或者存储带宽具有固定容量的场景，但可能导致复杂场景下的帧质量下降。WebRTC中使用的就是CBR。</p>
<p>VBR：可变码率，允许每个帧使用不同的比特数，根据图像复杂度和需要进行动态分配。适合于在不同场景下需要保持一致质量的情况，但是消耗的带宽会有较大波动。适合用于视频存储，不适合网络传输。</p>
<p>ABR：平均码率，允许在整个视频序列中有一定的变化，但是在一个时间窗口内保持一定的平均码率。在此时间内，对简单、静态的图像分配低于平均码率的码率，对于复杂的、大量运动的图像分配高于平均码率的码流。码率分配比较均衡，比较适合网络传输。</p>
<p>CRF：恒定质量因子，追求的是恒定的视觉质量，编码器根据图像内容自动调整码率，以保持相对恒定的质量。适合于追求质量而不在乎码率的场景如视频剪辑和存档。</p>
<h2 id="openh264码控">OpenH264码控</h2>
<p>编码第一个IDR帧时使用固定的QP，具体的值使用视频分辨率作为判断依据并查表得出并将其初始化为initialQP：</p>
<p></p>
<p>将QP查表转换为QStep完成初始化：</p>
<p></p>
<p>之后进行IDR帧的量化及后续编码操作，并得到frameDqBits（已编码的比特数），由此可以计算intraCmplx：</p>
<p></p>
<p>对于第一个PFrame，linearCmplx也使用下面的公式计算，其中QStep使用initialQP查表。</p>
<p></p>
<p>之后计算QStep&amp;QP时就使用一阶RQ模型计算，frameComplexity在预处理阶段得出。</p>
<p></p>
<h2 id="rtp">RTP</h2>
<p>RTP（Real-time Transport Protocol，实时传输协议）是一种应用层协议，通常基于 UDP 协议，但也支持 TCP 协议。</p>
<p>它提供了端到端的实时传输数据的功能，但不包含资源预留存 1（resource reservation）、不保证实时传输质量，这些功能都需要 WebRTC 自己实现。</p>
<p>RTP 协议分为两种子协议，分别是 RTP Data Transfer Protocol 和 RTP Control Protocol。</p>
<p>前者顾名思义，是用来传输实时数据的；后者则是我们常说的 RTCP 协议，可以提供实时传输过程中的统计信息（如网络延迟、丢包率等），WebRTC 正是根据这些信息处理丢包。</p>
<p>RT(D)P 包分为两部分，分别是 header 和 payload，header 包含了实时音视频的同步信息（和一些额外参数），payload 则承载了具体的音视频数据。这里我们只需要关注 header 结构就好，payload 是编解码器关心的。</p>
<p></p>
<p>如图所示，RT(D)P header 最小为 12 bytes；红色部分为可选字段。字段的含义分别如下：</p>
<ul>
<li>Version 表示 RTP 协议的版本，目前版本为 2。</li>
<li>P (Padding) 表示 RT(D)P 包末尾是否有 padding bytes，且 padding bytes 的最后一个 byte 表示 bytes 的数量。Padding 可以被用来填充数据块，比如加密算法可能会用到。</li>
<li>X (Extension) 表示是否有头部扩展，头部扩展可以用于存储信息，比如视频旋转角度。</li>
<li>CC (CSRC count) 表示红色部分的 CSRC（参见下文）数量，显然最多只能有 15 个 CSRC。</li>
<li>M (Marker) 表示当前数据是否与应用程序有某种特殊的相关性。比如传输的是一些私有数据，或者数据中的某些标志位具有特殊的作用。</li>
<li>PT (Payload type) 表示 payload 的数据类型，音视频的默认映射格式可参见 RFC 3551。</li>
<li>Sequence number 是递增的序列号，用于标记每一个被发送的 RT(D)P 包。接收方可以根据序列号按顺序重新组包，以及识别是否有丢包。序列号的初始值应当是随机的（不可预测的），从而增加明文攻击的难度。</li>
<li>Timestamp 即时间戳，接收方根据其来回放音视频。时间戳的间隔由传输的数据类型（或具体的应用场景）确定，比如音频通常以 125µs（8kHz）的时钟频率进行采样，而视频则以 90kHz 的时钟频率采样。这里时间戳的初始值也是随机选取的，是一种相对时间戳。</li>
<li>SSRC (Synchronization source) 即同步源标识符。相同 RTP 会话中的 SSRC 是唯一的，且生成的 SSRC 也需要保持随机。尽管多个源选中同一个标识符的概率很低，但具体实现时仍然需要这种情况发生，即避免碰撞。</li>
<li>CSRC (Contributing source) 在 MCU 混流时使用，表示混流出的新的音视频流的 SSRC 是由哪些源 SSRC 贡献的。根据上述 CC 得知，我们最多可以同时混 15 路音视频流。</li>
<li>Extension header 即头部扩展，包含了音视频的一些额外信息，比如视频旋转角度。</li>
</ul>
<h3 id="rtp与nalu分组">RTP与NALU分组</h3>
<p>RFC3984 给出了3 中不同的RTP 打包方案：</p>
<ol>
<li>Single NALU Packet：在一个RTP 包中只封装一个NALU，对于小于 1400字节的NALU 便采用这种打包方案。</li>
<li>Aggregation Packet：在一个RTP 包中封装多个NALU，对于较小的NALU 可以采用这种打包方案，从而提高传输效率。</li>
<li>Fragmentation Unit：一个NALU 封装在多个RTP包中，在本文中，对于大于1400字节的NALU 便采用这种方案进行拆包处理。</li>
</ol>
<h2 id="rtcp">RTCP</h2>
<p>RTCP 协议提供实时传输过程中的统计信息，如网络延迟、丢包率等。</p>
<p>在传统的实时通讯过程中，RT(D)P 协议占用偶数位的端口，而 RTCP 协议占用随后的奇数位端口。</p>
<p>不过如果接收方的 SDP 中包含 rtcp-mux 字段 6，即表明接收方支持 RT(D)P 协议和 RTCP 协议共用同一个端口，即多路复用。在 Chrome 57 版本已经强制开启了 rtcp-mux 。</p>
<p>对于 RTCP 包而言，我们不只要关注 header 的结构，还要关注具体的 report block 内容。不过我们先来看一个典型的 RTCP header 结构，如下图所示：</p>
<p></p>
<p>RTCP header 的固定大小为 8 bytes，其中 Version、P、SSRC 的含义同上述 RTP header 相同，在此不与赘述。其他几个字段的含义分别如下：
RC (Reception report count) 表示当前 RTCP 包有几个 block，显然最多只能有 32 个。</p>
<ul>
<li>PT (Packet type) 表示 RTCP 包的类型，比如 SR=200、RR=201（SR、RR 参见下文）。</li>
<li>Length 等于整个 RTCP 包的长度减一（使得 Length = 0 是合法的），其值包含 header 的长度和所有 padding 占用的空间长度。值的单位是以 32 位字长（32-bit words）描述的。</li>
</ul>
<h2 id="psnrssimvmafbd-rate">PSNR/SSIM/VMAF/BD-Rate</h2>
<h3 id="psnr">PSNR</h3>
<p>峰值信噪比，基于均方误差（MSE）计算。</p>
<p>公式：</p>
<p>$$
PSNR = 10 \cdot log_{10}(\frac{MAX_I^2}{MSE})
$$</p>
<p>$$
MSE = \frac{1}{MN}\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}[I(i,j) - K(i,j)]^2
$$</p>
<p>对于用8bit表示的视频图像而言，MAX就是255</p>
<p>PSNR的物理含义就是信号的峰值与平均误差的比值，如果误差越小，那么PSNR值越高。如果完全没有误差，那么PSNR值就是无穷大。</p>
<p>对于图像数据来说，通常有Y、U、V三个分量，可以对三个分量各自计算PSNR。</p>
<p>也可以把三个分量的PSNR值以一定的权重加起来作为总的PSNR值。</p>
<p>对于整个视频来说，可以计算单帧的PSNR值，然后平均，也可以计算整个视频的Overall PSNR。</p>
<ul>
<li>
<p>一般，psnr值高于40dB，表示画面质量极好，（非常接近于原始图像）；</p>
</li>
<li>
<p>psnr值在30dB-40dB之间，表示画面质量较好（有失真但可接受）；</p>
</li>
<li>
<p>psnr值在20dB-30dB之间，表示画面质量差；</p>
</li>
</ul>
<h3 id="ssim">SSIM</h3>
<p>PSNR指标比较常用，但是不能体现编码前后图像之间的相关性，SSIM可以从亮度，对比度和结构三个方面来描述编码前后图像之间的相似性。</p>
<ul>
<li>
<p>亮度维度的相似性用均值计算，𝝁𝒙为均值：</p>
<p></p>
</li>
<li>
<p>对比度维度的相似性用方差计算，𝝈𝒙 为方差：</p>
<p></p>
</li>
<li>
<p>结构维度的相似性用协方差计算， 𝝈𝒙𝒚 表示协方差：</p>
<p></p>
</li>
</ul>
<p>SSIM指标和SSIM计算公式：</p>
<p></p>
<p>SSIM性质：</p>
<p></p>
<h3 id="vmaf">VMAF</h3>
<p>VMAF 是一种 Full reference 的视频质量评估方法，适用于视频流媒体质量评估。</p>
<p>主要包括三种指标：视觉信息保真度 (VIF: visualquality fidelity) 、细节损失指标 (DLM: detail loss measure) 、时域运动指标/平均相关位置像素差 (Tl: temporal information) 。</p>
<ul>
<li>其中 VIF 和 DLM 是空间域的一个画面之内的特征。</li>
<li>TI 是时间域的，多个画面之间相关性的特征。</li>
</ul>
<p>这些特性之间融合计算总分的过程使用了训练好的 SVM 来预测。</p>
<p>VMAF 基于 SVM 的 nuSvr 算法，在运行的过程中，根据事先训练好的 model，赋予每种视频特征以不同的权重。对每一帧画面都生成一个评分。最终以均值算法进行汇总，算出该视频的最终评分</p>
<p>使用方式：</p>
<p>计算时需要保证编码后图像的分辨率与原始图像分辨率一致，如果不一致需要向上或者向下缩放编码图像，而不能缩放原始图像。</p>
<h3 id="bd-rate">BD-Rate</h3>
<p>比较两个编码器的RD曲线（Rate-Distortion）的差异：</p>
<ul>
<li>一种是相同质量下的码率差异，指标为BD-Rate。</li>
<li>一种是相同码率下的质量差异，指标为BD-PSNR。</li>
</ul>
<p>BD-Rate是选取一个范围的的多个采样点（通常是4个），然后进行曲线拟合插值，最后计算出平均的指标差异。目前大部分测试数据的对比，都是基于BDRate指标的。</p>
<h2 id="视频封装">视频封装</h2>
<p>视频的封装格式定义的是多媒体数据的存储结构，包括如何组织和存储音频、视频、字幕、元数据等信息，以及怎么进行同步和时间标记。</p>
<p>感觉封装其实可以理解为是一个柜子，并且对柜子里的不同抽屉里面能存放哪些数据以及怎么存放数据做了规定。\</p>
<p>常见的封装格式有Mp4、Mkv，微软的AVI、苹果的MOV、Adobe的FLV、Google的Webm。</p>
<p>不同的封装格式提供了一种统一的方式来存储和传输各种编码格式的多媒体数据。</p>
<p>H264支持AnnexB和AVCC两种封装模式。</p>
<ul>
<li>
<p>AnnexB模式是传统模式，有startcode，SPS和PPS在码流中分别作为一个NALU。</p>
</li>
<li>
<p>AVCC模式没有startcode，SPS和PPS以及其它信息被封装在container中，每个frame前面4个字节是这个frame的长度。一般在mp4和mkv中使用AVCC。</p>
</li>
</ul>
<h2 id="硬件编码和软件编码">硬件编码和软件编码</h2>
<p>硬编码是通过专用的硬件编码器，比如GPU或者专用的视频编码芯片来进行的，硬件编码可以利用专为编码设计的电路从而提供更高的编码速度和更低的功耗，适用于实时性要求较高的应用比如云游戏、视频会议这些场景。硬编码也通常会在移动设备比如手机或者其他的专业视频设备中使用</p>
<p>软编码是通过通用的计算设备，一般来讲就是用CPU编码。软编码的性能和功耗一般来讲要比硬件编码差，但是可以跨平台运行，容易升级和更新，编码的画质也会更好。一般用于需要更大灵活性和可定制性的应用，比如短视频录制、非实时的转码等。</p>
<h2 id="码率和分辨率">码率和分辨率</h2>
<p>码率提高和分辨率提高都会增大视频的体积，两者之间需要平衡。</p>
<ul>
<li>
<p>在码率一定的情况下，提高分辨率可能会导致每个像素获得的比特数减少，从而降低整体感知质量。</p>
</li>
<li>
<p>在分辨率一定的情况下，提高码率可以分配更多的比特给每个像素，从而提高每个像素的清晰度。</p>
</li>
</ul>
<p>高分辨率主要是为了适应更大的屏幕尺寸，或者需要更多图像细节的任务。</p>
<p>其实屏幕尺寸和分辨率之间的关系有点类似于分辨率和码率之间的关系。</p>
<h2 id="一个视频文件能否倒放">一个视频文件能否倒放</h2>
<p>一个文件不行，至少需要两个文件才可以。</p>
<p>理论上方式有两种：</p>
<ul>
<li>
<p>第一种是先顺序解码视频到一个yuv文件中，然后倒序读入内存进行编码。</p>
</li>
<li>
<p>第二种是先遍历视频，获取一共有多少个GOP，跳到最后一个GOP的IDR帧，对这个GOP进行解码输出到yuv文件中，再逆序读出这个解码之后的yuv文件然后编码，这样最后一个GOP就变成了第一个GOP，按照从后往前的顺序依次类推就可以。</p>
</li>
</ul>
<p>第一种方式简单粗暴好实现，但是对于磁盘存储空间的要求比较高。</p>
<h2 id="h265hevc比h264avc做了哪些改进">H265(HEVC)比H264(AVC)做了哪些改进</h2>
<ul>
<li>
<p>H265针对编码的各个环节都引入各自对应的单元。</p>
<ul>
<li>
<p>与H264中宏块类似的是，在 H.265里面用的是一系列互不重叠的编码树单元CTU处理信息，CTU内部可以以四叉树结构递归向下划分成更小的正方形编码单元CU。CU可以支持最大64x64的尺寸，因而可以对高分辨率视频中的平坦和复杂区域做有针对性的CTU划分。</p>
</li>
<li>
<p>预测单元PU是定义在CU上的一个矩形区域，用来存储和预测相关的所有信息如帧内预测方向、帧间预测的参考帧、和MV等。</p>
</li>
<li>
<p>变换单元TU是变换和量化的基本单位，支持4种正方形的尺寸大小(4/8/16/32)。变换时采用RQT技术，基于四叉树结构进行自适应变换。大块的 TU 模式能够将能量更好地集中，小块的 TU 模式能够保存更多的图像细节。根据当前 CU 内残差特性，自适应选择变换块大小，可以在能量集中和细节保留两者做最优的折中。与传统的固定块大小变换相比，RQT 对编码效率贡献更大。</p>
</li>
<li>
<p>CU划分成PU和TU，PU和TU之间存在交叉重叠关系，Inter预测时允许CU内的TU跨越PU边界，Intra预测时，TU不能跨越PU边界。</p>
</li>
</ul>
</li>
<li>
<p>在帧内预测模块，H265支持更多的帧内预测模式。H265的亮度分量支持35种帧内预测模式包括平面模式、DC模式和33种角度模式，色度分量有5种帧内预测模式包括平面模式、DC模式、水平、垂直方向模式和对应于亮度分量的帧内预测模式。</p>
</li>
<li>
<p>在帧间预测模块，H265引入了更加复杂的ME方式，主要包括Merge和AMPV以及基于Merge的Skip模式。</p>
<ul>
<li>Merge：取相邻PU的运动参数作为当前PU的运动参数（利用空域相关性和时域相关性）</li>
<li>AMVP得到的MV一方面为ME提供了搜索起点，另一方面也用于预测MV。AMVP根据周围块预测MV，MV=MVP+MVD(矢量差值)</li>
</ul>
</li>
<li>
<p>H265把变换和量化模块结合了起来，降低了计算复杂度，支持加权量化矩阵。</p>
</li>
<li>
<p>在环路滤波模块，H265新增了采样点自适应偏移滤波SAO，通过解析去方块滤波后的像素的统计特性，为像素添加相应的偏移值，削弱振铃效应。</p>
</li>
<li>
<p>因为H265的解码要比h264的解码复杂很多，所以提供了很多可以并行优化的思路。</p>
</li>
</ul>
<h2 id="simd">SIMD</h2>
<p>SIMD是一种并行计算技术，允许单一指令处理多个数据元素。SIMD指令集通常由处理器提供，用于加速向量化计算。视频编码中，SIMD可以用于加速压缩和解压算法。</p>
<h2 id="h264中的差错控制">H264中的差错控制</h2>
<p>Slice分割、Data Partition (DPA &gt; DPB &gt; DPC)、对SPS和PPS提供使用高传输优先级、差异化的熵编码（对重要的SPS和PPS采用指数哥伦布编码）</p>
<p>FMO通过宏块分配映射把同一帧里的不同宏块划分到不同的Slice Group里，在同一个Slice Group里的MB按照普通的光栅扫描顺序编码。</p>
<p>因为不管是Intra Coding还是Inter Coding都必须使用同一个Slice group的宏块数据，这样当一个Slice group里的某一个或者某几个宏块发生错误时候，因为相邻的宏块可能分布在不同的Slice group，就可以从其他正确接收的Slice group里拿到和丢失宏块相邻的宏块信息来进行错误掩盖。</p>
<h2 id="svc">SVC</h2>
<p>SVC：(Scalable Video Coding)可伸缩视频编码，编码器产生的码流包含一个或者多个子码流或者层，子码流可以有不同的码流、帧率和分辨率。基本层编码最低层的时域、空域和质量流；增强层以基本层作为起始点，对附加信息进行，从而在解码过程中重构更高层的质量、分辨率和时域层。通过解码基本层和相邻增强层，解码器能生成特定层的视频流。</p>
<ul>
<li>
<p>时域分层：从码流中提取出有不同帧频的码流。</p>
</li>
<li>
<p>空域分层：从码流中提取出有不同分辨率的码流。</p>
</li>
<li>
<p>质量分层：从码流中提取出有不同质量的码流。</p>
</li>
</ul>
<h3 id="应用场景">应用场景</h3>
<p>监控：监控视频流产生两路，一路质量好的用于存储，一路低码率的用于预览。</p>
<p>视频会议：会议终端利用SVC编出多种分辨率、分层质量的码流，会议中心替代传统的MCU二次编解码方法改成视频路由分解转发。也可以在丢包环境下利用时域分级，抛弃一些时域级别实现网络适应性。</p>
<p>流媒体IPTV：服务器可以根据不同的网络情况丢弃质量层，保证视频的流畅。兼容不同网络环境和终端。</p>
<h3 id="优缺点">优缺点</h3>
<p>优点：分级码流优点是应用非常灵活，因为能根据需要产生不同的码流或者提取出不同的码流。使用SVC实现一次分层编码比用AVC编多次更高效。
SFU从发布客户端复制音视频流的信息，然后分发到多个订阅客户端。典型的应用场景是1对多的直播服务。SFU是解决服务端性能问题的好方法，因为它不涉及视频解码和编码的计算费用，用最低的开销来转发各路媒体流，能实现海量的客户端接入。重终端，轻平台。</p>
<p>缺点：因为SVC解码控制复杂不利于流式处理，硬件编解码器支持差，协议协商细节复杂，业界标准不统一。</p>
<h2 id="rtc应用中提高实时性">RTC应用中提高实时性</h2>
<p>因为编码主要的时间开销在运动预测过程中，如果在云游戏的场景下，可以得到游戏画面中物体的运动信息然后考虑用来辅助运动预测，或者说对搜索过程进行剪枝。</p>
]]></description>
</item>
<item>
    <title>远程桌面与WebRTC</title>
    <link>https://ayamir.github.io/posts/knowledge/webrtc/remote-desktop-with-webrtc/</link>
    <pubDate>Thu, 15 Jun 2023 18:21:02 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/knowledge/webrtc/remote-desktop-with-webrtc/</guid>
    <description><![CDATA[<h1 id="关于远程桌面">关于远程桌面</h1>
<p>远程桌面是一种将一台计算机的桌面控制权限交给网络上另一台计算机的技术，两台计算机之间建立连接之后，可以进行音视频以及控制信令的相互传输，从而实现远程控制的功能。</p>
<h1 id="远程桌面技术的实现">远程桌面技术的实现</h1>
<p>基于远程桌面要完成的任务目标，其需要实现以下两个核心功能：</p>
<ol>
<li>音视频的传输，即需要让控制机收到受控机的音频跟视频。</li>
<li>控制信令的传输，即鼠标键盘的控制信号等</li>
</ol>
<p>目前主流的远程桌面技术主要有2种：</p>
<ol>
<li>基于<a href="https://en.wikipedia.org/wiki/Virtual_Network_Computing" target="_blank" rel="noopener noreffer">VNC(Virtual Network Computing)</a>的远程桌面技术</li>
<li>基于<a href="https://en.wikipedia.org/wiki/Remote_Desktop_Protocol" target="_blank" rel="noopener noreffer">RDP(Remote Desktop Protocol)</a>的远程桌面技术</li>
</ol>
<h2 id="vnc">VNC</h2>
<p>VNC使用远程帧缓冲协议即(RFB, Remote FrameBuffer)来远程控制另一台计算机，将控制机的键盘和鼠标事件传输到被控制机，同时将被控制机的屏幕图像传输到控制机。</p>
<p>基于其技术原理，VNC有以下优点：</p>
<ol>
<li>跨平台，可以在不同的操作系统上运行，VNC技术本身也有多个客户端和服务端的实现版本，如RealVNC、TightVNC、UltraVNC等</li>
<li>开源，VNC的源代码及其很多现代衍生品都是在GNU许可证之下发布的</li>
<li>轻量级，VNC的客户端和服务端都是非常轻量级的程序，可以在低配置的计算机上运行</li>
</ol>
<p>但因为VNC本身的设计时间很早，因此在2023年的今天暴露出了很多的时代局限性：</p>
<ol>
<li>因为其基于像素方块的传输原理，就算是采用部分更新传输的方式，在大量像素变化的情况下会消耗大量的带宽。特别是对于现在的高分屏，其传输的数据量会更大。</li>
<li>VNC在设计之初被用于局域网内使用，因此没有考虑太多的安全性，虽然密码并不以明文发送，但是如果从网络中嗅探出加密密钥和编码之后的密码，也可能成功破解出密码。</li>
</ol>
<h2 id="rdp">RDP</h2>
<p>RDP是<a href="https://learn.microsoft.com/en-us/troubleshoot/windows-server/remote/understanding-remote-desktop-protocol" target="_blank" rel="noopener noreffer">微软提出的一种专有协议</a>，扩展了T-120系列协议标准，最早专用于Windows系统的终端和服务器之间的远程桌面连接，之后微软也实现了<a href="https://learn.microsoft.com/en-us/windows-server/remote/remote-desktop-services/clients/remote-desktop-mac" target="_blank" rel="noopener noreffer">RDP的MacOS客户端</a>，现在也有很多第三方的实现版本实现了其功能的子集，为GNU/Linux做了适配如<a href="https://github.com/neutrinolabs/xrdp" target="_blank" rel="noopener noreffer">xrdp</a>。因此，可以说RDP也一定程度上具有跨平台的性质。</p>
<p>相比于VNC，RDP的实现原理还是比较复杂的：</p>
<p></p>
<p>首先，RDP的最底层是TCP，TCP之上是各层的协议和服务。</p>
<ul>
<li>TPKT：是TCP之上的ISO传输服务，允许两个组交换TPDU（传输协议数据单元）或PDU（协议数据单元）的信息单元。</li>
<li>X.224：连接传输协议，主要用于RDP初始连接请求和响应。</li>
<li>T.125 MCS：多点通信服务，允许RDP通过多个通道进行通信和管理。</li>
</ul>
<p>RDP的工作原理是通过TPKT实现信息单元的交换，通过X.224建立连接，使用T.125 MCS打开两个通道来完成两个设备之间的来回数据传输。</p>
<p>RDP的特点功能比较丰富，比如：</p>
<ul>
<li>支持共享剪切板。</li>
<li>支持多个显示器。</li>
<li>支持虚拟化GPU。</li>
<li>支持32位彩色和64000个独立的数据传输通道。</li>
<li>通过RC4对称加密算法使用128位密钥对数据进行加密。</li>
<li>可以在使用远程计算机时参考本地计算机上的文件系统。</li>
<li>远程计算机的应用程序可以在本地计算机上运行。</li>
</ul>
<p>当然，事物都有两面性，RDP拥有这么多强大功能，也有一些难以避免的缺点：</p>
<ul>
<li>网络速度较慢时，远程连接容易出现延迟。</li>
<li>两台计算机在不同的网络上时，其配置过程相当复杂。</li>
<li>固定使用3389端口监听，可能成为攻击的目标。</li>
<li>RDP整体上还是受到微软控制，定制性比较差。</li>
</ul>
<h1 id="webrtc和远程桌面">WebRTC和远程桌面</h1>
<p>远程桌面的核心需求和WebRTC的核心功能完美契合。</p>
<ul>
<li>WebRTC基于ICE/STUN/TURN的NAT穿透方案可以很方便地解决不同网络情况下主机连接的问题，</li>
<li>WebRTC基于SRTP的传输方式天然提供了实时特征、端到端的加密的数据传输服务。</li>
<li>WebRTC针对各种网络情况做了音视频传输的大量优化，可以保证各种网络条件下的可用性。</li>
<li>WebRTC本身其实是Chromium浏览器的一部分，天然具备跨平台的性质。</li>
<li>WebRTC完全开源，定制性极强，不少公司都基于WebRTC来做自家的直播、云游戏业务。</li>
</ul>
<p>整体上来讲，WebRTC的优势使其很适合用于远程桌面业务，当然，目前市面上已经有App基于WebRTC实现了远程桌面的功能，比如<a href="https://en.wikipedia.org/wiki/Chrome_Remote_Desktop" target="_blank" rel="noopener noreffer">Chrome Remote Desktop</a>和<a href="https://www.todesk.com/" target="_blank" rel="noopener noreffer">ToDesk</a>。前者可以理解为是Google用自己WebRTC推出的远程桌面服务，体验了一下，整体上功能比较少，但是连接比较稳定，不过受GFW影响，这玩意在国内应该是处于没法用的状态；后者则是国产远程桌面软件，目前已经比较成熟，提供了企业版、个人版、专业版和游戏版四个版本，从其官网上提供的信息来看，应该是做出了一定成绩。</p>
<p>从技术上讲，基于WebRTC开发远程桌面应用相当合理，开源可控，还有谷歌背书，WebRTC本身在不停地与时俱进，作为上层应用开发的远程桌面也可以及时享受到WebRTC带来的改进。</p>
<p>从业务上讲，WebRTC本身具有的功能可以解决上面所说的VNC和RDP的诸多问题，不过就功能的丰富性而言，可能跟微软的RDP还差一些，但是WebRTC基于音视频的解决方案本身可以优化的上限还是挺高的，毕竟随着人们需求的上升，高分辨率、高帧率也会成为未来远程桌面应用必不可少的功能需求。</p>
<p>本篇博客从非技术层面探讨了远程桌面技术的当下两大主流技术，以及WebRTC应用于远程桌面业务下的可行性。下篇博客将从技术层面详细分析WebRTC与远程桌面业务的契合程度及可能的解决方案，就先从核心功能开始吧！</p>
]]></description>
</item>
<item>
    <title>在Linux下如何搭建WebRTC的开发环境</title>
    <link>https://ayamir.github.io/posts/development/webrtc-development-prepare/</link>
    <pubDate>Sun, 23 Apr 2023 21:28:38 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/development/webrtc-development-prepare/</guid>
    <description><![CDATA[<p>本文主要记录笔者在 Gentoo Linux 下面搭建 WebRTC 开发环境的过程。</p>
<h2 id="准备工作">准备工作</h2>
<ol>
<li>网络：可以科学上网的梯子</li>
<li>IDE：VSCode 或者 CLion</li>
</ol>
<h2 id="安装depot_tools">安装<code>depot_tools</code></h2>
<p>Google 有自己的一套用于管理 Chromium 项目的工具，名叫<code>depot_tools</code>，其中有包括<code>git</code>在内的一系列工具和脚本。</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># 创建google目录用于存储google相关的代码</span>
</span></span><span class="line"><span class="cl">mkdir ~/google
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> ~/google
</span></span><span class="line"><span class="cl"><span class="c1"># clone depot_tools</span>
</span></span><span class="line"><span class="cl">git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git
</span></span></code></pre></td></tr></table>
</div>
</div><p>克隆完成之后需要将<code>depot_tools</code>的路径加到<code>PATH</code>中，Linux 上添加环境变量最简单的方式是修改<code>~/.profile</code>，这种方式与你的登录 shell 是什么没有关系，不管是<code>fish</code>还是<code>bash</code>还是<code>zsh</code>都会吃这种方式：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="c1"># ~/.profile</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">GOOGLE_BIN</span><span class="o">=</span><span class="nv">$HOME</span>/google/depot_tools
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$GOOGLE_BIN</span>:<span class="nv">$PATH</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>但是这种方式需要你注销重新登录。</p>
<h2 id="克隆代码">克隆代码</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">mkdir webrtc-checkout
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> webrtc-checkout
</span></span><span class="line"><span class="cl">fetch --nohooks webrtc
</span></span><span class="line"><span class="cl">gclient sync
</span></span></code></pre></td></tr></table>
</div>
</div><p>整个 WebRTC 的项目代码大小约 20G，克隆过程中需要保证网络畅通顺畅，如果你的梯子有大流量专用节点最好，否则可能克隆完你的流量就用光了。</p>
<p>克隆期间可能会因为网络问题中断，重新执行<code>gclient sync</code>即可，直到所有的模块都克隆完毕。</p>
<p>按照官方的建议，克隆完成之后创建自己的本地分支，因为官方分支更新很快，不 checkout 的话，可能你的 commit 还没写完，就被 Remote 的 change 给覆盖了，还要手动处理冲突。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nb">cd</span> src
</span></span><span class="line"><span class="cl">git checkout master
</span></span><span class="line"><span class="cl">git new-branch &lt;branch-name&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="编译-webrtc">编译 WebRTC</h2>
<p>关于 WebRTC 的版本可以在<a href="https://chromiumdash.appspot.com/branches" target="_blank" rel="noopener noreffer">Chromium Dash</a>查到：</p>

<p>如上图所示，113 分支是当前的稳定分支，对应的 tag 是<code>branch-heads/5672</code>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nb">cd</span> ~/google/webrtc-checkout/src
</span></span><span class="line"><span class="cl">git checkout branch-heads/5672
</span></span><span class="line"><span class="cl">git switch -c m113
</span></span></code></pre></td></tr></table>
</div>
</div><p>创建本地分支之后就可以用<code>gn</code>生成<code>ninja</code>文件了：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">gn gen out/Default --root<span class="o">=</span><span class="s2">&#34;.&#34;</span> --args<span class="o">=</span><span class="s1">&#39;is_debug=true target_os=&#34;linux&#34; target_cpu=&#34;x64&#34; rtc_include_tests=false rtc_use_h264=true rtc_enable_protobuf=false is_clang=true symbol_level=0 enable_iterator_debugging=false is_component_build=false use_rtti=true rtc_use_x11=true use_custom_libcxx=false treat_warnings_as_errors=false use_ozone=true&#39;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这里使用了<code>clang</code>并且启用了<code>h264</code>，详细的<code>gn</code>参数可以参考<a href="https://www.chromium.org/developers/gn-build-configuration/" target="_blank" rel="noopener noreffer">gn-build-configuration</a>和项目根目录下的<code>webrtc.gni</code>文件。</p>
<p>之后使用<code>autoninja</code>进行编译，编译时会吃满你 PC 的所有核心，编译时间取决于你 PC 的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">autoninja -C out/Default
</span></span></code></pre></td></tr></table>
</div>
</div>
<p>可以看到默认生成了几个样例的可执行文件。</p>

<p>cd 到<code>obj</code>目录下可以看到<code>libwebrtc.a</code>文件，就是编译链接之后最终生成的可以引用的库文件。</p>
<h2 id="搭建开发环境">搭建开发环境</h2>
<p>Google 官方给出了 Chromium 项目的<a href="https://chromium.googlesource.com/chromium/src.git/&#43;/master/docs/clion.md#Building_Running_and-Debugging-within-CLion" target="_blank" rel="noopener noreffer">CLion 配置指南</a>，所以只需要照猫画虎给 WebRTC 配置一下。</p>
<h3 id="配置-clion-属性">配置 CLion 属性</h3>
<p>因为整个项目比较大，所以需要调大 CLion 的 VM 内存和 intellisence 支持的文件大小：</p>
<p><code>Help</code>-&gt; <code>Edit Custom VM Options</code>，在文件的末尾添加：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">-Xmx8g
</span></span></code></pre></td></tr></table>
</div>
</div><p>表示给 VM 设定<code>8G</code>的可用内存，这样基本上不用担心使用过程因为内存不足而 CLion 性能不够了。</p>
<p><code>Help</code>-&gt;<code>Edit Custom Properties</code>，在文件的末尾添加：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">idea.max.intellisense.filesize=12500
</span></span></code></pre></td></tr></table>
</div>
</div><p>表示为大小为<code>12500KB</code>也就是<code>12M</code>以下的文件提供 intellisense 支持。</p>
<h3 id="配置-gdb">配置 gdb</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">vim ~/.gdbinit
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 添加下面一行</span>
</span></span><span class="line"><span class="cl"><span class="nb">source</span> ~/google/webrtc-checkout/src/tools/gdb/gdbinit
</span></span></code></pre></td></tr></table>
</div>
</div><p>之后在 CLion 中的<code>Settings</code>-&gt;<code>Toolchain</code>-&gt;<code>Debugger</code>选择系统自带的 gdb：<code>/usr/bin/gdb</code>即可。</p>
<h3 id="配置-intellisense">配置 intellisense</h3>
<p>因为 WebRTC 用的是<code>gn</code>+<code>ninja</code>作为构建工具，而<code>CLion</code>目前只支持<code>cmake</code>，所以当要求配置<code>CMakeLists.txt</code>时直接无视即可。网络上有说用<code>gn_to_cmake.py</code>这个脚本的，但是我没看懂这东西的功能，反正是不能生成<code>CMakeLists.txt</code>，只是生成一个<code>json</code>文件，并不能用于 CLion 的索引。</p>
<p>我这边成功开启 IDE 语法高亮和索引的姿势是这样的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="n">cd</span> <span class="n">webrtc</span><span class="o">-</span><span class="n">checkout</span><span class="o">/</span><span class="n">src</span>
</span></span><span class="line"><span class="cl"><span class="n">python3</span> <span class="o">./</span><span class="n">tools</span><span class="o">/</span><span class="n">clang</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">generate_compdb</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">p</span> <span class="o">./</span><span class="n">out</span><span class="o">/</span><span class="n">Default</span> <span class="o">-</span><span class="n">o</span> <span class="o">./</span><span class="n">compile_commands</span><span class="o">.</span><span class="n">json</span> <span class="o">--</span><span class="n">target_os</span><span class="o">=</span><span class="n">linux</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这一步会生成 CLion 可以自动识别的<code>compile_commands.json</code>文件，从而可以正确索引项目的代码并提供代码补全功能。</p>

<p>之后每次启动项目 CLion 就会自动索引项目文件，就可以愉快地看代码和写代码啦！</p>
]]></description>
</item>
<item>
    <title>WebRTC 中关于视频自适应的相关设置</title>
    <link>https://ayamir.github.io/posts/knowledge/webrtc/note-for-webrtc-1/</link>
    <pubDate>Thu, 15 Sep 2022 20:48:51 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/knowledge/webrtc/note-for-webrtc-1/</guid>
    <description><![CDATA[<h1 id="概况">概况</h1>
<p><code>WebRTC</code>提供了视频自适应机制，其目的主要是通过降低编码的视频的质量来减少带宽和 CPU 消耗。</p>
<p>视频自适应发生的情形：带宽或 CPU 资源发出信号表明自己未被充分使用或被过度使用时，进行视频自适应。过度使用则降低质量，否则提高质量。</p>
<p>视频自适应调整的对象：帧率与分辨率。</p>
<h1 id="资源">资源</h1>
<p><code>Resources</code>监测指标来自于系统或视频流。例如，一个资源可以监测系统温度或者视频流的带宽使用率。</p>
<p>资源实现了<code>Resource</code>接口：</p>
<ul>
<li>当资源检测到被过度使用则调用<code>SetUsageState(kOveruse)</code>；</li>
<li>当资源不再被过度使用则调用<code>SetUsageState(kUnderuse)</code>。</li>
</ul>
<p>对所有的视频而言，默认有两种类型的资源：</p>
<ul>
<li>质量标量资源</li>
<li>编码过度使用资源</li>
</ul>
<h2 id="qp-标量资源">QP 标量资源</h2>
<p>质量标量资源监测发送视频流中编码之后的帧的量化参数（QP），确保视频流的对于当前的分辨率而言可以接受。</p>
<p>每一帧被编码之后，<code>QualityScaler</code>就能获得相应的 QP。</p>
<p>过度使用或者未被充分使用的信号在平均 QP 脱离 QP 阈值之后发出。</p>
<p>QP 阈值在<code>EncoderInfo</code>中的<code>scaling_settings</code>属性中设置。</p>
<p>需要注意的是 QP 标量只在降级偏好设置为<code>MAINTAIN_FRAMERATE</code>或<code>BALANCED</code>时启用。</p>
<h2 id="编码使用资源">编码使用资源</h2>
<p>编码使用资源监测编码器需要花多长时间来编码一个视频帧，实际上这是 CPU 使用率的代理度量指标。</p>
<p>当平均编码使用超过了设定的阈值，就会触发过度使用的信号。</p>
<h2 id="插入其他资源">插入其他资源</h2>
<p>自定义的资源可以通过<code>Call::AddAdaptationResource</code>方法插入。</p>
<h1 id="自适应">自适应</h1>
<p>资源发出过度使用或未充分使用的信号之后，会发送给<code>ResourceAdaptationProcessor</code>，其从<code>VideoStreamAdapter</code>中请求<code>Adaptation</code>提案。这个提案基于视频的降级偏好设置。</p>
<p><code>ResourceAdaptationProcessor</code>基于获得的提案来确定是否需要执行当前的<code>Adaptation</code>。</p>
<h2 id="降级偏好设置">降级偏好设置</h2>
<p>有 3 种设置，在<code>RtpParameters</code>的头文件中定义：</p>
<ul>
<li><code>MAINTAIN_FRAMERATE</code>: 自适应分辨率</li>
<li><code>MAINTAIN_RESOLUTION</code>: 自适应帧率</li>
<li><code>BALANCED</code>: 自适应帧率或分辨率</li>
</ul>
<p>降级偏好设置在<code>RtpParameters</code>中的<code>degradation_perference</code>属性中设置。</p>
<h1 id="videosinkwants和视频流自适应"><code>VideoSinkWants</code>和视频流自适应</h1>
<p>自适应完成之后就会通知视频流，视频流就会转换自适应为<code>VideoSinkWants</code>。</p>
<p>这些接收器需求向视频流表明：在其被送去编码之前需要施加一些限制。</p>
<p>对于自适应而言需要被设置的属性为：</p>
<ul>
<li><code>target_pixel_count</code>: 对于每个视频帧要求的像素点总数，为了保持原始的长宽比，实际的像素数应该接近这个值，而不一定要精确相等，</li>
<li><code>max_pixel_count</code>: 每个视频帧中像素点的最大数量，不能被超过。</li>
<li><code>max_framerate_fps</code>: 视频的最大帧率，超过这个阈值的帧将会被丢弃。</li>
</ul>
<p><code>VideoSinkWants</code>可以被任何视频源应用，或者根据需要可以直接使用其基类<code>AdaptationVideoTraceSource</code>来执行自适应。</p>
]]></description>
</item>
<item>
    <title>Note for DQB</title>
    <link>https://ayamir.github.io/posts/papers/note-for-dqb/</link>
    <pubDate>Sun, 20 Mar 2022 22:09:11 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/papers/note-for-dqb/</guid>
    <description><![CDATA[<h1 id="整体概况">整体概况</h1>
<p>Link：<a href="https://ieeexplore.ieee.org/document/9317771" target="_blank" rel="noopener noreffer">Modeling the Perceptual Quality for Viewport-Adaptive Omnidirectional Video Streaming Considering Dynamic Quality Boundary Artifact</a>
Level：IEEE TCSVT 2021</p>
<p>DQB: Dynamic Quality Boundary，指在基于分块的 FoV 自适应全景视频推流过程中低质量分块区域的暴露和质量切换现象。</p>
<p>DQB 现象实际上就是 FoV 内分块间的质量差异和随时间变化的分块质量变化。
这篇论文主要的贡献在于深入研究了这种现象，并且针对此提出了可以利用现存的 QoE 评估指标的模型，并且可以实际应用。</p>
<h1 id="model-的建立">Model 的建立</h1>
<ol>
<li>执行一系列主观评估，由低质量分块的比例和质量导致的感知质量的降低可以基于主观实验结果完成建模。</li>
<li>结合剩下分块的感知质量可以完成单帧质量模型的建模。</li>
<li>最后将一段时间内的所有帧的感知质量池化，就完成了整个的模型。</li>
</ol>
<h2 id="主观实验的设定">主观实验的设定</h2>
<ol>
<li>获得 FoV 内帧的感知质量（低质量分块和高质量分块同时存在）</li>
<li>获取整个视频的感知质量（与上面的实验过程相近，只是过程中没有暂停）</li>
<li>获取整个视频的感知质量（没有引入 DQB，所有分块质量相同）</li>
</ol>
<p>实验结果</p>
<p></p>
<h2 id="帧质量感知模型">帧质量感知模型</h2>
<p>从上面的实验结果可以看出来高质量区域与低质量区域的质量差距 $d_n$ 越大，DQB 效应越显著（符合直觉）。将这部分影响因素看作是感知质量的主要影响因素：</p>
<p>$$
d_n = Q_{H, n} - Q_{L, n}
$$</p>
<p>$Q_{H, n}$ 和 $Q_{L, n}$ 分别表示第 $n$个 帧高质量分块和低质量分块的感知质量。
这两个质量从主观实验 3 的主观质量获得，在之后的训练过程中可以被客观质量评估的结果所替换。</p>
<p>为了调查质量差异 $d_n$ 和感知质量降低 $D_n$ 之间的关系，通过使用实验 1 的帧质量分数计算得出第$n$个帧的感知质量降低：</p>
<p>$$
D_n = Q_{H, n} - Q_{HL, n}
$$</p>
<p>$Q_{HL, n}$是实验 1 中评分得到的第$n$个帧的 FoV 内感知质量。</p>
<p>在 6 个视频上的实验结果如下图：</p>
<p></p>
<p>可以看到二者的关系可以近似为线性相关，即：</p>
<p>$$
D_n = k_1 d_n
$$</p>
<p>$k_1$ 作为线性回归的参数，可以计算出来。</p>
<p>但是对于不同取值的 $p_n$ ， $k_1$ 的取值也相当不同，两者之间的关系可以见下图：</p>
<p></p>
<p>数学表示可以建模为：</p>
<p>$$
k_1 = a_1 \cdot ln(a_2 \cdot p_n + a_3) \cdot sgn(p_n - P)
$$</p>
<p>$sgn$ 是符号函数，$a_1, a_2, a_3$ 可以从回归中计算出来， $P$ 表示低质量分块的比例。按照图中的回归结果，$P = 0.118$ 时，用户几乎没办法注意到低质量区域的存在。</p>
<p>最终，由低质量区域暴露引起的感知质量降低 $D_n$ 可以计算为：</p>
<p>$$
D_n = a_1 \cdot ln(a_2 \cdot p_n + a_3) \cdot (Q_{H, n} - Q_{L, n}) \cdot sgn(p_n - P)
$$</p>
<p>那么实际的感知质量 $Q_n$ 可以计算为：</p>
<p>$$
Q_n = Q_{H, n} - D_n
$$</p>
<h2 id="时间池化">时间池化</h2>
<p>可以采用下面两种方式之一完成</p>
<h3 id="exp-minkowski-basedhttpsieeexploreieeeorgdocument6603210"><a href="https://ieeexplore.ieee.org/document/6603210" target="_blank" rel="noopener noreffer"><code>Exp Minkowski-Based</code></a></h3>
<p>单个帧的感知质量由衰减指数加权，衰减指数表示在主观评估中观察到的<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/3299/1/Viewer-response-to-time-varying-video-quality/10.1117/12.320109.short?SSO=1" target="_blank" rel="noopener noreffer">近因效应</a>。</p>
<p>最终整个视频的感知质量 $PQ$ 可以计算为：</p>
<p>$$
PQ = \Big[\frac{1}{N} \sum_{n=1}^{N} exp\big( \frac{n-N}{\delta} \big) \cdot {Q_n}^p \Big]^{1/p}
$$</p>
<p>$N$ 是整个视频的帧数。</p>
<p>$p$ 是 <code>Minkowski</code>指数，高 $p$ 值强调了最高质量帧的影响。</p>
<p>$\delta$ 是控制近因效应强度的指数时间常数，以帧的数量的形式给出，高 $\delta$ 值对应较弱的近因效应。</p>
<p>$p$ 和 $\delta$ 的值可以通过对主观帧质量和视频序列的整体质量进行回归得到。</p>
<h3 id="quality-contribution-basedhttpsieeexploreieeeorgdocument6235989"><a href="https://ieeexplore.ieee.org/document/6235989" target="_blank" rel="noopener noreffer"><code>Quality Contribution-Based</code></a></h3>
<p>之前的研究表明，传统视频在时间维度上的感知质量降低主要与每帧的显示时长相关。</p>
<p>FoV 自适应的全景视频也与之类似，感知质量与降低质量帧和高质量帧的持续时间相关。因此采用<code>Quality Contribution</code>的概念来描述每帧对视频感知质量的影响（考虑每帧的空间感知质量和显示时长）。</p>
<p>时间池化是由相应的显示时长加权的每帧的质量贡献的函数，特别的，质量贡献是从 MOS 和显示持续时间之间初步找到的对数关系所导出的：</p>
<p>$$
C_n = Q_n \cdot (p_1 + p_2 \cdot log(T))
$$</p>
<p>$C_n$ 是第 $n$ 帧的贡献， $T$ 是每帧的显示时长， $T = Max(T, 33.3ms)$，即当帧率不低于 30fps 时，时间不连续性可以忽略。</p>
<p>接着，二级时间池化法用于池化单帧的分布。这种方法将 FoV 内的帧以注视水平划分为短时帧组(GoFs)，并以 GoF 的质量作为长期时间池化的基本单位来评估感知质量。</p>
<p>给出每帧的质量贡献之后，每个 GoF 的质量可以计算为</p>
<p>$$
Q_{GoF} = \frac{\sum_{n \in N} \big( C(n) \cdot T(n) \big)}{\sum_{n \in N} T(n)}
$$</p>
<p>接下来组合 GoF 的质量得到长期时间池化，即可以获得感知质量。</p>
<p>质量严重受损的帧会影响相邻帧的感知质量，视频中质量最差的部分主要决定整个视频的感知质量。因此提出选择计算出的质量低于平均值 75%的 GoF，以此计算平均质量并作为整个视频的感知质量。</p>
]]></description>
</item>
<item>
    <title>Note for Toward Immersive Experience</title>
    <link>https://ayamir.github.io/posts/papers/note-for-toward-immersive-experience/</link>
    <pubDate>Wed, 09 Mar 2022 11:20:37 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/papers/note-for-toward-immersive-experience/</guid>
    <description><![CDATA[<h1 id="overview">Overview</h1>
<p>Link: <a href="https://ieeexplore.ieee.org/document/9679801" target="_blank" rel="noopener noreffer">Toward Immersive Experience: Evaluation for Interactive Network Services</a></p>
<p>Level: IEEE Network 2022</p>
<p>Keywords: QoE Metrics</p>
<h1 id="background">Background</h1>
<p>Compared with traditional QoE for regular video/audio services, the existing work on IE is still in its infancy. This work aims at providing systematic and comprehensive research on IE for interactive network services, mainly studying the following three fundamental and challenging issues.</p>
<ul>
<li><em>What is the essential difference between IE and traditional QoE?</em></li>
<li><em>Which categories of factors mainly influence IE?</em></li>
<li><em>How to evaluate IE in an efficient and intelligent manner?</em></li>
</ul>
<h1 id="ie-versus-traditional-qoe">IE versus traditional QoE</h1>
<h2 id="theoretical-definitions">Theoretical definitions</h2>
<p>Existing concepts of IE can be classified into two categories.</p>
<ul>
<li>The subjective sense of being surrounded or experiencing multi-sensory stimulation when interacting with the virtual environment.</li>
<li>The user&rsquo;s psychological state of deep involvement, engagement, absorption, or engrossment.</li>
</ul>
<p>Traditional QoE:</p>
<ul>
<li>A subjective measure from the user perspective of the overall value of the provided service and application.</li>
</ul>
<p>We can summary two significant points as follows to distinguish IE and traditional QoE:</p>
<ul>
<li>Both IE and traditional QoE are devoted to characterizing user&rsquo;s subjective experience for network services.</li>
<li>In terms of application scenarios, IE concentrates on the evaluation of network services equipped with interactive characteristics while traditional QoE is generally appropriate for regular audio/video services.</li>
</ul>
<p>IE is much more complex, fine-grained and multi-dimensional perception, which is produced through the interplay between multi-sensory data and diverse cognitive processes.</p>
<h2 id="technical-challenges">Technical challenges</h2>
<ul>
<li>Growing data volume</li>
<li>Stricter delay constraint</li>
<li>Increasing data dimension</li>
</ul>
<h2 id="ifs-on-ie">IFs on IE</h2>
<p></p>
<h2 id="network-aware-ifs">Network-aware IFs</h2>
<p>Actually, when heterogeneous streams are delivered to the network, their transmission quality is dependent on the outside network conditions(e.g., delay, jitter, throughput, and so on), as well as the streaming strategy (e.g., encoding, transmission protocol, and so on) inside streams, which ultimately impact end users&rsquo; IE. To this end, we can further subdivide this category into two classes including network QoS and stream-related IFs.</p>
<ul>
<li>
<p>QoS:</p>
<ul>
<li>low latency</li>
<li>high throughput</li>
<li>high reliability</li>
<li>temporal synchronization among heterogeneous streams</li>
</ul>
</li>
<li>
<p>stream-related IFs</p>
<ul>
<li>the form of data compression strategy</li>
<li>resource scheduling scheme</li>
</ul>
</li>
</ul>
<h2 id="user-aware-ifs">User-aware IFs</h2>
<p>IE may be influenced by human users while human users can perceive IE, for which we can subdivide this category into three classes based on such correlations.</p>
<ul>
<li>User profile</li>
<li>Physiological IFs</li>
<li>Psychological IFs</li>
</ul>
<p>It is obvious that users with diverse user profiles have distinctive influences on IE.</p>
<p>The psychology and physiology of users can highly reflect the IE for the application.</p>
<ul>
<li>For psychological IFs, they are able to directly demonstrate a user&rsquo;s positive or negative feedback for interactive network services. However, this can hardly be simply measured.</li>
<li>For physiological IFs, some of them(e.g., heart rate, blood pressure) can be objectively measured by affordable medical sensors.</li>
</ul>
<h2 id="device-aware-ifs">Device-aware IFs</h2>
<p>With regard to device-aware IFs, two broad classes can be gotten according to internal systems(e.g., CPU) and external specifications(e.g., screen size, FOV) of the device.</p>
<p>IE management in the device level mainly lies in two aspects.</p>
<ul>
<li>The selection of terminal type(e.g., mobile phone, laptop, VR/AR glasses)</li>
<li>The corresponding possession of hardware(e.g., CPU, GPU, battery).</li>
</ul>
<h2 id="context-aware-ifs">Context-aware IFs</h2>
<p>Typically, IE for interactive network services is generated by interacting with the virtual environment. To this end, we can derive two primary classes.</p>
<ul>
<li>Virtual context: focuses on the specific virtual application scenario.</li>
<li>Physical context: focuses on its surrounding physical environment.</li>
</ul>
<p>We can provide constructive suggestions for different contexts. For example, online virtual games are  appropriate to play outside for the broad horizon, but watching a 3D film is more proper inside the home.</p>
<p>We can suggest appropriate application types with different technical requirement to guarantee users&rsquo; IE according to existing network resources and the surrounding environment.</p>
<p></p>
<h1 id="light-weight-ie-evaluation">Light-weight IE evaluation</h1>
<p>We proposed two light-weight IE evaluation approaches by respectively exploiting the AI technology and exploring the mathematical relationship among IFs and IE, which are appropriate for different cases according to the data amount.</p>
<h2 id="ai-based">AI-based</h2>
<p>Existing popular studies focusing on DL-based models(e.g., DNNs, LSTMs) can hardly satisfy the stringent delay requirement.</p>
<p>We employ a multi-view learning combining with lightweight ML methods(e.g., SVM, decision tree) for fast and accurate IE evaluation.</p>
<p></p>
<p>The raw data through multi-view learning is first represented by multiple feature extractors according to their heterogeneous properties. Each modality is regraded as a particular view for multi-modal applications. Motivations are:</p>
<ol>
<li>It can provide efficient dimension reduction via subspace mapping. Subspace learning-based approaches can map the high-dimensional raw data to a latent subspace, in which its dimensionality is lower than that of raw data.</li>
<li>Multi-view learning is more applicable to the IE context with abundant infomation, which can overcome the weakness of ML-based methods regarding evaluation accuracy for interactive network services.</li>
<li>Multi-view learning can take full advantage of the associated and complementary features from redundant views for evaluation performance improvement.</li>
</ol>
<h2 id="statistical-function-based">Statistical function-based</h2>
<p>AI-based approach may achieve better evaluation performances under large amounts of data, they lack strong interpretability and cannot explicitly explain the inherent relations among IFs and IE.</p>
<p>We introduced statistical function-based approach to analyze the mathematical relationship among IFs and IF under limited data.</p>
<p>Existing statistical function-based approaches for user experience evaluation are broadly divided into three categories:</p>
<ul>
<li>Exponential model</li>
<li>Logarithmic model</li>
<li>Linear regression model</li>
</ul>
<p>Notably, in order to further improve evaluation performance for interactive network services via statistical function-based approaches, two fundamental and significant issues need to be concerned as follows:</p>
<ol>
<li>How to comprehensively explore diverse and various IFs for accurate IE evaluation?</li>
<li>How to conduct an efficient dimension reduction method for fast IE evaluation?</li>
</ol>
<h1 id="case-study">Case study</h1>
<h2 id="multi-view-generation">Multi-view generation</h2>
<p>We can construct multiple views from expert prior knowledge or via the random subspace method, which is a random sampling algorithm for automatic feature set partitioning. Here we partition multi-modal data into three specific views according to different modalites.(e.g., audio, video, and haptic signals).</p>
<h2 id="view-combination">View combination</h2>
<p>Then we adopt subspace learning-based approaches to obtain an appropriate subspace from the above-mentioned multiple views. Importantly, canonical correlation analysis in subspace learning plays a significant role in dimension reduction, and outputs the optimal projection for each view.</p>
<h3 id="ie-evaluation">IE evaluation</h3>
<p>Finally, based on the optimal and combined projection subspace, decision tree is deployed here to evaluation IE.</p>
<p>The key point is find a general and robust evaluation approach:
$$
f: X \rarr Y
$$
Result is:
$$
Y = X^{\top} {\beta} + {\epsilon}
$$
${\epsilon}$ is the noise, ${\beta}$ can be considered as influencing degree of various IFs to the IE.</p>
<p>IE evaluation for multi-modal applications must satisfy more stringent delay requirements in the context of higher-dimensional data. So we apply the <a href="https://www.doi.org/10.1080/10618600.1998.10474784" target="_blank" rel="noopener noreffer">LASSO estimation</a>, which is equipped with sparse solutions for the linear regression model, is incorporated to alleviate the issue of high-dimensional data for fast IE evaluation.</p>
<p>Dataset: <a href="http://8.133.175.194/" target="_blank" rel="noopener noreffer">VisTouch</a></p>
<p>Compare obejcts:</p>
<ul>
<li>Ridge regression</li>
<li>Exponential model</li>
</ul>
<p>Performance metric: MAE</p>
<p>Test result:</p>
<p></p>
]]></description>
</item>
<item>
    <title>MLflow 的用法</title>
    <link>https://ayamir.github.io/posts/development/note-for-mlflow/</link>
    <pubDate>Mon, 07 Mar 2022 19:25:46 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/development/note-for-mlflow/</guid>
    <description><![CDATA[<h1 id="overview">Overview</h1>
<p><code>MLflow</code>是一个用于管理机器学习全生命周期的框架。</p>
<p>其主要的作用是：</p>
<ul>
<li>完成训练和测试过程中不同超参数的结果的记录、对比和可视化——<code>MLflow Tracking</code></li>
<li>以一种可复现重用的方式包装 ML 代码——<code>MLflow Projects</code></li>
<li>简化模型部署的难度——<code>MLflow Models</code></li>
<li>提供中心化的模型存储来管理全生命周期——<code>MLflow Model Registry</code></li>
</ul>
<p>现在主要用到的是第三个，所以先记录<code>Models</code>的用法</p>
<h1 id="mlflow-models">MLflow Models</h1>
<p><code>MLflow Models</code>本质上是一种格式，用来将机器学习模型包装好之后为下游的工具所用。</p>
<p>这种格式定义了一种惯例来让我们以不同的<code>flavor</code>保存模型进而可以被下游工具所理解。</p>
<h2 id="存储格式">存储格式</h2>
<p>每个<code>MLflow Model</code>是一个包含任意文件的目录，根目录之下有一个<code>MLmodel</code>文件，用于定义多个<code>flavor</code>。</p>
<p><code>flavor</code>是<code>MLflow Model</code>的关键概念，抽象上是部署工具可以用来理解模型的一种约定。</p>
<p><code>MLflow</code>定义了其所有内置部署工具都支持的几种标准<code>flavor</code>，比如描述如何将模型作为<code>Python</code>函数运行的<code>python_function</code> <code>flavor</code>。</p>
<p>目录结构示例如下：</p>
<p></p>
<p><code>MLmode</code>文件内容示例如下：</p>
<p></p>
<p>这个模型可以用于任何支持<code>pytorch</code>或<code>python_function</code> <code>flavor</code>的工具，例如可以使用如下的命令用<code>python_function</code>来 serve 一个有<code>python_function</code> <code>flavor</code>的模型：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">mlflow models serve -m my_model
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="model-signature">Model Signature</h2>
<p>模型的输入输出要么是<code>column-based</code>，要么是<code>tensor-based</code>。</p>
<ul>
<li><code>column-based</code> inputs and outputs can be described as a sequence of (optionally) named columns with type specified as one of the <code>MLflow data type</code>.</li>
<li><code>tensor-based</code> inputs and outputs can be described as a sequence of (optionally) named tensors with type specified as one of the <code>numpy data type</code>.</li>
</ul>
<h3 id="signature-enforcement">Signature Enforcement</h3>
<p>Schema enforcement checks the provided input against the model&rsquo;s signature and raises an exception if the input is not compatible. It only works when using <code>MLflow model</code> deployment tools or loading models as <code>python_function</code>. It has no impact on native model.</p>
<h4 id="name-ordering-enforcement">Name Ordering Enforcement</h4>
<p>The input names are checked against the model signature. If there are any missing inputs, <code>MLflow</code> will raise an exception. Extra inputs will be ignored. Prioritized method is matching by name if provided in input schema, then according to position.</p>
<h4 id="input-type-enforcement">Input Type Enforcement</h4>
<p>For <code>column-based</code> signatures, <code>MLflow</code> will perform safe type conversions if necessary. Only lossless conversions are allowed.</p>
<p>For <code>tensor-based</code> signatures, type checking is strict(any dismatch will throw an exception).</p>
<h4 id="handling-integers-with-missing-values">Handling Integers With Missing Values</h4>
<p>Integer data with missing values is typically represented as floats in <code>Python</code>.</p>
<p>Best way is to declare integer columns as doubles whenever there can be missing values.</p>
<h4 id="handling-data-and-timestamp">Handling Data and Timestamp</h4>
<p><code>Python</code> has precision built into the type for datatime values.</p>
<p>Datetime precision is ignored for <code>column-based</code> model signature but is enforced for <code>tensor-based</code> signatures.</p>
<h3 id="log-models-with-signatures">Log Models with Signatures</h3>
<p>Pass signature object as an argument to the appropriate log_model call to include a signature with model. The model signature object can be created by hand or inferred from datasets with valid model inputs and valid model outputs.</p>
<h4 id="column-based-example"><code>Column-based</code> example</h4>
<p>The following example demonstrates how to store a model signature for a simple classifier trained on the <code>Iris</code> dataset:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlflow</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">infer_signature</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">iris_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris_train</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">signature</span> <span class="o">=</span> <span class="n">infer_signature</span><span class="p">(</span><span class="n">iris_train</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">iris_train</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="s2">&#34;iris_rf&#34;</span><span class="p">,</span> <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The same signature can be created explicitly as follows:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">ModelSignature</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">ColSpec</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">input_schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">  <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&#34;double&#34;</span><span class="p">,</span> <span class="s2">&#34;sepal length (cm)&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&#34;double&#34;</span><span class="p">,</span> <span class="s2">&#34;sepal width (cm)&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&#34;double&#34;</span><span class="p">,</span> <span class="s2">&#34;petal length (cm)&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&#34;double&#34;</span><span class="p">,</span> <span class="s2">&#34;petal width (cm)&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">output_schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&#34;long&#34;</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl"><span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_schema</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="tensor-based-example"><code>Tensor-based</code> example</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlflow</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">mlflow.keras</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">infer_signature</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">),</span> <span class="p">(</span><span class="n">test_X</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">trainX</span> <span class="o">=</span> <span class="n">train_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">testX</span> <span class="o">=</span> <span class="n">test_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">trainY</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_Y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">testY</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_Y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">signature</span> <span class="o">=</span> <span class="n">infer_signature</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&#34;mnist_cnn&#34;</span><span class="p">,</span> <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The same signature can be created explicitly as follows:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">ModelSignature</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">TensorSpec</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">input_schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">  <span class="n">TensorSpec</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">output_schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">([</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))])</span>
</span></span><span class="line"><span class="cl"><span class="n">signature</span> <span class="o">=</span> <span class="n">ModelSignature</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_schema</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_schema</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="model-input-example">Model Input Example</h2>
<p>Model inputs can be <code>column-based</code> (i.e <code>DataFrame</code>) or <code>tensor-based</code> (i.e <code>numpy.ndarrays</code>).</p>
<p>A model input example provides an instance of a valid model input which can be stored as separate artifact and is referenced in the <code>MLmodel</code> file.</p>
<h3 id="log-model-with-column-based-example">Log Model with <code>column-based</code> example</h3>
<p>An example can be a single record or a batch of records. The sample input can be passed in as a Pandas <code>DataFrame</code>, <code>list</code> or <code>dict</code>. The given example will be converted to a Pandas <code>DataFrame</code> and then serialized to json using the Pandas split-oriented format.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">input_example</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;sepal length (cm)&#34;</span><span class="p">:</span> <span class="mf">5.1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;sepal width (cm)&#34;</span><span class="p">:</span> <span class="mf">3.5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;petal length (cm)&#34;</span><span class="p">:</span> <span class="mf">1.4</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;petal width (cm)&#34;</span><span class="p">:</span> <span class="mf">0.2</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="log-model-with-tensor-based-example">Log Model with <code>Tensor-based</code> example</h3>
<p>An example must be a batch of inputs. The axis 0 is the batch axis by default unless specified otherwise in the model signature. The sample input can be passed in as a numpy <code>ndarray</code> or a <code>dict</code> mapping a string to a numpy <code>array</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># each input has shape (4, 4)</span>
</span></span><span class="line"><span class="cl"><span class="n">input_example</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">   <span class="p">[[</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span>  <span class="mi">25</span><span class="p">,</span>  <span class="mi">56</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="mi">253</span><span class="p">,</span> <span class="mi">242</span><span class="p">,</span> <span class="mi">195</span><span class="p">,</span>   <span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">93</span><span class="p">,</span>  <span class="mi">82</span><span class="p">,</span>  <span class="mi">82</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">   <span class="p">[[</span>  <span class="mi">0</span><span class="p">,</span>  <span class="mi">23</span><span class="p">,</span>  <span class="mi">46</span><span class="p">,</span>   <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span> <span class="mi">33</span><span class="p">,</span>  <span class="mi">13</span><span class="p">,</span>  <span class="mi">36</span><span class="p">,</span> <span class="mi">166</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span> <span class="mi">76</span><span class="p">,</span>  <span class="mi">75</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span> <span class="mi">33</span><span class="p">,</span>  <span class="mi">44</span><span class="p">,</span>  <span class="mi">11</span><span class="p">,</span>  <span class="mi">82</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mlflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="model-api">Model API</h2>
<p><code>MLflow</code> includes integrations with several common libraries. For example, <code>mlflow.sklearn</code> contains <code>save_model</code>, <code>log_model</code>, and <code>load_model</code> functions for <code>scikit-learn</code> models.</p>
<p>Additionally, we can use <code>mlflow.models.Model</code> class to create and write models which has 4 key functions:</p>
<ul>
<li><code>add_flavor</code> to add a flavor to the model. Each <code>flavor</code> has a <code>string</code> name and a <code>dict</code> of key-value attributes, where the values can be any object that can be serialized to YAML.</li>
<li><code>save</code> to save the model to a local directory.</li>
<li><code>log</code> to log the model as an artifact in the current run using <code>MLflow tracking</code>.</li>
<li><code>load</code> to load a model from a local directory or from an artifact in a previous run.</li>
</ul>
<h3 id="pytorch">Pytorch</h3>
<p><code>mlflow.pytorch</code> module defines utilities for saving and loading <code>MLflow Models</code> with the <code>pytorch</code> flavor.</p>
<p>We can use <code>mlflow.pytorch.save_model()</code> and <code>mlflow.pytorch.log_model()</code> methods to save <code>pytorch</code> models in <code>MLflow</code> format.</p>
<p>We can use <code>mlflow.pytorch.load_mode()</code> to load <code>MLflow Models</code> with <code>pytorch</code> flavor as <code>pytorch</code> model objects. This loaded <code>PyFunc</code> model can be scored with both <code>DataFrame</code> input and numpy <code>array</code> input.</p>
]]></description>
</item>
<item>
    <title>WebGL 样例的解释</title>
    <link>https://ayamir.github.io/posts/knowledge/webgl/webgl-samples-explanation/</link>
    <pubDate>Thu, 03 Mar 2022 10:31:38 &#43;0800</pubDate><author>miracle_l@bupt.edu.cn (Ayamir)</author><guid>https://ayamir.github.io/posts/knowledge/webgl/webgl-samples-explanation/</guid>
    <description><![CDATA[<h1 id="context">Context</h1>
<ol>
<li>Create an <code>HTML5</code> canvas</li>
<li>Get the canvas id</li>
<li>Obtain <code>WebGL</code> Context</li>
</ol>
<p>The parameter <code>WebGLContextAttributes</code> is not mandatory.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Attributes</th>
<th style="text-align:center">Description</th>
<th style="text-align:center">Default value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>alpha</code></td>
<td style="text-align:center">true: provide an alpha buffer to the canvas;</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center"><code>depth</code></td>
<td style="text-align:center">true: drawing buffer contains a depth buffer of at least 16 bits;</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center"><code>stencil</code></td>
<td style="text-align:center">true: drawing buffer contains a stencil buffer of at least 8 bits;</td>
<td style="text-align:center">false</td>
</tr>
<tr>
<td style="text-align:center"><code>antialias</code></td>
<td style="text-align:center">true: drawing buffer performs anti-aliasing</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center"><code>premultipliedAlpha</code></td>
<td style="text-align:center">true: drawing buffer contains colors with pre-multiplied alpha</td>
<td style="text-align:center">true</td>
</tr>
<tr>
<td style="text-align:center"><code>preserveDrawingBuffer</code></td>
<td style="text-align:center">true: buffers will not be cleared and will preserve their values until cleared or overwritten by the author</td>
<td style="text-align:center">false</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">canvas</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s2">&#34;my_canvas&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">context</span> <span class="o">=</span> <span class="nx">canvas</span><span class="p">.</span><span class="nx">getContext</span><span class="p">(</span><span class="s2">&#34;webgl&#34;</span><span class="p">,</span> <span class="p">{</span> <span class="nx">antialias</span><span class="o">:</span> <span class="kc">false</span><span class="p">,</span> <span class="nx">stencil</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="geometry">Geometry</h1>
<h2 id="definition">Definition</h2>
<p>A 2D or 3D model drawn using vertices is call a <code>mesh</code>.</p>
<p>Each facet in a mesh is called a polygon and a polygon is made of 3 or more vertices.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="c1">// create a 2D triangle which lies on the coordinates {(-5, -5), (5, -5), (5, 5)}
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span> <span class="nx">vertices</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span>   <span class="c1">// Vertex 0
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span>   <span class="c1">// Vertex 1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span>    <span class="c1">// Vertex 2
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">];</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>Similarly, we can create an array for the indices follow the sequence.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">];</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>drawArrays()</code>: pass the vertices of the primitive using JavaScript arrays.</li>
<li><code>drawElements()</code>: pass both vertices and indices of the primitive using JavaScript arrays.</li>
</ul>
<h2 id="buffer-objects">Buffer Objects</h2>
<p>A buffer object indicates a memory area allocated in GPU.</p>
<p>We can store data of the models corresponding to vertices, indices, color and etc.</p>
<p>There are 2 types of buffer objects:</p>
<ul>
<li>Vertex Buffer Object(VBO): It holds the per-vertex data of the graphical model that is going to be rendered.</li>
<li>Index Buffer Object(IBO): It holds the indices of the graphical model that is going to be rendered.</li>
</ul>
<p>After defining the required geometry and storing them in JavaScript arrays, we need to pass these arrays to the buffer objects, from where the data will be passed to the shader programs.</p>
<ol>
<li>
<p>Create an empty buffer.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertex_buffer</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">createBuffer</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">index_buffer</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">createBuffer</span><span class="p">();</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Bind an appropriate array object to the empty buffer.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="k">void</span> <span class="nx">bindBuffer</span><span class="p">(</span><span class="kr">enum</span> <span class="nx">target</span><span class="p">,</span> <span class="nb">Object</span> <span class="nx">buffer</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// ARRAY_BUFFER represents vertex data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">gl</span><span class="p">.</span><span class="nx">bindBuffer</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">ARRAY_BUFFER</span><span class="p">,</span> <span class="nx">vertex_buffer</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// ELEMENT_ARRAY_BUFFER represent index data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">gl</span><span class="p">.</span><span class="nx">bindBuffer</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">ELEMENT_ARRAY_BUFFER</span><span class="p">,</span> <span class="nx">index_buffer</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Pass the data (vertices/indices) to the buffer using one of the typed arrays.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="k">void</span> <span class="nx">bufferData</span><span class="p">(</span><span class="kr">enum</span> <span class="nx">target</span><span class="p">,</span> <span class="nb">Object</span> <span class="nx">data</span><span class="p">,</span> <span class="kr">enum</span> <span class="nx">usage</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Usage specifies how to use the buffer object data to draw shapes
</span></span></span><span class="line"><span class="cl"><span class="c1">// gl.STATIC_DRAW -- Data will be specified once and used many times.
</span></span></span><span class="line"><span class="cl"><span class="c1">// gl.STREAM_DRAW -- Data will be specified once and used a few times.
</span></span></span><span class="line"><span class="cl"><span class="c1">// gl.DYNAMIC_DRAW -- Data will be specified repeatedly and used many times.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="c1">// vertex buffer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">gl</span><span class="p">.</span><span class="nx">bufferData</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">ARRAY_BUFFER</span><span class="p">,</span> <span class="k">new</span> <span class="nx">Float32Array</span><span class="p">(</span><span class="nx">vertices</span><span class="p">),</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">STATIC_DRAW</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// index buffer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">gl</span><span class="p">.</span><span class="nx">bufferData</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">ELEMENT_ARRAY_BUFFER</span><span class="p">,</span> <span class="k">new</span> <span class="nx">Uint16Array</span><span class="p">(</span><span class="nx">indices</span><span class="p">),</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">STATIC_DRAW</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Unbind the buffer (Optional/Recommended).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">bindBuffer</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">ELEMENT_ARRAY_BUFFER</span><span class="p">,</span> <span class="kc">null</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h1 id="shader">Shader</h1>
<p>Shaders are written in ES SL which has variables of its own data types, qualifiers, built-in inputs and outputs.</p>
<h2 id="data-types">Data Types</h2>
<table>
<thead>
<tr>
<th style="text-align:center">Type</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>void</code></td>
<td style="text-align:center">empty value</td>
</tr>
<tr>
<td style="text-align:center"><code>bool</code></td>
<td style="text-align:center">true or false</td>
</tr>
<tr>
<td style="text-align:center"><code>int</code></td>
<td style="text-align:center">signed integer</td>
</tr>
<tr>
<td style="text-align:center"><code>float</code></td>
<td style="text-align:center">floating scalar</td>
</tr>
<tr>
<td style="text-align:center"><code>vec2</code>, <code>vec3</code>, <code>vec4</code></td>
<td style="text-align:center">n-component floating point vector</td>
</tr>
<tr>
<td style="text-align:center"><code>bvec2</code>, <code>bvec3</code>, <code>bvec4</code></td>
<td style="text-align:center">boolean vector</td>
</tr>
<tr>
<td style="text-align:center"><code>ivec2</code>, <code>ivec3</code>, <code>ivec4</code></td>
<td style="text-align:center">signed integer vector</td>
</tr>
<tr>
<td style="text-align:center"><code>mat2</code>, <code>mat3</code>, <code>mat4</code></td>
<td style="text-align:center">2x2, 3x3, 4x4 float matrix</td>
</tr>
<tr>
<td style="text-align:center"><code>sampler2D</code></td>
<td style="text-align:center">access a 2D texture</td>
</tr>
<tr>
<td style="text-align:center"><code>samplerCube</code></td>
<td style="text-align:center">access cube mapped texture</td>
</tr>
</tbody>
</table>
<h2 id="qualifiers">Qualifiers</h2>
<table>
<thead>
<tr>
<th style="text-align:center">Qualifier</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>attribute</code></td>
<td style="text-align:center">acts as a link between a vertex shader and OpenGL ES for per-vertex data. Its value changes for every execution of the vertex shader.</td>
</tr>
<tr>
<td style="text-align:center"><code>uniform</code></td>
<td style="text-align:center">links shader programs and the WebGL application. Its value is <code>read-only</code>. It can be used for to declare a variable with any basic data types: <code>uniform vec4 lightPosition;</code>.</td>
</tr>
<tr>
<td style="text-align:center"><code>varying</code></td>
<td style="text-align:center">forms a link between a vertex shader and fragment shader for interpolated data. It can be used with the following data types: <code>float</code>, <code>vec2</code>, <code>vec3</code>, <code>vec4</code>, <code>mat2</code>, <code>mat3</code>, <code>mat4</code>, <code>arrays</code> like: <code>varying vec3 normal;</code></td>
</tr>
</tbody>
</table>
<h2 id="vertex-shader">Vertex Shader</h2>
<p>Vertex shader is a program code, which is called on every vertex. Programmer have to define <code>attribute</code> in code of vertex shader to handle data. The <code>attribute</code> point to a VBO written in JavaScript.</p>
<h3 id="predefined-variables">Predefined Variables</h3>
<p>OpenGL ES SL provides the following predefined variables for every vertex shader</p>
<table>
<thead>
<tr>
<th style="text-align:center">Variables</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>highp vec4 gl_Position</code></td>
<td style="text-align:center">Holds the position of the vertex</td>
</tr>
<tr>
<td style="text-align:center"><code>mediump float gl_PointSize</code></td>
<td style="text-align:center">Holds the transformed point size</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-glsl" data-lang="glsl"><span class="line"><span class="cl"><span class="k">attribute</span> <span class="k">vec2</span> <span class="n">coordinates</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">void</span> <span class="n">main</span><span class="p">(</span><span class="k">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">gl_Position</span> <span class="o">=</span> <span class="k">vec4</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>gl_Position</code> is the predefined variable which is available only in the vertex shader. It contains the vertex position. As vertex shader is a per-vertex operation, the <code>gl_Position</code> value is calculated for each vertex.</p>
<h2 id="fragment-shader">Fragment Shader</h2>
<p>A mesh is formed by multiple triangles, and the surface of each triangle is known as a fragment.</p>
<p>Fragment shader is the code that runs on every pixel on each fragment. This is written to calculate and fill the color on individual pixels.</p>
<h3 id="predefined-variables-1">Predefined Variables</h3>
<table>
<thead>
<tr>
<th style="text-align:center">Variables</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>mediump vec4 gl_FragCoord;</code></td>
<td style="text-align:center">Holds the fragment position within the frame buffer</td>
</tr>
<tr>
<td style="text-align:center"><code>bool gl_FrontFacing;</code></td>
<td style="text-align:center">Holds the fragment that belongs to a front-facing primitive</td>
</tr>
<tr>
<td style="text-align:center"><code>mediump vec2 gl_PointCoord;</code></td>
<td style="text-align:center">Holds the fragment position within a point</td>
</tr>
<tr>
<td style="text-align:center"><code>mediump vec4 gp_FragColor;</code></td>
<td style="text-align:center">Holds the output fragment color value of the shader</td>
</tr>
<tr>
<td style="text-align:center"><code>mediump vec4 gl_FragData[n];</code></td>
<td style="text-align:center">Holds the fragment color for color attachment n</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-glsl" data-lang="glsl"><span class="line"><span class="cl"><span class="k">void</span> <span class="n">main</span><span class="p">(</span><span class="k">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">gl_FragColor</span> <span class="o">=</span> <span class="k">vec4</span><span class="p">(</span><span class="mo">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mo">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="store-and-compiling">Store and Compiling</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertCode</span> <span class="o">=</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;attribute vec2 coordinates;&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;void main(void) {&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;gl_Postion = vec4(coordinates, 0.0, 1.0);&#34;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;}&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">fragCode</span> <span class="o">=</span> <span class="s2">&#34;void main(void) {&#34;</span> <span class="o">+</span> <span class="s2">&#34;gl_FragColor = vec4(0, 0.8, 0, 1);&#34;</span> <span class="o">+</span> <span class="s2">&#34;}&#34;</span><span class="p">;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Compilation involves following 3 steps</p>
<ul>
<li>Creating the shader object</li>
<li>Attaching the source code to the created shader object</li>
<li>Compiling the program</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertShader</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">createShader</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">VERTEX_SHADER</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">shaderSource</span><span class="p">(</span><span class="nx">vertShader</span><span class="p">,</span> <span class="nx">vertCode</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">compileShader</span><span class="p">(</span><span class="nx">vertShader</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Same process for fragment shader</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">fragShader</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">createShader</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">FRAGMENT_SHADER</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">shaderSource</span><span class="p">(</span><span class="nx">fragShader</span><span class="p">,</span> <span class="nx">fragCode</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">compileShader</span><span class="p">(</span><span class="nx">fragShader</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="combined-program">Combined Program</h2>
<ul>
<li>Create a program object</li>
<li>Attach both the shaders</li>
<li>Link both the shaders</li>
<li>Use the program</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">shaderProgram</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">createProgram</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">attachShader</span><span class="p">(</span><span class="nx">shaderProgram</span><span class="p">,</span> <span class="nx">vertShader</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">attachShader</span><span class="p">(</span><span class="nx">shaderProgram</span><span class="p">,</span> <span class="nx">fragShader</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">linkProgram</span><span class="p">(</span><span class="nx">shaderProgram</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">useProgram</span><span class="p">(</span><span class="nx">shaderProgram</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="associating-attributes--buffer-objects">Associating Attributes &amp; Buffer Objects</h1>
<ul>
<li>Get the attribute location</li>
<li>Point the attributes to a vertex buffer object</li>
<li>Enable the attribute</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="c1">// ulong getAttribLocation(Object program, string name)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">let</span> <span class="nx">coordinatesVar</span> <span class="o">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">getAttribLocation</span><span class="p">(</span><span class="nx">shaderProgram</span><span class="p">,</span> <span class="s2">&#34;coordinates&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// void vertexAttribPointer(location, int size, enum type, bool normalized, long stride, long offset)
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">gl</span><span class="p">.</span><span class="nx">vertexAttribPointer</span><span class="p">(</span><span class="nx">coordinatesVar</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">FLOAT</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">enableVertexAttribArray</span><span class="p">(</span><span class="nx">coordinatesVar</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="drawing-a-model">Drawing a Model</h1>
<h2 id="drawarrays">drawArrays()</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-glsl" data-lang="glsl"><span class="line"><span class="cl"><span class="k">void</span> <span class="n">drawArrays</span><span class="p">(</span><span class="k">enum</span> <span class="n">mode</span><span class="p">,</span> <span class="k">int</span> <span class="n">first</span><span class="p">,</span> <span class="k">long</span> <span class="n">count</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>mode: <code>gl.POINTS</code>, <code>gl.LINE_STRIP</code>, <code>gl.LINE_LOOP</code>, <code>gl.LINES</code>, <code>gl.TRIANGLE_STRIP</code>, <code>gl.TRANGLE_FAN</code>, <code>gl.TRIANGLES</code>.</li>
<li>first: specified the starting element in the enabled arrays. (Non-negative)</li>
<li>count: specifies the number of elements to be rendered.</li>
</ul>
<p><code>WebGL</code> will create the geometry in the order in which the vertex coordinates while rendering the shapes.</p>
<p>draw a triangle:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">drawArrays</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">TRIANGLES</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>draw two contiguous triangles:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertices</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">  <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">drawArrays</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">TRIANGLES</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<h2 id="drawelements">drawElements()</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-glsl" data-lang="glsl"><span class="line"><span class="cl"><span class="k">void</span> <span class="n">drawElements</span><span class="p">(</span><span class="k">enum</span> <span class="n">mode</span><span class="p">,</span> <span class="k">long</span> <span class="n">count</span><span class="p">,</span> <span class="k">enum</span> <span class="n">type</span><span class="p">,</span> <span class="k">long</span> <span class="n">offset</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>mode: same as <code>drawArrays()</code>;</li>
<li>count: same as <code>drawArrays()</code>;</li>
<li>type: specifies the data type of the indices which must be <code>UNSIGNED_BYTE</code> or <code>UNSIGNED_SHORT</code>;</li>
<li>offset: specifies the starting point for rendering, usually the first element (0);</li>
</ul>
<p>If use <code>drawElements()</code> to draw a model, then index buffer object should also be created along with the vertex buffer object. The vertex data will be processed once and used as many time as mentioned in the indices.</p>
<p>draw a triangle:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertices</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">drawElements</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">TRIANGLES</span><span class="p">,</span> <span class="nx">indices</span><span class="p">.</span><span class="nx">length</span><span class="p">,</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">UNSIGNED_SHORT</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>draw two contagious triangles:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-javascript" data-lang="javascript"><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">vertices</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">  <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="mf">0.0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="kd">let</span> <span class="nx">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nx">gl</span><span class="p">.</span><span class="nx">drawElements</span><span class="p">(</span><span class="nx">gl</span><span class="p">.</span><span class="nx">TRIANGLES</span><span class="p">,</span> <span class="nx">indices</span><span class="p">.</span><span class="nx">length</span><span class="p">,</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">UNSIGNED_SHORT</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
]]></description>
</item>
</channel>
</rss>
