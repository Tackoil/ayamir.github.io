<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Immersive-Video - 分类 - Ayamir&#39;s Blog</title>
        <link>https://ayamir.github.io/categories/immersive-video/</link>
        <description>Immersive-Video - 分类 - Ayamir&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>miracle_l@bupt.edu.cn (Ayamir)</managingEditor>
            <webMaster>miracle_l@bupt.edu.cn (Ayamir)</webMaster><lastBuildDate>Mon, 15 Nov 2021 10:13:18 &#43;0800</lastBuildDate><atom:link href="https://ayamir.github.io/categories/immersive-video/" rel="self" type="application/rss+xml" /><item>
    <title>沉浸式推流中应用层的优化</title>
    <link>https://ayamir.github.io/posts/note10/</link>
    <pubDate>Mon, 15 Nov 2021 10:13:18 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note10/</guid>
    <description><![CDATA[<h2 id="背景">背景</h2>
<p>大多数的HAS方案使用HTTP/1.1协议进行请求-回应的事务来取得需要的资源、缓冲取到的视频段并以线性的顺序播放。传统的HAS中，只需要1个GET请求来取得下一个视频的暂时的部分。只要视频段的持续时间比网络内的时延高，这种方法就可行。</p>
<p>在基于VR的HAS方案中，播放1条视频片段就需要取得多种资源：1次GET请求需要同时请求基础的tile层和每个空间视频tile。使用4x4的tile方案时，客户端需要发起不少于17次GET请求。使用 1 s 数量级的分段持续时间，即使是 20 ms 的微小网络延迟也会显着阻碍客户端和服务器之间的整体吞吐量，因此会导致较低的视频质量。</p>
<h2 id="解决方案">解决方案</h2>
<h3 id="使用多条持久的tcp连接">使用多条持久的TCP连接</h3>
<p>大多数的现代浏览器都支持同时建立并维持多达6条TCP连接来减少页面加载时间，并行地获取请求的资源。这允许增加整体吞吐量，并部分消除网络延迟引入的空闲 RTT 周期。</p>
<p>类似地，基于 VR 的 HAS 客户端可以使用多个 TCP 连接并行下载不同的tile。</p>
<h3 id="使用http2协议的服务端push特性">使用HTTP/2协议的服务端push特性</h3>
<p>HTTP/2协议引入了请求和相应的多路复用、头部压缩和请求优先级的特性，这可以减少页面加载时间。</p>
<p>服务端直接push短视频片段可以减少视频的启动时间和端到端延迟。</p>
<p>并且，服务端push特性可以应用在基于tile的VR视频推流中，客户端可以向服务器同时请求一条视频片段的所有tile。</p>
<p>服务端可以使用特制的请求处理器，允许客户端为每个tile定义一系列质量等级。</p>
<p>因此可以将应用的启发式自适应的速率的决定传达给服务器，这允许客户端以期望的质量级别取得所有图块。</p>
]]></description>
</item><item>
    <title>沉浸式流媒体面临的挑战和启示</title>
    <link>https://ayamir.github.io/posts/note9/</link>
    <pubDate>Sun, 14 Nov 2021 19:06:10 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note9/</guid>
    <description><![CDATA[<h2 id="最终的目标">最终的目标</h2>
<p>主要的挑战是用户的临场感，这可以通过避免虚拟的线索来创造出接近真实的世界。</p>
<h2 id="具体的任务">具体的任务</h2>
<ol>
<li>
<p>从360度视频的采集到显示的过程中，引入了好几种失真。</p>
<p>应该重点增加新的拼接、投影和分包方式以减少噪音。</p>
</li>
<li>
<p>除了捕获和使用360度视频来表示真实世界和实际交互内容之外，环境中还包括3D对象。</p>
<p>3D对象的合并对于真实的视图而言是一个挑战。</p>
</li>
<li>
<p>因为在推流会话中，用户的头部移动高度可变，所以固定的tiling方案可能会导致非最优的viewport质量。</p>
<p>推流框架中的tile数量应该被动态选择，进而提高推流质量。</p>
</li>
<li>
<p>自适应的机制应该足够智能来根据环境因素精确地做出适应。</p>
<p>应该制定基于深度强化学习的策略，来给360度视频帧中不同区域的tile分配合适的比特率。</p>
</li>
<li>
<p>用户在360度视频中的自由导航很容易让其感觉忧虑自己错过了什么重要的东西。</p>
<p>在360度视频中导航的时候，需要支持自然的可见角度方向。</p>
<p>丰富的环境应配备新颖的定向机制，以支持360度视频，同时降低认知负荷，以克服此问题。</p>
</li>
<li>
<p>真实的导航依赖viewport预测机制。</p>
<p>现代的预测方式应该使用时空图像特性以及用户的位置信息，采用合适的编解码器卷积LSTM结构来减少长期预测误差。</p>
</li>
<li>
<p>沉浸式的场景随着用户的交互应该发生变化。</p>
<p>由于用户与场景的交互而产生的新挑战是通过编码和传输透视图创建的。</p>
<p>因此预测用户的行为来实现对交互内容的高效编码和推流非常关键。</p>
</li>
<li>
<p>对360度视频的质量获取方法和度量手段需要进一步研究。</p>
</li>
<li>
<p>360度视频中特殊的音效需要引起注意。</p>
</li>
</ol>
]]></description>
</item><item>
    <title>360度视频的音频处理</title>
    <link>https://ayamir.github.io/posts/note8/</link>
    <pubDate>Sun, 14 Nov 2021 16:52:20 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note8/</guid>
    <description><![CDATA[<h2 id="背景">背景</h2>
<p>空间音频是一种全球状空间环绕的声音方式，采用多个声音通道来模拟现实世界中听到的声音。</p>
<p>360度视频由于空间音频而变得更加可靠，因为声音的通道特性使其能够穿越时间和空间。</p>
<p>360度视频显示系统在制作空间音频音轨方面的重要性无论怎样强调都不为过</p>
<h2 id="空间音频的再现技术">空间音频的再现技术</h2>
<h3 id="物理重建">物理重建</h3>
<p>物理重建技术用于合成尽可能接近所需信号的整个声场。</p>
<p>立体声配置在最流行的声音再现方法中使用两个扬声器，以促进更多的空间信息（包括距离、方向感、环境和舞台合奏）。而多信道再现方法在声学环境中使用，并在消费类设备中流行。</p>
<h4 id="多信道再现技术">多信道再现技术</h4>
<p>同样的声压场也通过其他物理重建技术产生，如环境中存在的环境声学和波场合成（WFS）。</p>
<p>需要麦克风阵列来捕获更多的空间声场。</p>
<p>因为不能直接用于声场特性分析，麦克风记录的内容需要后期处理。</p>
<p>麦克风阵列用于语音增强、声源分离、回声消除和声音再现。</p>
<h3 id="感知重建">感知重建</h3>
<p>心理声学技术用于感知重建，以产生对空间声音特征的感知。</p>
<p>感知重建技术复制空间音频的自然听觉感受来表示物理音频。</p>
<h4 id="双耳录制技术">双耳录制技术</h4>
<p>双耳录制技术是立体声录制的一种扩展形式，提供3D的听觉体验。</p>
<p>双耳录制技术通过使用两个360度麦克风尽可能的复制人耳，这与使用定向麦克风捕捉声音的常规立体声录音相同。</p>
<p>假人头部的360度麦克风用作人耳的代理，因为它提供了耳朵的精确几何坐标。</p>
<p>假人头部还产生与人头轮廓相互作用的声波。借助360度麦克风，与任何其他记录方法相比，空间立体图像的捕获更精确。</p>
<h5 id="头部相关传递函数hrtf">头部相关传递函数（HRTF）</h5>
<p>用于双耳音频的实时技术中，以再现复杂的线索，帮助我们通过过滤音频信号来定位声音。</p>
<p>多个因素（如耳朵、头部和听力环境）会影响线索，因为在现实中，我们会重新定位自己以定位声音。</p>
<p>选择合适的录音/重放技术对于使听到的声音与真实场景中的体验相同至关重要。</p>
<h2 id="环境声学">环境声学</h2>
<h3 id="概述">概述</h3>
<p>环境声学也被称为3D音频，被用于记录、混成和播放一个中心点周围的360度音频。</p>
<h3 id="区别">区别</h3>
<p>环境音频和传统的环绕声技术不同。</p>
<ol>
<li>
<p>双声道和传统环绕声技术背后的原理是相同的，都是通过将声音信号送到特定的扬声器来创建音频。</p>
<p>环境音频不受任何特定扬声器的预先限制，因为它在即使音域旋转的情况下，也能创造出平滑的音频。</p>
</li>
<li>
<p>传统环绕声的格式只有在声音场景保持静态的情况下才能提供出色的成像效果。</p>
<p>环境音频提供一个完整的球体，将声音均匀地传播到整个球体。</p>
</li>
</ol>
<h3 id="格式">格式</h3>
<p>环境音频有6种格式，分别为：A、B、C、D、E、G。</p>
<h3 id="用途">用途</h3>
<h4 id="一阶环境音频的用途">一阶环境音频的用途</h4>
<p>第一阶的环境音频或B格式的环境音频，其麦克风用于使用四面体阵列表示线性VR。</p>
<p>此外，这些在四个通道中进行处理，例如提供非定向压力水平的“W”。同时，“X、Y和Z”分别促进了从前到后、从侧到侧以及从上到下的方向信息。</p>
<p>一阶环境音频仅适用于相对较小的场景，因为其有限的空间保真度会影响声音定位。</p>
<h4 id="高阶环境音频的用途">高阶环境音频的用途</h4>
<p>高阶环境音频通过增加更多的麦克风来增强一阶环境音频的性能效率。</p>
<h2 id="总结">总结</h2>
<p></p>
]]></description>
</item><item>
    <title>自适应策略之viewport依赖型</title>
    <link>https://ayamir.github.io/posts/note7/</link>
    <pubDate>Sun, 14 Nov 2021 13:24:59 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note7/</guid>
    <description><![CDATA[<h2 id="概述">概述</h2>
<p>在360度视频的推流过程中，根据用户头部的运动自适应地动态选择推流的区域，调整其比特率，以达到节省带宽的目的。</p>
<h2 id="通常的实现方式">通常的实现方式</h2>
<p>在服务端提供几个自适应集，来在遇到用户头部的突然运动的情况时，能保证viewport的平滑转换。</p>
<p>提出QER(Quality-focused Regios)的概念使viewport内部的视频分辨率高于viewport之外的视频分辨率。</p>
<p>非对称的方式以不同的空间分辨率推流来节省带宽。</p>
<ul>
<li>在播放过程中，客户端根据用户的方向来请求不同分辨率版本的视频。</li>
<li>优点是即使客户端对用户的方面做了错误预测，低质量的内容仍然可以在viewport中生成。</li>
<li>缺点是在大多数场景下，这种方案需要巨大的存储开销和处理负载。</li>
</ul>
<h2 id="自适应推流参数">自适应推流参数</h2>
<ol>
<li>可用带宽和网络吞吐量</li>
<li>Viewport预测的位置</li>
<li>客户端播放器的可用缓冲</li>
</ol>
<h2 id="参数计算公式">参数计算公式</h2>
<ul>
<li>
<p>第n个估计的Viewport：$V^e(n)$</p>
<p>$V^e(n) = V_{fb}$</p>
<p>$V_{fb}$是最新报告的viewport位置</p>
</li>
<li>
<p>第n个估计的吞吐量：$T^e(n)$</p>
<p>$T^e(n) = T_{fb}$</p>
<p>$T_{fb}$是最新报告的吞吐量</p>
</li>
<li>
<p>比特率：$R_{bits}$</p>
<p>$R_{bits} = (1-\beta)T^e(n)$</p>
<p>$\beta$是安全边缘</p>
</li>
<li>
<p>第n个帧的客观度量质量：$VQ(k)$和最终客观度量质量$VQ$</p>
<p>$VQ=\frac{1}{L}\sum^L_{k=1}VQ(k)$</p>
<p>$VQ(k) = \sum_{t=1}^{T^n}w_k(k) * D^n_t(V_t, k)$</p>
<p>$w_k = \frac{A(t,k)}{A_{vp}}$</p>
<p>$L=总帧数$</p>
<p>$w_k$表示在第k个帧中与viewport所重叠的tile程度</p>
<p>$A(t,k)$表示第k个帧中tile $t$ 重叠的区域</p>
<p>$A_{vp}$表示viewport中总共的区域</p>
</li>
</ul>
]]></description>
</item><item>
    <title>沉浸式流媒体现有标准</title>
    <link>https://ayamir.github.io/posts/note6/</link>
    <pubDate>Thu, 11 Nov 2021 20:08:03 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note6/</guid>
    <description><![CDATA[<h2 id="omafomnidirectional-media-format">OMAF(Omnidirectional Media Format)</h2>
<p><code>OMAF</code>是第1个国际化的沉浸式媒体格式，描述了对360度视频进行编码、演示、消费的方法。</p>
<p><code>OMAF</code>与与现有格式兼容，包括编码（例如<code>HEVC</code>），文件格式（例如<code>ISOBMFF</code>），交付信号（例如<code>DASH</code>，<code>MMT</code>）。</p>
<p><code>OMAF</code>中还包括编码、投影、分包和viewport方向的元数据。</p>
<h2 id="omafdash-mpd">OMAF+DASH-&gt;MPD</h2>
<p>OMAF与DASH相结合，再加上一些额外的描述构成了MPD文件格式，用于向客户端通知360度媒体的属性。</p>
<p>OMAF规定了9中媒体配置文件，包括3种视频配置文件：基于HEVC的viewport独立型、基于HEVC的viewport依赖型、基于AVC的viewport依赖型。</p>
<p>OMAF为视角独立型的推流提供了无视viewport位置的连续的视频帧质量。</p>
<p>常规的HEVC编码方式和DASH推流格式可以用于viewport独立型的推流工作。</p>
<p>但是使用HEVC/AVC编码方式的基于viewport的自适应操作是OMAF的一项技术开发，允许无限制地使用矩形RWP来增强viewport区域的质量。</p>
<h2 id="cmafcommon-media-application-format">CMAF(Common Media Application Format)</h2>
<p>致力于提供跨多个应用和设备之间的统一的编码格式和媒体配置文件。</p>
<p>CMAF使请求低延迟的segment成为可能。</p>
<h2 id="isobmffiso-base-media-file-format">ISOBMFF(ISO Base Media File Format)</h2>
<p>ISOBMFF是用于定时数据交换、管理和显示的最流行的文件格式。</p>
<ul>
<li>
<p>文件由一系列兼容并且可扩展的文件级别的box组成。</p>
</li>
<li>
<p>每个box表示1个由4个指针字符代码组成的数据结构。</p>
</li>
<li>
<p>ISOBMFF的媒体数据流和元数据流被分别分发。</p>
<ul>
<li>媒体数据流中包括编码过的音频和视频数据。</li>
<li>元数据流中包括媒体类型、编码属性、时间戳、大小等元数据，也包括全向内容的额外信息如投影格式、旋转、帧分包、编码和分发等元数据。</li>
</ul>
</li>
<li>
<p>ISOBMFF为了访问方便，保证有价值信息能灵活聚合。</p>
</li>
</ul>
<h2 id="3dof3-degree-of-freedom">3DoF(3 Degree of Freedom)</h2>
<p>在3DoF场景中，用户可以自由的移动头部以三个方向：摆动、俯仰、旋转。</p>
<h2 id="3dof">3DoF+</h2>
<p>用户的头部可以以任意方向移动：上下、左右、前后</p>
<h2 id="6dof">6DoF</h2>
<p>不只用户的头部，用户的身体也是自由的。同时支持方向与位置的自由。</p>
]]></description>
</item><item>
    <title>自适应360度视频推流挑战</title>
    <link>https://ayamir.github.io/posts/note5/</link>
    <pubDate>Thu, 04 Nov 2021 11:01:18 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note5/</guid>
    <description><![CDATA[<h1 id="背景">背景</h1>
<p>用户使用头戴设备比使用传统显示器观看360度视频内容时的满意度对于扰乱更加敏感。</p>
<p>沉浸式的体验受到不完美的视角预测和高度动态化的网络状况的消极影响。</p>
<p>目前主要面临的挑战有以下4个：</p>
<p></p>
<h2 id="viewport预测">Viewport预测</h2>
<h3 id="背景-1">背景</h3>
<p>HMD的本质特征是快速响应用户头部的移动。当用户改变viewport时HMD处理交互并检测相关的viewport来精确播放器的信息，这样视野就能以正常的可视角度被提供给用户。Viewport预测在优化的360度视频推流中非常必要。配备有位置传感器的可穿戴HMD允许客户端更新其视角方向相应的视角场景。</p>
<h3 id="分类">分类</h3>
<ul>
<li><em>内容不可知</em>的方式基于历史信息对viewport进行预测。</li>
<li><em>内容感知</em>的方式需要视频内容信息来预测未来的viewport。</li>
</ul>
<h3 id="内容不可知方式">内容不可知方式</h3>
<h4 id="分类-1">分类</h4>
<ul>
<li>平均线性回归LR</li>
<li>航位推算DR</li>
<li>聚类</li>
<li>机器学习ML</li>
<li>编解码器体系结构</li>
</ul>
<h4 id="现有成果">现有成果</h4>
<h5 id="qians-worklr">Qian&rsquo;s work——LR</h5>
<p>使用平均线性回归和加权线性回归模型来做viewport预测，之后对与预测区域重叠的tile进行整体推流。</p>
<ul>
<li>当预测后0.5s、1s、2s加权线性回归表现更好</li>
</ul>
<h5 id="petrangelis-worklr">Petrangeli&rsquo;s work——LR</h5>
<p>将被划分成tile的等矩形的帧分成3个区域：viewport区、相邻区、其他区。</p>
<p>结合观察者头部的移动，将可变比特率分配给可见和不可见区域。</p>
<p>作者利用最近（100毫秒）用户观看历史的线性外推来预测未来的注视点。</p>
<h5 id="mavlankar-and-girods-work运动向量">Mavlankar and Girod&rsquo;s work——运动向量</h5>
<p>使用运动向量比如观察者的平移、倾斜、缩放等方向上的速度和加速度，来执行视角区域预测。</p>
<h5 id="la-fuentes-work运动向量">La Fuente&rsquo;s work——运动向量</h5>
<p>考虑了两种预测变体：角速度和角加速度，从用户以前的方向数据来估计未来的头部方向。按照预测结果分配不同的量化参数到每个tile上。</p>
<p>当进行进一步的预测时（超过2s），这种方式限制了预测的精度。</p>
<p>如果视频tile被基于错误的预测而被请求，用户的实际viewport可能会被没有请求因而没有内容的黑色tile所覆盖。</p>
<h5 id="bans-workknnlr">Ban&rsquo;s work——KNN+LR</h5>
<p>使用KNN算法利用跨用户观看历史，使用LR模型利用户个体化的行为。</p>
<p>就视角预测的准确率而言，分别取得了20%和48%的绝对和相对改进。</p>
<h5 id="lius-workcluster">Liu&rsquo;s work——cluster</h5>
<p>提出了使用数据融合方法，通过考虑几个特征来估计未来视角位置。特征例如：用户的参与度、用户观看同一视频的行为、单个用户观看多个视频的行为、最终用户设备、移动性水平。</p>
<h5 id="petrangelis-workcluster">Petrangeli&rsquo;s work——cluster</h5>
<p>基于车辆轨迹预测的概念，考虑了类似的轨迹形成一个簇来预测未来的viewport。</p>
<p>结果表明这种方法为更长的视野提高了精确度。</p>
<p>检查了来自三个欧拉角的不同轨迹，这样做可能导致性能不足。</p>
<h5 id="rossis-workcluster">Rossi&rsquo;s work——cluster</h5>
<p>提出了一种聚类的方法，基于球形空间中有意义的viewport重叠来确认用户的簇。</p>
<p>基于Bron-Kerbosch（BK）算法的聚类算法能够识别大量用户，这些用户观看的是相同的60%的3s长球形视频块。</p>
<p>与基准相比，该方法为簇提供了可兼容且重要的几何viewport重叠。</p>
<h5 id="jiangs-work">Jiang&rsquo;s work</h5>
<p>背景：</p>
<p>LR方法对于长期的预测视野会导致较差的预测精度。长短时记忆（LSTM）是一种递归神经网络（RNN）架构，适用于序列建模和模式开发。</p>
<p>方法：</p>
<p>为了在FoV预测中获取比LR方法更高的精确度，开发了一种使用带有128个神经元的LSTM模型的viewport预测方法。</p>
<ul>
<li>分析了360度数据集，观察到用户在水平方向头部有快速转向，但是在垂直方向几乎是稳定的。</li>
<li>实验表明，这种方法同时考虑水平和垂直方向的头部移动时，比LR等方法产生了更少的预测错误。</li>
</ul>
<h5 id="baos-work">Bao&rsquo;s work</h5>
<p>背景：</p>
<p>对150个用户进行了16个视频剪辑的主观实验，并对其行为进行了分析。</p>
<p>使用3个方向的欧拉角$\theta$, $\phi$, $\psi$来表示用户在3D空间中头部的移动，结果表明不同方向的动作有强自相关性和消极的互相关性。因此多个角度的预测可以分开进行。</p>
<p>方法：</p>
<p>开发两个独立的LSTM模型来分别预测$\theta$和$\phi$，之后将预测结果应用于目标区域流来有效利用可用网络资源。</p>
<h5 id="hous-work">Hou&rsquo;s work</h5>
<ul>
<li>提出一种基于深度学习的视角产生方法来只对提前预测的360度视频和3自由度的VR应用的viewport tile进行抽取和推流。（使用了大规模的数据集来训练模型）</li>
<li>使用包含多层感知器和LSTM模型来预测6自由度的VR环境中头部乃至身体的移动，预测的视野被预渲染来做到低延迟的VR体验。</li>
</ul>
<h5 id="heyses-work">Heyse&rsquo;s work</h5>
<p>背景：</p>
<p>在某些例子中，用户的移动在视频的不同部分中非常不稳定。这增加了机器学习方式的训练压力。</p>
<p>方法：</p>
<p>提出了一个基于RL模型的上下文代理，这个模型首先检测用户的显著移动，然后预测移动的方向。这种分层自学习执行器优于球形轨迹外推法（这种方法将用户运动建模为轨迹的一部分，而不是单位球体上的完整轨迹）</p>
<h5 id="qians-work">Qian&rsquo;s work</h5>
<p>提出了一种叫做Flare的算法来最小化实际viewport和预测viewport之间的不匹配。</p>
<ul>
<li>应用了一种ML方法来执行频繁的viewport预测，包括从130名用户收集的1300条头部运动轨迹的4个间隔。</li>
<li>使用viewport轨迹预测，Flare可以将错误预测替换成最新预测。</li>
</ul>
<h5 id="yu-and-lius-work">Yu and Liu&rsquo;s work</h5>
<p>背景：</p>
<p>LSTM网络本身具有耗时的线性训练特性。编解码器的LSTM模型把训练过程并行化，相比于LR和LSTM本身而言，改善了预测精度。</p>
<p>方法：</p>
<p>使用基于注意力的LSTM编解码器网络体系结构来避免昂贵的递归并能更好地捕获viewport变化。</p>
<ul>
<li>提出的体系结构相比于传统的RNN，获得了更高的预测精度，更低的训练复杂度和更快的收敛。</li>
</ul>
<h5 id="jamalis-work">Jamali&rsquo;s work</h5>
<p>提出使用LSTM编解码器网络来做长期的viewport预测（例如3.5s）。</p>
<p>收集了低延迟异质网络上跨用户的方向反馈来调整高延迟网络上目标用户的预测性能。</p>
<h3 id="内容感知方式">内容感知方式</h3>
<h4 id="背景-2">背景</h4>
<p>内容感知方式可以提高预测效率。</p>
<h4 id="具体方法">具体方法</h4>
<h5 id="aladaglis-work">Aladagli&rsquo;s work</h5>
<p>提出了一个显著性驱动的模型来提高预测精度。</p>
<ul>
<li>没有考虑用户在360度视频中的视角行为。</li>
<li>viewport预测错误可以通过理解用户对360度视频独特的可见注意力最小化。</li>
</ul>
<h5 id="nguyens-work">Nguyen&rsquo;s work</h5>
<p>背景：</p>
<p>大多数现存的方法把显著性图看作是360度显示中的位置信息来获得更好的预测结果。</p>
<p>通用的显著性和位置信息体系结构基于固定预测模型。</p>
<p>方法：</p>
<p>提出了<code>PanoSalNet</code>来捕获用户在360度帧中独特的可见注意力来改善显著性检测的性能。</p>
<ul>
<li>同时使用HMD特性和显著性图的固定预测模型获得了可测量的结果。</li>
</ul>
<h5 id="xus-work">Xu&rsquo;s work</h5>
<p>提出了两个DRL(Deep Reinforcement Learning)模型用于同时考虑运动轨迹和可见注意力特性的viewport预测网络。</p>
<ul>
<li>离线模型基于内容流行度检测每个帧里的显著性。</li>
<li>在线模型基于从离线模型获得的显著性图和之前的viewport预测信息预测viewport方向和大小。</li>
<li>这个网络只能预测30ms的下一个viewport位置。</li>
</ul>
<h5 id="xus-work-1">Xu&rsquo;s work</h5>
<p>收集了大规模的被使用带有眼部轨迹跟踪的HMD的45个观测者观察的动态360度视频数据集，提出了基于历史扫描路径和图像特征预测注视位移的方法。</p>
<ul>
<li>在与当前注视点、viewport和整个图像相关的三个空间尺度上执行了显著性计算。</li>
<li>可能的图像特性被通过向CNN喂图像和相应的显著性图，同时LSTM模型捕获历史信息来抽取出来。</li>
<li>之后将LSTM和CNN特性耦合起来，用于下一次的用户注视信息预测。</li>
</ul>
<h5 id="fans-work">Fan&rsquo;s work</h5>
<p>用户更容易被运动的物体吸引，因此除了显著性图之外，Fan等人也考虑了使用预训练  的CNN来估计用户未来注视点的内容运动图。</p>
<ul>
<li>由于可能存在多个运动，这让预测变得不可靠，因此运动贴图的开发还需要进一步的研究。</li>
</ul>
<h5 id="yangs-work">Yang&rsquo;s work</h5>
<ul>
<li>使用CNN模型基于历史观测角度信息预测了单viewport。</li>
<li>接着考虑了一种使用内容不可知和内容感知方法如RNN和CFVT模型的融合层的viewport轨迹预测策略。</li>
<li>融合模型使其同时支持更好地预测并且提高了大概40%的精度。</li>
</ul>
<h5 id="ozcinars-work">Ozcinar&rsquo;s work</h5>
<p>将viewport轨迹转换为基于viewport的视觉注意图，然后对不同大小的tile进行推流以保证更高的编码效率。</p>
<h5 id="lis-work">Li&rsquo;s work</h5>
<p>现有的预测模型对未来的预测能力有限，Li等人提出了两种模型，分别用于viewport相关和基于tile的推流系统。</p>
<ul>
<li>第一个模型应用了基于用户轨迹的LSTM编解码网络体系结构。</li>
<li>第二个模型应用了卷积LSTM编解码体系结构，使用序列的热图来预测用户的未来方向。</li>
</ul>
<h3 id="总结">总结</h3>
<p>精确的方向预测使360度视频的客户端可以以高分辨率下载最相关的tile。</p>
<p>当前采用显著性和位置信息的神经网络模型的性能比直接利用当前观察位置进行未来viewport位置估计的简单无运动的基线方法表现差。估计的显著性中的噪音等级限制了这些模型的预测精度。并且这些模型也引入了额外的计算复杂度。</p>
<p>对于360度视频注意点的可靠预测和用户观看可能性与显著性图之间关系的理解，显著性模型必须被改善并通过训练大规模的数据集来适应，尤其是被配备了不同摄像机旋转的镜头所捕获的数据。</p>
<p>另一方面，卷积LSTM编解码器和基于轨迹的预测方法适合长期预测，并能带来相当大的QoE改进，特别是在协作流媒体环境中。</p>
<h2 id="qoe评估">QoE评估</h2>
<h3 id="背景-3">背景</h3>
<p>由于全方位视频非常普遍，因此，通过这种类型的视频分发来确定用户的特定质量方面是至关重要的。QoE在视频推流应用中扮演着重要角色。在传统视频推流中，QoE很大程度上被网络负载和分发性能所影响。现有的次优目标度量方法并不适用于全向视频，因为全向视频受网络状况和用户视角行为的影响很大。</p>
<h3 id="主观质量评估">主观质量评估</h3>
<p>主观质量评估是估计360度视频推流质量的现实并且可靠的方法。</p>
<h4 id="upeniks-work">Upenik&rsquo;s work</h4>
<p>用一台MergeVR HMD执行了主观测试来体验360度图像。</p>
<ul>
<li>实验数据包括主观分数、视角轨迹、在每个图像上花费的时间由软件上获得。</li>
<li>视角方向信息被用于计算显著性图。</li>
<li>但是这项研究没有考虑对360度视频的评估。</li>
</ul>
<h4 id="zhangs-work">Zhang&rsquo;s work</h4>
<p>为了弥补360度视频和常规视频度量方式之间的性能差距，为全景视频提出了一种主观质量评估方法，称为<em>SAMPVIQ</em>。</p>
<ul>
<li>23位参与者被允许观看4个受损视频，整体视频质量体验的评分在0～5分之间。</li>
<li>参与者之间存在较大的评分差异。</li>
</ul>
<h4 id="xus-work-2">Xu&rsquo;s work</h4>
<p>提出两种主观测量方式：总体区分平均意见分数(O-DMOS)和矢量区分平均意见分数(V-DMOS)来获得360度视频的质量损失。</p>
<ul>
<li>类似于传统食品的DMOS度量方式，O-DMOS度量方式计算主观测试序列的总计区分分数。</li>
</ul>
<h4 id="schatzs-work">Schatz&rsquo;s work</h4>
<p>研究了使用HMD观看360度内容时停顿事件的影响。</p>
<ul>
<li>沉浸式内容的主观质量评估并非不重要，可能导致比实际推荐更多的开放性问题。</li>
<li>通常来讲人们的期望于传统的HAS相似，即如果可能的话，根本没有停顿。</li>
</ul>
<h4 id="可用的开源工具">可用的开源工具</h4>
<p>AVTrack360，OpenTrack和360player能捕获用户观看360度视频的头部轨迹。</p>
<p>VRate是一个在VR环境中提供主观问卷调查的基于Unity的工具。</p>
<p>安卓应用*<a href="https://github.com/zerepolbap/miro360" target="_blank" rel="noopener noreffer">MIRO360</a>*，支持未来VR主观测试的指南开发。</p>
<h4 id="cybersickness"><code>Cybersickness</code></h4>
<p><code>Cybersickness</code>是一种获得高QoE的潜在障碍，它能引起疲劳、恶心、不适和呕吐。</p>
<h5 id="singlas-work">Singla&rsquo;s work</h5>
<p>使用受限的带宽和分辨率，在不同的延迟情况下进行了两个主观实验。</p>
<ul>
<li>开发了主观测试平台、测试方法和指标来评估viewport自适应360度视频推流中的视频感知等级和<code>Cybersickness</code>。</li>
<li>基于tile的推流在带宽受限的情况下表现很好。</li>
<li>47ms的延迟实际上不影响感知质量。</li>
</ul>
<h5 id="trans-work">Tran&rsquo;s work</h5>
<p>考虑了几个影响因子例如内容的空间复杂性，数量参数，分辨率特性和渲染模型来评估cybersickness，质量，可用性和用户的存在。</p>
<ul>
<li>VR环境中快速移动的内容很容易引发cybersickness。</li>
<li>由于高可用性和存在性，用户的cybersickness也可能加剧。</li>
</ul>
<h5 id="singlas-work-1">Singla&rsquo;s work</h5>
<p>评估了28名受试者在Oculus Rift和HTC Vive头戴式电脑上观看6个全高清和超高清分辨率YouTube视频时的观看不适感。</p>
<ul>
<li>HMD的类型轻微地影响感知质量。</li>
<li>分辨率和内容类型强烈影响个人体验。</li>
<li>女性用户感到<code>cybersickness</code>的人数更多。</li>
</ul>
<h4 id="空间存在感">空间存在感</h4>
<p>空间存在感能增强沉浸感。</p>
<h5 id="zous-work">Zou&rsquo;s work</h5>
<p>方法：</p>
<p>提出了一个主观框架来测量25名受试者的空间存在感。</p>
<ul>
<li>提出的框架包括三层，从上到下分别为：空间存在层、感知层、科技影响层。</li>
<li>心理上的空间存在感形成了空间存在层。</li>
<li>感知层以视频真实感、音频真实感和交互元素为特征。</li>
<li>科技影响层由几个模块组成，这些模块与感知层相连，以反映传感器的真实性。</li>
</ul>
<h5 id="huponts-work">Hupont&rsquo;s work</h5>
<p>应用通用感知的原则来研究在Oculus HMD和传统2D显示器上玩游戏的用户的空间存在感。</p>
<ul>
<li>与2D显示器相比，3D虚拟现实主义显示出更高的惊奇、沉浸感、存在感、可用性和兴奋感。</li>
</ul>
<h4 id="生理特征度量">生理特征度量</h4>
<h5 id="salgados-work">Salgado&rsquo;s work</h5>
<p>方法：</p>
<p>捕获多种多样的生理度量，例如心率HR，皮肤电活性EDA、皮肤温度、心电图信号ECG、呼吸速率、血压BVP、脑电图信号EEG来评价沉浸式模拟器的质量。</p>
<h5 id="egans-work">Egan&rsquo;s work</h5>
<p>基于HR和EDA信号评估VR和非VR渲染模式质量分数。</p>
<ul>
<li>相比于HR，EDA对质量分数有强烈的影响。</li>
</ul>
<h4 id="技术因素感知">技术因素感知</h4>
<p>不同的技术和感知特征，如失真、清晰度、色彩、对比度、闪烁等，用于评估感知视频质量。</p>
<h5 id="fremereys-work">Fremerey&rsquo;s work</h5>
<p>确定了可视质量强烈地依赖于应用的运动插值（MI）算法和视频特征，例如相机旋转和物体的运动。</p>
<p>在一项主观实验中，12位视频专家回顾了使用FFmpeg混合、FFmpeg MCI（运动补偿插值）和butterflow插值到90 fps的四个视频序列。作者发现，与其他算法相比，MCI在QoE方面提供了极好的改进。</p>
<h4 id="总结-1">总结</h4>
<p>主观测试与人眼直接相关，并揭示了360度视频质量评估的不同方面的影响。</p>
<p>在这些方面中，空间存在感和由佩戴VR头戴设备观看360度视频导致的<em>cybersickness</em>极为重要，因为这些效果并不在传统的2D视频观看中出现。</p>
<p>主观评估需要综合的手工努力并因此昂贵耗时并易于出错，相对而言，客观评估更易于管理和可行。</p>
<h3 id="客观质量评估">客观质量评估</h3>
<p>由于类似的编码结构和2D平面投影格式，对360度内容应用客观质量评估很自然。</p>
<h4 id="计算psnr">计算PSNR</h4>
<p>现有投影方式中的采样密度在每个像素位置并不均匀。</p>
<h5 id="yus-work">Yu&rsquo;s work</h5>
<p>为基于球形的PSNR计算引入S-PSNR和L-PSNR。</p>
<ul>
<li>S-PSNR通过对球面上所有位置的像素点做同等加权来计算PSNR。</li>
<li>利用插值算法，S-PSNR可以完成对支持多种投影模式的360度视频的客观质量评估。</li>
<li>L-PSNR通过基于纬度和访问频率的像素点加权测量PSNR。</li>
<li>L-PSNR可以测量viewport的平均PSNR而无需特定的头部运动轨迹。</li>
</ul>
<h5 id="zakharchenkos-work">Zakharchenko&rsquo;s work</h5>
<p>提出了一种Craster Parabolic Projection-PSNR (CPP-PSNR) 度量方式来比较多种投影方案，通过不改变空间分辨率和不计算实际像素位置的PSNR，将像素重新映射成CPP投影。</p>
<ul>
<li>CPP投影方式可能使视频分辨率大幅下降。</li>
</ul>
<h5 id="suns-work">Sun&rsquo;s work</h5>
<p>提出了一种叫做weighted-to-spherically-uniform PSNR (WS-PSNR)的质量度量方式，以此来测量原始和受损内容之间的质量变化。</p>
<ul>
<li>根据像素在球面上的位置考虑权重。</li>
</ul>
<h4 id="计算ssim">计算SSIM</h4>
<p>SSIM是另一种质量评估指标，它通过三个因素反映图像失真，包括亮度、对比度和结构。</p>
<h5 id="chens-work">Chen&rsquo;s work</h5>
<p>为2D和360度视频分析了SSIM结果，引入了球型结构的相似性度量（S-SSIM）来计算原始和受损的360度视频之间的相似性。</p>
<ul>
<li>在S-SSIM中，使用重投影来计算两个提取的viewport之间的相似性。</li>
</ul>
<h5 id="zhous-work">Zhou&rsquo;s work</h5>
<p>考虑相似性的权重提出了WS-SSIM来测量投影区域中窗口的相似性。</p>
<ul>
<li>性能评估表明，与其他质量评估指标相比，WS-SSIM更接近人类感知。</li>
</ul>
<h5 id="van-der-hoofts-work">Van der Hooft&rsquo;s work</h5>
<p>提出了<em>ProbGaze</em>度量方式，基于tile的空间尺寸和viewport中的注视点。</p>
<ul>
<li>考虑外围tile的权重来提供合适的质量测量。</li>
<li>相比于基于中心和基于平均的PSNR和SSIM度量方式，<em>ProbGaze</em>能估计当用户突然改变viewport位置时的视频质量变化。</li>
</ul>
<h5 id="xus-work-3">Xu&rsquo;s work</h5>
<p>引入了两种客观质量评估度量手段：基于内容感知的PSNR和非内容感知的PSNR，用于编码360度视频。</p>
<ul>
<li>第一种方式基于空间全景内容对像素失真进行加权。</li>
<li>第二种方式考虑人类偏好的统计数据来估计质量损失。</li>
</ul>
<h4 id="基于psnr和ssim方式的改进">基于PSNR和SSIM方式的改进</h4>
<p>尽管各种基于PSNR和SSIM的方式被广阔地应用到了360度视频的质量评估中，但这些方式都没有真正地捕获到感知质量，特别是当HMD被用于观看视频时。因此需要为360度内容特别设计一种优化的质量度量方式。</p>
<h5 id="upeniks-work-1">Upenik&rsquo;s work</h5>
<p>考虑了一场使用4张高质量360度全景图像来让45名受试者在不同的编码设定下评估和比较客观质量度量方式性能的主观实验。</p>
<ul>
<li>现有的客观度量方式和主观感知到的质量相关性较低。</li>
</ul>
<h5 id="trans-work-1">Tran&rsquo;s work</h5>
<p>论证主观度量和客观度量之间相关性较高，但是使用的数据集较小。</p>
<h4 id="基于ml的方式">基于ML的方式</h4>
<p>基于ML的方式可以弥补客观评估和主观评估之间的差距。</p>
<h5 id="da-costa-filhos-work">Da Costa Filho&rsquo;s work</h5>
<p>提出了一个有两个阶段的模型。</p>
<ul>
<li>首先自适应VR视频的播放性能由机器学习算法所确定。</li>
<li>之后模型利用估计的度量手段如视频质量、质量变化、卡顿时间和启动延迟来确定用户的QoE。</li>
</ul>
<h5 id="lis-work-1">Li&rsquo;s work</h5>
<p>引入了基于DRL的质量获取模型，在一次推流会话中同时考虑头部和眼部的移动。</p>
<ul>
<li>360度视频被分割成几个补丁。</li>
<li>低观看概率的补丁被消除。</li>
<li>参考和受损视频序列都被输入到深度学习可执行文件中，以计算补丁的质量分数。</li>
<li>之后分数被加权并加到一起得到最终的分数。</li>
</ul>
<h5 id="yangs-work-1">Yang&rsquo;s work</h5>
<p>考虑了多质量等级的特性和融合模型。</p>
<ul>
<li>质量特性用<code>region of interest(ROI)</code>图来计算，其中包括像素点等级、区域等级、对象等级和赤道偏差。</li>
<li>混合模型由后向传播的神经网络构造而成，这个神经网络组合了多种质量特性来获取整体的质量评分。</li>
</ul>
<h3 id="总结-2">总结</h3>
<p>精确的QoE获取是优化360度视频推流服务中重要的因素，也是自适应分发方案中基础的一环。</p>
<p>单独考虑VR中的可视质量对完整的QoE框架而言并不足够。</p>
<p>为能获得学界的认可，找到其他因素的影响也很必要，例如<code>cybersickness</code>，生理症状，用户的不适感，HMD的重量和可用性，VR音频，viewport降级率，网络特性（延迟，抖动，带宽等），内容特性（相机动作，帧率，编码，投影等），推流特性（viewport偏差，播放缓冲区，时空质量变化等）。</p>
<h2 id="低延迟推流">低延迟推流</h2>
<h3 id="背景-4">背景</h3>
<p>360度全景视频推流过程中的延迟由几部分组成：传感器延迟、云/边处理延迟、网络延迟、请求开销、缓冲延迟、渲染延迟和反馈延迟。</p>
<p>低延迟的要求对于云VR游戏、沉浸式临场感和视频会议等更为严格。</p>
<p>要求极低的终端处理延迟、快速的云/边计算和极低的网络延迟来确保对用户头部移动做出反馈。</p>
<p>现代HMD可以做到使传感器延迟降低到用户无法感知的程度。</p>
<p>传输延迟已经由5G移动和无线通信技术大幅减少。</p>
<p>但是，对于减少处理、缓冲和渲染延迟的工作也是必要的。</p>
<p>许多沉浸式应用的目标是MTP的延迟少于20ms，理想情况是小于15ms。</p>
<h3 id="减少启动时间">减少启动时间</h3>
<h4 id="减少初始化请求的数据量">减少初始化请求的数据量</h4>
<p>通常来讲，较小的视频segment能减少启动和下载时间。</p>
<h5 id="van-der-hoofts-work-1">Van der Hooft&rsquo;s work</h5>
<p>考虑了新闻相关内容的推流，使用的技术有：</p>
<ol>
<li>服务端编码</li>
<li>服务端的用户分析</li>
<li>服务器推送策略</li>
<li>客户端积极存储视频数据</li>
</ol>
<p>取得的效果：</p>
<ul>
<li>降低了启动时间</li>
<li>允许不同网络设定下的快速内容切换</li>
<li>较长的响应时间降低了性能</li>
</ul>
<h5 id="nguyens-work-1">Nguyen&rsquo;s work</h5>
<p>基于viewport依赖的自适应策略分析了自适应间隔延迟和缓冲延迟的影响。</p>
<ul>
<li>使用服务端比特率计算策略来最小化响应延迟的影响。</li>
<li>根据客户端的响应估计可用的网络吞吐量和未来的viewport位置。</li>
<li>服务端的决策引擎推流合适的tile来满足延迟限制。</li>
</ul>
<p>取得的效果：</p>
<ul>
<li>对于viewport依赖型推流方案而言，较少的自适应和缓冲延迟不可避免。</li>
</ul>
<h3 id="降低由tile分块带来的网络负载">降低由tile分块带来的网络负载</h3>
<p>在HTTP/1.1中，在空间上将视频帧分成矩形tile会增加网络负载，因为每个tile会产生独立的网络请求。</p>
<p>请求爆炸的问题导致了较长的响应延迟，但是可以通过使用HTTP/2的服务器推送特性解决。这个特型使服务器能使用一条HTTP请求复用多条消息。</p>
<h5 id="weis-work">Wei&rsquo;s work</h5>
<p>利用HTTP/2协议来促进低延迟的HTTP自适应推流。</p>
<ul>
<li>提出的服务端推送的策略使用一条请求同时发送几个segment避免多个GET请求。</li>
</ul>
<h5 id="petrangelis-work">Petrangeli&rsquo;s work</h5>
<p>结合特定请求参数与HTTP/2的服务端推送特性来促进360度视频推流。</p>
<ul>
<li>客户端为一个segment发送一条call，服务器使用FCFS策略传送k个tile。</li>
<li>利用HTTP/2的优先级特性可以使高优先级的tile以紧急的优先级被获取，进而改善网络环境中的高往返时间的性能。</li>
</ul>
<h5 id="xus-work-4">Xu&rsquo;s work</h5>
<p>为360度内容采用了<code>k-push</code>策略：将k个tile推送到客户端，组成一个单独的时间段。</p>
<ul>
<li>提出的方法与QoE感知的比特率自适应算法一起，在不同的RTT设定下，提高了20%的视频质量，减少了30%的网络传输延迟。</li>
</ul>
<h5 id="yahias-work">Yahia&rsquo;s work</h5>
<p>使用HTTP/2的优先级和多路复用功能，在两个连续的viewport预测之间，即在交付相同片段之前和期间，组织紧急视频块的受控自适应传输。</p>
<h5 id="yens-work">Yen&rsquo;s work</h5>
<p>开发了一种支持QUIC的体系结构来利用流优先级和多路复用的特性来实现360度视频的安全和低优先级的传输。</p>
<ul>
<li>当viewport变化发生时，QUIC能让常规的tile以低优先级推流，viewport内的tile以高优先级推流，都通过一条QUIC连接来降低viewport tile的缺失率。</li>
<li>作者说测试表明基于QUIC的自适应360度推流比HTTP/1.1和HTTP/2的方案表现更好。</li>
</ul>
<h3 id="使用移动边缘计算降低延迟">使用移动边缘计算降低延迟</h3>
<h5 id="mangiantes-work">Mangiante&rsquo;s work</h5>
<p>提出了利用基于边缘处理的viewport渲染方案来减少延迟，同时利用终端设备上的电源和计算负载。</p>
<ul>
<li>但是作者没有给出有效的算法或是建立一个实践执行平台。</li>
</ul>
<h5 id="lius-work">Liu&rsquo;s work</h5>
<p>采用远端渲染技术，通过为不受约束的VR系统获取高刷新率来隐藏网络延迟。</p>
<ul>
<li>采用60GHz的无线链路支持的高端GPU，来加快计算速度和4K渲染，减少显示延迟。</li>
<li>尽管提供了高质量和低延迟的推流，但是使用了昂贵的带宽连接，这通常并不能获得。</li>
</ul>
<h5 id="viitanens-work">Viitanen&rsquo;s work</h5>
<p>引入了端到端的VR游戏系统。通过执行边缘渲染来降低延迟，能源和计算开销。</p>
<ul>
<li>为1080p 30fps的视频格式实现了端到端的低延迟（30ms）的系统。</li>
<li>前提是有充足的带宽资源、终端设备需要性能强劲的游戏本。</li>
</ul>
<h5 id="shis-work">Shi&rsquo;s work</h5>
<p>考虑了不重视viewport预测的高质量360度视频渲染。</p>
<ul>
<li>提出的MEC-VR系统采用了一个远端服务器通过使用一个自适应裁剪过滤器来动态适应viewport覆盖率，这个过滤器按照观测到的系统延迟增加viewport之外的区域。</li>
<li>基于viewport覆盖率的延迟调整允许客户端容纳和补偿突然的头部移动。</li>
</ul>
<h3 id="共享vr环境中的延迟处理">共享VR环境中的延迟处理</h3>
<p>共享VR环境中用户的延迟取决于用户的位置和边缘资源的分发。</p>
<h5 id="parks-work">Park&rsquo;s work</h5>
<p>通过考虑多个用户和边缘服务器之间的双向通信，提出了一种使用线性蜂窝拓扑中的带宽分配策略，以最小化端到端系统延迟。确定了推流延迟强烈地依赖于：</p>
<ul>
<li>边缘服务器的处理性能</li>
<li>多个交互用户之间的物理和虚拟空间</li>
</ul>
<h5 id="perfectos-work">Perfecto&rsquo;s work</h5>
<p>集成了深度神经网络和毫米波多播传输技术来降低协同VR环境中的延迟。</p>
<ul>
<li>神经网络模型估计了用户即将来临的viewport。</li>
<li>用户被基于预测的相关性和位置分组，以此来优化正确的viewport许可。</li>
<li>执行积极的多播资源调度来最小化延迟和拥塞。</li>
</ul>
<h3 id="总结-3">总结</h3>
<p>在单用户和多用户的环境中，边缘辅助的解决方式对于控制延迟而言占主要地位。</p>
<p>此外还有服务端的viewport计算、服务端push机制和远程渲染机制都能用于低延迟的控制。</p>
<p>现有的4G网络足以支持早期的自适应沉浸式多媒体，正在成长的5G网络更能满足沉浸式内容的需求。</p>
<h2 id="360度直播推流">360度直播推流</h2>
<h3 id="背景-5">背景</h3>
<p>传统的广播电视频道是直播推流的流行来源。现在私人的360度直播视频在各个社交媒体上也有大幅增长。</p>
<p>因为视频生产者和消费者之间在云端的转码操作，360度视频推流是更为延迟敏感的应用。</p>
<p>现有的处理设备在诸如转码、渲染等实时处理任务上受到了限制。</p>
<h4 id="内容分发">内容分发</h4>
<h5 id="hus-work">Hu&rsquo;s work</h5>
<p>提出了一套基于云端的直播推流系统，叫做<code>MELiveOV</code>，它使高分辨率的全向内容的处理任务以毛细管分布的方式分发到多个支持5G的云端服务器。</p>
<ul>
<li>端到端的直播推流系统包括内容创作模块、传输模块和viewport预测模块。</li>
<li>移动边缘辅助的推流设计减少了50%的带宽需求。</li>
</ul>
<h5 id="griwodzs-work">Griwodz&rsquo;s work</h5>
<p>为360度直播推流开发了优化FoV的原型，结合了RTP和基于DASH的<code>pull-patching</code>来传送两种质量等级的360度视频给华为IPTV机顶盒和Gear VR头戴设备。</p>
<ul>
<li>作者通过在单个H.265硬件解码器上多路复用多个解码器来实现集体解码器的想法，以此减少切换时间。</li>
</ul>
<h4 id="视频转码">视频转码</h4>
<h5 id="lius-work-1">Liu&rsquo;s work</h5>
<p>研究表明只转码viewport区域有潜力大幅减少高性能转码的计算需求。</p>
<h5 id="baigs-work">Baig&rsquo;s work</h5>
<p>开发了快速编码方案来分发直播的4K视频到消费端设备。</p>
<ul>
<li>采用了分层视频编码的方式来在高度动态且不可预测的WiGig和WiFi链路上分发质量可变的块。</li>
</ul>
<h5 id="les-work">Le&rsquo;s work</h5>
<p>使用RTSP网络控制协议为CCTV的360度直播推流提出了实时转码和加密系统。</p>
<ul>
<li>转码方式基于ARIA加密库，Intel媒体SDK和FFmpeg库。</li>
<li>系统可以管理并行的转码操作，实现高速的转码性能。</li>
</ul>
<h4 id="内容拼接缝合">内容拼接缝合</h4>
<p>相比于其他因素如捕获、转码、解码、渲染，内容拼接在决定整体上的推流质量时扮演至关重要的角色。</p>
<h5 id="chens-work-1">Chen&rsquo;s work</h5>
<p>提出了一种内容驱动的拼接方式，这种方式将360度帧的语义信息的不同类型看作事件，以此来优化拼接时间预算。</p>
<ul>
<li>基于VR帧中的语义信息，tile执行器模块选择合适的tile设计。</li>
<li>拼接器模块然后执行基于tile的拼接，这样，基于可用资源，事件tile有更高的拼接质量。</li>
<li>评估表明系统通过实现89.4%的时间预算，很好地适应了不同的事件和时间限制。</li>
</ul>
<h3 id="总结-4">总结</h3>
<p>相比于点播式流媒体，360度直播推流面临多个挑战，例如在事先不知情的情况下处理用户导航、视频的首次流式传输以及实时视频的转码。在多用户场景中，这些挑战更为棘手。</p>
<p>关于处理多个用户的观看模式，可伸缩的多播可以用于在低带宽和高带宽网络上以接近于按需推流的质量等级。</p>
<p>基于ROI的tile拼接和转码可以显著地减少延迟敏感的交互型应用的延迟需求。</p>
]]></description>
</item><item>
    <title>沉浸式流媒体网络问题的相关解决方案</title>
    <link>https://ayamir.github.io/posts/note4/</link>
    <pubDate>Sat, 30 Oct 2021 19:20:00 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note4/</guid>
    <description><![CDATA[<h1 id="概况">概况</h1>
<p>现有的沉浸式流媒体应用都对带宽、QoS和计算需求有着高要求，这主要得益于5G网络。</p>
<p>传统的中心化云计算和云存储体系结构不适于实时的高码率内容分发。</p>
<p>边缘缓存和移动边缘计算成为了推动沉浸式流媒体发展的关键技术。</p>
<h1 id="解决方案">解决方案</h1>
<h2 id="360度视频的边缘协助推流">360度视频的边缘协助推流</h2>
<h3 id="背景">背景</h3>
<p>主要的视频内容可以被传送到边缘节点乃至下游客户端来满足高分辨率等级和严格的低延迟要求。</p>
<p>在边缘计算中，处理和存储的任务被从核心网转移到边缘节点例如基站、微型数据中心和机顶盒等。</p>
<h4 id="hous-work">Hou&rsquo;s work</h4>
<p>提出边缘/云服务器渲染可以使计算更加轻便，可以让无线VR/AR体验可行并且便携。</p>
<h4 id="zhangs-work">Zhang&rsquo;s work</h4>
<p>为VR多人游戏提出了一种混合边缘云基础架构，中心云负责更新全局游戏事件，边缘云负责管理视图更新和大规模的帧渲染任务，以此来支持大量的在线联机人数的低延迟游戏。</p>
<p>进一步陈述了一种服务器选择算法，它基于QoS和玩家移动的影响确保所有VR玩家之间的公平性。</p>
<h4 id="los-work">Lo&rsquo;s work</h4>
<p>考虑了为360度视频渲染提供边缘协助的设备的异质性。</p>
<ul>
<li>边缘服务器将 HEVC tile流转码为viewport视频流并传输到多个客户端。</li>
<li>最优化算法根据视频质量、HMD类型和带宽动态决定边缘节点服务哪个客户端。</li>
</ul>
<h4 id="边缘缓存策略">边缘缓存策略</h4>
<h5 id="背景-1">背景</h5>
<p>传统视频的缓冲方案并不能直接应用到360度视频上。</p>
<p>为了在启用边缘缓存的网络中促进360度视频的传输，两个传输节点之间的代理缓存被部署来使用户侧的内容可用。</p>
<p>边缘缓存能从实质上减少重复的传输并且可以使内容服务器更加可扩展。</p>
<h5 id="mahzais-work">Mahzai&rsquo;s work</h5>
<p>基于其他用户的观看行为为360度视频的流行内容提出了一种缓存策略。</p>
<ul>
<li>与最不常用 (LFU) 和最近最少使用 (LRU) 缓存策略相比，在缓存使用方面的性能分别提高了至少 40% 和 17%。</li>
</ul>
<h5 id="papaioannous-work">Papaioannou&rsquo;s work</h5>
<p>提出了基于tile分辨率和需求统计信息的缓存策略，用最少的错误，提高要求tile的和缓存tile这两种版本的viewport覆盖率。</p>
<ul>
<li>不同缓存和传输延迟的实验评估表明提高了缓存命中率，特别是对于分层编码的tile。</li>
</ul>
<h5 id="lius-work">Liu&rsquo;s work</h5>
<p>背景：</p>
<p>边缘缓存可以被在Evolved Packet Core处执行，因为packet大小很小所以这样可能会产生次优的性能。</p>
<p>另一种替换的方式是在Radio Access Network处缓存数据。但这样由于数据隧道和分包会变得更加复杂。</p>
<p>研究内容：</p>
<p>为移动网络提出了一种同时使用RAN和EPC的基于tile的缓存方案，以此在视频流延迟的约束下节省传输带宽。</p>
<ul>
<li>为EPC和RAN的缓存节点分别被部署在Packet Data Network Gateway和eNodeBs。</li>
<li>EPC中的内容控制实体负责为tile内容改善缓存利用率。</li>
<li>这种联合的tile缓存设计能以优秀的可伸缩性为<a href="https://zh.wikipedia.org/wiki/%E8%A1%8C%E5%8B%95%E7%B6%B2%E8%B7%AF%E5%9B%9E%E5%82%B3" target="_blank" rel="noopener noreffer">回程网络</a>显著地减少带宽压力。</li>
</ul>
<h5 id="maniotiss-work">Maniotis&rsquo;s work</h5>
<p>为了利用协作传输的机会，提出了一种在包含宏蜂窝基站(MBS)和多个小基站(SBS)的蜂窝网络中的tile级别的视频流行度感知缓存和传输方案。</p>
<ul>
<li>应用了一种高级的编码方式来创建灵活的tile编码结构，使在每个SBS中能协同缓存。</li>
<li>这种协同允许在 SBS 只存储可能被观看的图块，而其他图块可以通过回程链路获取。</li>
</ul>
<h5 id="chens-work">Chen&rsquo;s work</h5>
<p>为被捕获内容从<code>Drone base station</code>到小基站的联合缓存和分发提出了一种<code>echo-liquid</code>状态的 DRL 模型，使用高频毫米波通信技术。</p>
<ul>
<li>为了满足即时延迟的目标，基站可以从数据中缓存流行内容。</li>
<li>但是，小基站的广泛部署实际上消耗了很多能源。</li>
</ul>
<h5 id="yangs-work">Yang&rsquo;s work</h5>
<p>在计算资源受限制的MEC架构中，利用缓存和计算资源来降低对通信资源的要求。</p>
<ul>
<li>但是这种结构需要资源敏感的任务调度来平衡通信开销和延迟。</li>
</ul>
<h5 id="chakareskis-work">Chakareski&rsquo;s work</h5>
<p>为<code>multi-cell</code>网络环境中的AR/VR应用探索了最前沿的缓存、计算和通信机制。</p>
<ul>
<li>提出的框架允许基站利用适当的计算和缓存资源来最大化总计的回报。</li>
<li>只关注了缓存和渲染，没有考虑用户视角的感受以及处理事件。</li>
</ul>
<h5 id="suns-work">Sun&rsquo;s work</h5>
<p>在内容到达终端之前，同时利用FoV(Field of View)缓存和必要的计算操作来节省通信带宽而不牺牲响应时间。</p>
<ul>
<li>对于同质的FoVs，联合缓存和计算框架执行关于缓存和后期处理的最优决策。</li>
<li>对于异质的FoVs，应用凹凸表达式来得到有吸引力的结果。</li>
</ul>
<h5 id="rigazzis-work">Rigazzi&rsquo;s work</h5>
<p>基于一个开源项目Fog05提出了一个三层(3C)解决方案来分发密集的任务（例如编解码和帧重建），穿越中心云层，受约束的雾层和边缘节点层。</p>
<ul>
<li>利用了系统可伸缩性、互操作性和360度视频推流服务的生命周期循环。</li>
<li>实验性的评估表明在带宽、能源消耗、部署开销和终端复杂性方面取得了显著的减少。</li>
</ul>
<h5 id="elbambys-work">Elbamby&rsquo;s work</h5>
<p>通过在延迟和可靠性的约束下，应用积极的计算和毫米波传输，为交互式的VR游戏提出了一个联合框架。</p>
<ul>
<li>对视频帧做预计算和存储来减少VR流量。</li>
<li>评估表明这种联合机制可以减少多达30%的端到端延迟。</li>
</ul>
<h4 id="边缘计算的优势">边缘计算的优势</h4>
<ol>
<li>
<p>减少延迟</p>
<p>传统的云端节点距离用户较远，边缘计算使用户可以共享多个服务器池的协同计算资源。</p>
</li>
<li>
<p>降低能耗</p>
<p>根据网络架构和资源供应将计算卸载到分布式计算集群，能显著提高移动设备的性能。</p>
</li>
<li>
<p>负载均衡</p>
<p>边缘节点例如基站、小蜂窝和终端设备可以在用户端存储内容，降低了核心网的负载。</p>
</li>
</ol>
<h4 id="现有利用边缘计算的解决方案">现有利用边缘计算的解决方案</h4>
<p></p>
<ul>
<li>大多数任务卸载的MEC方案只致力于优化带宽、能源或延迟。</li>
<li>发展中的方案同时致力于许多其他重要的目标：可靠性、可移动性、QoS、部署成本、安全性。</li>
<li>利用带缓存的边缘计算的能力可以增强可移动性、位置感知能力、高效的数据分发、网络上下文理解和提供服务的安全性。</li>
<li>层级化的边缘-云体系结构对于适应360度视频快速动态传输是必要的。</li>
<li>相比于单静态层，多个动态缓存模型可以帮助管理唐突的viewport和网络变化来改善多用户的viewport命中率。</li>
<li>无论环境怎样，主动缓存都可以通过采用预测机制来预取和缓存部分视频来提高感知质量。</li>
</ul>
<h2 id="360度视频的协同传输">360度视频的协同传输</h2>
<h3 id="背景-2">背景</h3>
<ul>
<li>360度视频推流有较大的用户需求并且在逐渐增长。</li>
<li>目前推流viewport之外的冗余信息会浪费重要的网络带宽。</li>
<li>相同的360度视频内容，在带宽受限的网络之上被推流给多个用户时，码率的需求变得更难满足。</li>
</ul>
<p>几个方法应用了360度视频的协同传输，进而改善传输效率。</p>
<h3 id="方案">方案</h3>
<h4 id="ahmadis-work">Ahmadi&rsquo;s work</h4>
<p>引入了基于DASH的加权tile方法来优化子用户组请求的tile编码性能。</p>
<ul>
<li>提出了多播流方案基于被用户看到的可能性对tile分配适当的权重。</li>
<li>接着基于可用带宽和tile权重为每个子用户组选择tile的码率。</li>
<li>实际上因为相邻tile的不同质量导致了空间质量变化，最终造成糟糕的推流体验。</li>
<li>不必要的离散优化问题巨大，不能保证有积极的表现。</li>
</ul>
<h4 id="baos-work">Bao&rsquo;s work</h4>
<p>基于动作预测和并发观看用户的信道条件提出了一种多播框架，来只分发可能被看到的360度视频块。</p>
<ul>
<li>没有在无线多播传输中考虑优化资源分配。</li>
</ul>
<h4 id="guos-work">Guo&rsquo;s work</h4>
<p>为每个用户假设了一种随机动作模式和不稳定的信道条件，并且开发了多播机会来避免冗余数据传输。</p>
<p>作者考虑了两个非凸的问题：</p>
<ol>
<li>在给定视频质量的约束下，最小化平均传输时间和能源消耗。</li>
<li>在给定的传输时间和能源预算下，最大化每个用户的视频质量。</li>
</ol>
<h4 id="longs-work">Long&rsquo;s work</h4>
<p>考虑了传输时间、视频质量的平滑性和能源限制，在单服务器多用户无线网络环境中优化多个用户的聚合效用。</p>
<ul>
<li>为了减少传输复杂性，作者准备了多种质量的tile，并为每组用户将tile划分到不相邻的子集中。</li>
</ul>
<h4 id="zhangs-work-1">Zhang&rsquo;s work</h4>
<p>引入了一种使用SVC质量自适应方法的协同推流策略，来改善移动自组网环境中，观看360度内容的多个用户间的带宽共享。</p>
<ul>
<li>当遇到可用网络资源限制时，提出的启发性方式基于被看到的可能性和聚合的组级别偏好设置选择最优的tile子集。</li>
</ul>
<h4 id="kans-work">Kan&rsquo;s work</h4>
<p>提出了一种服务端混合多播-单播协同推流方案来分发不同质量的360度视频到多个用户。</p>
<ul>
<li>基于用户的观看行为对其进行分簇，以此来轻松共享相同的视频内容。</li>
<li>为每个tile联合选择传输模式和适当的码率来提高整体的QoE。</li>
</ul>
<h4 id="huang-and-zhangs-work">Huang and Zhang&rsquo;s work</h4>
<p>设计了一种MIMO网络中的MAC调度方式。</p>
<ul>
<li>资源分配策略基于三个主要的函数
<ol>
<li>基于延迟的<code>Motion-To-Photon</code>(MTP)VR帧权重计算。</li>
<li>基于最大<code>Aggregate Delay-Capacity Utility</code>（ADCU）的用户选择。</li>
<li>用于平衡VR数据传输的极高需求的链路自适应方法。</li>
</ol>
</li>
</ul>
<h4 id="li-and-gaos-work">Li and Gao&rsquo;s work</h4>
<p>提出了多用户VR框架，其中边缘云自适应地存储和重用冗余VR帧，以减少计算和传输负载。</p>
<ul>
<li>两级cache的设计：用户端的小型本地cache和边缘的大型中央cache。</li>
<li>通过为所有用户产生背景视图和无论何时都重用帧，使得减少了内存需求。</li>
<li>评估表明帧相关数据和计算负载分别减少了95%和90%。</li>
</ul>
<h4 id="总结">总结</h4>
<p>对推流到多个临近用户的流行内容共享例如360度视频是一种自然的选择。</p>
<p>然而非协作式的用户对带宽的竞争会快速使整个网络瘫痪。</p>
<p>为了为多个用户获得改善的QoE，研究者从以下几个方面做了努力：</p>
<ol>
<li>确定多个用户可能的需求来公平地分配可用的网络资源。</li>
<li>分析跨用户的行为来精确传输要求的子帧到终端用户。</li>
<li>由于侧信道攻击，保护VR帧传输到多个终端用户。</li>
</ol>
]]></description>
</item><item>
    <title>自适应360度视频推流方案</title>
    <link>https://ayamir.github.io/posts/note3/</link>
    <pubDate>Mon, 25 Oct 2021 09:34:10 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note3/</guid>
    <description><![CDATA[<h2 id="概述">概述</h2>
<p>360度视频的推流手段逐渐从视角独立型方案变成基于tile的视角依赖型方案。</p>
<p>相比于常规视频，360度视频被编码成全向的场景。</p>
<p>自适应360度视频推流利用DASH框架来实现比特率的自适应。</p>
<h2 id="分类">分类</h2>
<h3 id="viewport-independent-streaming">Viewport-Independent Streaming</h3>
<h4 id="服务端的任务">服务端的任务</h4>
<ul>
<li>使用如ERP、CMP等视角独立型的投影方式，360度视频被投影到一个球体上。</li>
</ul>
<h4 id="客户端的任务">客户端的任务</h4>
<ul>
<li>投影之后的视频直接被传送到客户端，并不需要来自传感器的方向信息。</li>
<li>客户端需要支持对应的投影格式。</li>
<li>客户端像处理传统视频一样完成比特率自适应。
<ul>
<li>基于网络特征向将要到来的segment请求相同投影格式的表示</li>
</ul>
</li>
</ul>
<p>DASH插件需要支持相同质量视频的推流。</p>
<h4 id="应用">应用</h4>
<p>视角独立型推流主要用于体育、教育和旅游视频内容。</p>
<h4 id="优点">优点</h4>
<ul>
<li>简单</li>
</ul>
<h4 id="缺点">缺点</h4>
<ul>
<li>相比于视角依赖型方案视频编码效率低了30%。</li>
<li>为不可见的区域要求大量带宽和解码资源。</li>
</ul>
<h3 id="viewport-dependent-streaming">Viewport-Dependent Streaming</h3>
<h4 id="终端设备的任务">终端设备的任务</h4>
<ul>
<li>只接受特定的视频帧内容，包括等于或大于视角角度的可见信息。</li>
<li>监测相关的视角作为用户头部移动的回应，并且向服务端发送信号来精确播放器信息。</li>
<li>为服务端准备和用户方向相关的几个自适应集。</li>
</ul>
<h4 id="客户端的任务-1">客户端的任务</h4>
<ul>
<li>根据网络情况和估计的视角位置决定获取哪个自适应集。</li>
</ul>
<h4 id="难点">难点</h4>
<ul>
<li>可视区域的确定</li>
<li>与用户头部移动的同步</li>
<li>质量调整</li>
<li>提供平滑的播放体验</li>
</ul>
<h4 id="现有的工作">现有的工作</h4>
<h5 id="各种投影方式在实际推流中表现如何">各种投影方式在实际推流中表现如何？</h5>
<ul>
<li>相比于金字塔格式，为视角依赖型投影方案提出的多分辨率变体有最好的研究和开发(RD)性能。</li>
<li>偏移CMP获得了5.6%到16.4%的平均可见质量。
<ul>
<li>提出的框架可以基于已知的网络资源和未来的视角位置适应视角的尺寸和质量。</li>
<li>相比于理想的下载过程，这种二维自适应策略可以花费20%的额外网络带宽下载超过57%的额外视频块。</li>
</ul>
</li>
</ul>
<h5 id="如何在网络资源受限的情况下提供高质量的推流">如何在网络资源受限的情况下提供高质量的推流？</h5>
<ul>
<li>为视角依赖型推流产生不同质量的segment。
<ul>
<li>当流中只有有限的representation时，利用Quality Emphasized Regions策略来缩放特定区域的分辨率。</li>
<li>在拥塞网络条件下，执行了基于网络回应的视角大小和比特率的联合适应，结果显示，相比于传送全部的360度场景，动态的视角覆盖率提供了更好的画面质量。</li>
<li>这种基于网络回应的自适应也确保基于整体拥塞变化做调整时能改善视频质量。</li>
</ul>
</li>
<li>为立体视频的背景和前景视图采用不对称质量。
<ul>
<li>可以分别为背景块和前景块分别节省15%和41%的比特率。</li>
</ul>
</li>
</ul>
<h5 id="dash需要做什么">DASH需要做什么？</h5>
<ul>
<li>manifest中需要包含视角位置信息和投影元数据。</li>
<li>优化获取random access point的周期来优化视角分辨率自适应体验。</li>
<li>考虑低延迟和活跃的视角切换。</li>
</ul>
<h3 id="tile-based-streaming">Tile-based Streaming</h3>
<p>传统视频被分成多个块，360度视频在块的基础上还被分成多个大小相等或者不等的tile，以此更加精确地调整画面的细节质量。</p>
<h4 id="分块策略">分块策略</h4>
<ul>
<li>
<p>基本完全交付</p>
</li>
<li>
<p>高级完全交付</p>
</li>
<li>
<p>部分交付</p>
</li>
</ul>
<p></p>
<h4 id="分块模式">分块模式</h4>
<p>1x1，3x2，5x3，6x4，8x5</p>
<p>其中6x4的模式实现了较好的带宽消耗和编码效率的折中。</p>
<p>在不同的带宽条件下，基本完全交付策略获得了大约65%的带宽节约。</p>
<h4 id="具体方案">具体方案</h4>
<h5 id="clustile">ClusTile</h5>
<p>基于分簇的方式，推送满足最小带宽需求的tile来克服编码效率和计算开销。</p>
<ul>
<li>相比于传统和高级的基于tile的推流方案，分别实现了72%和52%的带宽节约。</li>
<li>当实际看到的和下载的tile有差异时，基于分簇的tile选取可能会导致选择不当。</li>
</ul>
<h5 id="ghoshs-work">Ghosh&rsquo;s work</h5>
<p>提议以最低可获得的质量下载周围和远处的tile。</p>
<ul>
<li>相比于其他算法，视角及其周边区域的可变质量提高了20%的QoE水平。</li>
</ul>
<h5 id="ozcinars-work">Ozcinar&rsquo;s work</h5>
<p>介绍了一种自适应 360° 视频流框架。</p>
<ul>
<li>
<p>利用视觉注意力度量来计算每个帧的最佳平铺模式。</p>
</li>
<li>
<p>使用选中的模式，为不同区域的tile分配非统一的比特率。</p>
</li>
<li>
<p>比特率的选取取决于估计的视角和网络状况。</p>
</li>
<li>
<p>因为很大部分的带宽被用于传输非视角内的tile，框架难以优化视角内的质量。</p>
</li>
</ul>
<h5 id="xies-work">Xie&rsquo;s work</h5>
<p>提出了一套优化框架，以此来最小化预取tile的错误，改善与不同比特率相关联的tile边界的平滑程度。</p>
<ul>
<li>
<p>定义了两个QoE函数，目标是最小化：</p>
<p>预期质量失真$\Phi(X)$</p>
<p>当考虑tile看到概率时视角的空间质量方差$\Psi(X)$：
$$
\Phi(X) = \frac{\sum_{i=1}^{N}\sum_{j=1}^{M}D_{i,j} * x_{i,j} * p_{i,j}}{\sum_{i=1}^{N}\sum_{j=1}^{M}x_{i,j} * s_{i}}
$$</p>
<p>$$
\Psi(X) = \frac{\sum_{i=1}^{N}\sum_{j=1}^{M}x_{i,j}*p_i * (D_{i,j} - s_i * \Phi(X))^{2}}{\sum_{i=1}^{N}\sum_{j=1}^{M}x_{i,j}*s_i}
$$</p>
</li>
<li>
<p>基于目标缓冲区的自适应方法用于在需要短期视口预测的小缓冲区下进行平滑播放</p>
<p>在自适应的第k步，当第k个segment集合下载完成时，缓冲区占用率$b_k$由下面的式子给出：
$$
b_k = b_{k-1} - \frac{R_k*T}{C_k} + T
$$
为了避免用尽所有块，缓冲区的占用率被通过设定一个目标缓冲区水平$B_{target}$所控制，即$b_k = B_{target}$。</p>
</li>
<li>
<p>平均空间质量方差是0.97，比其他基于tile的策略小。</p>
</li>
<li>
<p>所提出的概率自适应框架在感知质量上实现了约 39% 的增益，平均降低了 46% 的空间质量方差。</p>
</li>
</ul>
<h5 id="vander-hoofts-work">Vander Hooft&rsquo;s work</h5>
<p>将360度帧划分成视角内区域和视角外区域。</p>
<ul>
<li>首先为所有区域都选择最低质量，然后提高视角内tile的质量。</li>
<li>如果带宽依然可用，接着提高剩下的tile的质量。</li>
<li>启发式的方式在带宽可用的基础上积极提高视角内tile的质量。</li>
<li>没有考虑视角比特率调整时视角预测的错误。</li>
</ul>
<h5 id="nguyens-work">Nguyen&rsquo;s work</h5>
<p>提出了一种新的自适应机制，它在每个segment中同时考虑头部移动和视角的预测错误，动态地决定视角内的比特率。</p>
<ul>
<li>联合适应扩展块的覆盖范围和比特率。</li>
<li>在不同记录的用户头部运动下的实验评估表明，在不获取非视角内区域过多带宽利用率的情况下，视角内容质量有所提高。</li>
</ul>
<h4 id="dash-srd扩展">DASH SRD扩展</h4>
<p>DASH的SRD扩展提供了多种版本的tile的关联来节省更多的比特率。</p>
<h5 id="le-feuvre-and-concolatos-work">Le Feuvre and Concolato&rsquo;s work</h5>
<p>他们应用了这个SRD特性，引入了同时为独立的和运动受限的HEVC tile的不同优先级设定，以此来高效地实现基于tile的方案。</p>
<ul>
<li>使用开源的GPAC多媒体框架开发了一个DASH客户端，以此来执行带有可配置参数的基于tile的推流。</li>
</ul>
<h5 id="dacuntos-work">D&rsquo;Acunto&rsquo;s work</h5>
<p>提出了一种 <a href="https://github.com/tnomedialab/dash-srd.js" target="_blank" rel="noopener noreffer">MPEG-DASH SRD 方法</a>来促进可缩放和可平移视频的平滑推流。</p>
<ul>
<li>总是下载低分辨率的tile来避免用户移动视角时的重新缓冲。</li>
<li>当前视野区域被上采样并展示给用户，以此来支持高质量的缩放功能。</li>
<li>用<code>JavaScript</code>实现了SRD视频播放器。</li>
</ul>
<h5 id="hosseinis-work">Hosseini&rsquo;s work</h5>
<p>基于SRD实现了视角内容、相邻tile和剩余tile的优先级推流。</p>
<ul>
<li>用6个3D网格构建了一套3D座标系来在3D空间中平滑地表示tile。</li>
<li>相比于基础的方式，这种区分质量的推流方案节省了72%的带宽。</li>
</ul>
<h5 id="kim-and-yangs-work">Kim and Yang&rsquo;s work</h5>
<p>使用改进的MPEG-DASH SRD来在质量可变的tile层中作选择。</p>
<ul>
<li>基于他们之前的工作设计并实现了一个支持多层渲染的 360° VR 播放器，以支持高度不可预测的头部运动数据的高分辨率和低延迟流。</li>
</ul>
<h4 id="motion-constrained-tileset">Motion-Constrained TileSet</h4>
<p>在HEVC中，运动约束贴图集(MCTS)是将整个帧表示为子视频的相邻分割，并为自由选择的贴图集提供解码支持。</p>
<h5 id="zares-work">Zare&rsquo;s work</h5>
<p>将MCTS的概念应用到了全景视频推流中。</p>
<ul>
<li>将两个质量版本的视频分割成tile，以原始的分辨率推流视角内的tile，以低分辨率推流剩余的tile。</li>
<li>它已经表明，选定图块的可变比特率会降低 30% 到 40% 的比特率。</li>
</ul>
<h5 id="skupins-work">Skupin&rsquo;s work</h5>
<p>陈述了一种使用HEVC编码器的基于tile的可变分辨率的推流系统。</p>
<ul>
<li>使用立方贴图投影的360度视频被分割成24个网格，每个代表了一个独立的比特流。</li>
<li>两种不同质量的版本被推流到客户端，例如8个tile以高质量推送，16个tile以低质量推送。</li>
</ul>
<h5 id="sons-work">Son&rsquo;s work</h5>
<p>在基于视角的移动VR推流中，为独立的tile提取和传输实现了基于MCTS的HEVC和可缩放的HEVC编解码器。</p>
<ul>
<li>节省了超过47%的带宽。</li>
<li>相比于原始的HM和SHM编码器表现不佳，因为MCTS限制了时间运动信息。</li>
</ul>
<h5 id="lees-work">Lee&rsquo;s work</h5>
<p>用MCTS编码360度视频tile，并使用显著性检测网络将混合质量的视频tile推流给终端用户。</p>
<ul>
<li>通过显著性模型改进MCTS的使用，可以在不增加任何复杂性的情况下灵活地对感兴趣的tile区域进行解码支持。</li>
</ul>
<h4 id="scalable-video-code">Scalable Video Code</h4>
<p>可伸缩视频编码SVC是实现viewport自适应的一种替代策略。</p>
<p>基础层总被需要并且能从客户端预取来避免重新缓冲事件。</p>
<p>提高层改善viewport质量并且可以在带宽充足的时候被请求。</p>
<p>SVC促进了一种高效的网络内缓存支持来减少多个客户端请求相同内容时的分发开销。</p>
<h5 id="nasrabadis-work">Nasrabadi&rsquo;s work</h5>
<p>使用了一种可伸缩编码方案来解决360度视频推流的重新缓冲的问题。</p>
<ul>
<li>存在质量波动的问题，因为没有使用任何机制来处理viewport的预测错误。</li>
</ul>
<h5 id="nguyens-work-1">Nguyen&rsquo;s work</h5>
<p>建议使用SVC协同viewport预测来克服网络信道和头部运动的随机性。</p>
<ul>
<li>实验表明，所提出的平铺层更新和后期平铺终止特征可使viewport质量提高17%。</li>
</ul>
<h4 id="ai方法的应用">AI方法的应用</h4>
<p>背景：传统视频推流中使用强化学习来高效调整视频比特率和实现长期的QoE回报。</p>
<p>和传统视频内容不同，360度视频包含几个新的方面比如tile大小、viewport预测等。</p>
<p>直接将现有的强化学习自适应策略应用到360度视频上可能会降低推流性能。</p>
<h5 id="fus-work">Fu&rsquo;s work</h5>
<p>为360度视频提出了称为<em>360SRL</em>的一种序列化强化学习方法，它基于之前决策的QoE回报而非估计的带宽状况做出自适应决策。</p>
<ul>
<li>360SRL使用基于tile的推流模拟器来增强训练阶段。</li>
<li>跟踪驱动的评估表明，360SRL比基线适应方法取得了12%的QoE改善。</li>
</ul>
<h5 id="jiangs-work">Jiang&rsquo;s work</h5>
<p>基于历史带宽、缓冲区空间、tile大小和viewport预测错误等，利用强化学习来做viewport和非viewport内tile的比特率选择。</p>
<ul>
<li>所提出系统的架构由状态缓冲区、视口预测 (VPP) 和tile比特率选择 (TBS) 代理组成。</li>
<li>状态缓冲区向VPP和TBS代理提供用户查看模式和网络状态。</li>
<li>VPP代理然后使用LSTM模型估计下一个viewport位置。</li>
<li>TBS 代理由 Asynchronous Advantage Actor-Critic (A3C)算法训练以执行合适的比特率决策。</li>
</ul>
<h5 id="quans-work">Quan&rsquo;s work</h5>
<p>通过卷积神经网络(CNN)提取像素运动来分析用户QoE，并使用它对tile动态分组，从而在视频质量和编码效率之间提供重要的平衡。</p>
<ul>
<li>使用了基于强化学习的自适应代理，它可以智能地使每个图块的质量适应动态环境。</li>
<li>使用真实LTE带宽跟踪验证该方案，在感知质量方面表现出了卓越的性能，同时也节省了带宽资源。</li>
</ul>
<p>背景：深度学习使强化学习能够使用多方面的状态和动作空间进一步优化聚合回报。</p>
<h5 id="kan-and-xiaos-work">Kan and Xiao&rsquo;s work</h5>
<p>设计了一套深度强化学习的框架，基于对环境因素的探索和开发，自适应地调整推流策略。</p>
<ul>
<li>这两种方案都采用DRL的A3C算法来进行比特率决策，因为A3C算法能使代理变得越来越智能化。</li>
<li>性能评估表明，所提出的系统平衡了各种 QoE 指标，包括平均视觉质量、平均质量波动和重新缓冲事件等。</li>
</ul>
<h5 id="zhangs-work">Zhang&rsquo;s work</h5>
<p>提出了一个深度强化学习模型，它考虑viewport预测准确度和网络状况，使用基于LSTM的ACTOR-CRITIC(AC)网络动态地学习适应比特率分配。</p>
<ul>
<li>方案能够很好地适应广泛的动态特性，并且与传统方法相比，提供了20%到30%的改进QoE回报。</li>
</ul>
<h4 id="总结">总结</h4>
<p>基于tile的推流只需要少量的服务端内容版本。</p>
<p>与依赖视图的推流相比，它包含更低的存储和处理开销。</p>
<p>提出的大多数方案为viewport及其临近的tile使用不同的分辨率，这会为高效推流减少带宽开销。</p>
<p>但是这种区分分辨率的tile为了防止viewport预测错误会显著地降低能察觉到的视频质量。</p>
<p>一个50个用户的主观实验表明，当混合1920x1080和960x540分辨率的块时，绝大多数用户能观察到明显的质量降低。</p>
<p>但是当混合1920x1080和1600x900分辨率的块时，用户只会注意到微小的差别。</p>
<p>对于高运动内容，这种混合效应甚至会导致严重的质量下降。</p>
<p>因此为了动态执行tile的选择和基于DRL的比特率适应，需要有一个推流分辨率的恰当选择，进而在流质量、空间质量方差、视口预测误差和带宽效率之间获得完美的平衡。</p>
]]></description>
</item><item>
    <title>自适应视频推流方案</title>
    <link>https://ayamir.github.io/posts/note2/</link>
    <pubDate>Thu, 21 Oct 2021 10:50:54 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note2/</guid>
    <description><![CDATA[<h2 id="概述">概述</h2>
<p>自适应方案可以在处理不同目标对象时帮助改善推流体验。</p>
<p>目标主要包括视频质量、功耗、负载均衡等在移动无线网和有线网接入的情形。</p>
<p>适应性的视频比特率需要同时匹配网络条件和质量目标的需求。</p>
<h2 id="分类">分类</h2>
<h3 id="服务端适应">服务端适应</h3>
<p>大多数服务端适应的方案要求客户端发送系统或网络相关信息。</p>
<h4 id="质量导向的适应方案quality-oriented-adaptive-schemeqoas">质量导向的适应方案（Quality-Oriented Adaptive Scheme/QOAS）</h4>
<p>向终端用户提供了高知觉质量的媒体内容。</p>
<ol>
<li>
<p>QOAS是C-S架构，决策在服务器端产生。</p>
</li>
<li>
<p>QOAS基于客户知觉质量的反馈，提供对推流质量等级的调整。</p>
</li>
</ol>
<h4 id="智能优先级适应方案intelligent-prioritized-adaptive-schemeipas">智能优先级适应方案（intelligent Prioritized Adaptive Scheme/iPAS）</h4>
<p>专用于802.11网络。</p>
<ol>
<li>
<p>iPAS服务器上的基于固有印象的带宽分配模块被用于组合QoS相关的参数和视频内容特征来进行内容的优先级分类和带宽份额分配。</p>
</li>
<li>
<p>通过区分多媒体流，iPAS提供可用无线信道的优先级分配。</p>
</li>
</ol>
<h4 id="设备导向的适应方案device-oriented-adaptive-multimedia-schemedoas">设备导向的适应方案（Device-Oriented Adaptive multimedia Scheme/DOAS）</h4>
<p>专用于LTE网络，建立在LTE下行链路调度机制之上。</p>
<ol>
<li>DOAS专门根据设备特性实现适配，尤其为多屏终端用户提供了卓越的QoE。</li>
</ol>
<h3 id="客户端适应">客户端适应</h3>
<h4 id="基于吞吐量的自适应方案">基于吞吐量的自适应方案</h4>
<p>这类方案基于估计的网络吞吐量从服务端选择视频的比特率。</p>
<ol>
<li>HTTP客户端通过之前的观察记录来估计网络的吞吐量。</li>
<li>通过测量端获取时间（segment fetch time/SFT）来代表发起和收到回复的瞬时HTTP GET请求之间的时间段，以此来确定一个推流会话中吞吐量的变化，进而独立地做出适应决策。</li>
<li>在分布式网络中，同时考虑并发和顺序的SFT。通过比较实际的和理想的SFT来选择未来的segment的质量等级。</li>
</ol>
<h5 id="festive算法">FESTIVE算法</h5>
<p>适用于多个HAS客户端共享一个常见的拥塞带宽链路的情形。</p>
<p>以<strong>效率、稳定性、公平性</strong>为度量因素的适应性算法。</p>
<p>探索了一种为<strong>分段调度、吞吐量估计和比特率选择</strong>而生的健壮的机制。</p>
<p>包含一个随机调度器来调度下一个视频块的下载。</p>
<p>多个客户端共享容量为$W$的满带宽链路，每个客户端$x$在$t$时刻播放的视频比特率为$b_x,_t$ ，需要避免以下3种问题：</p>
<ul>
<li>
<p><em>Inefficiency</em>：多个HAS客户端必须能选择最可能的表示来提高QoE。</p>
<p>$$ Inefficiency = \frac{|\sum_{x}b_x,_t - W|}{W} $$</p>
<p>低<em>Inefficiency</em>值表明多个客户端对带宽实现了最有效的利用。</p>
</li>
<li>
<p><em>Unfairness</em>：可用带宽应该被均等地分配。</p>
<p>$$ Unfairness = \sqrt{1-JainFair} $$</p>
<p>低<em>Unfairness</em>值表明多个客户端有相近的比特率。</p>
</li>
<li>
<p><em>Instability</em>：不必要的比特率切换会损害推流体验</p>
<p>$$Instability = \frac{\sum_{d=0}^{k-1}|b_{x,t-d} - b_{x,t-d-1}|*w(d)}{\sum_{d=1}^{k}b_{x,t-d} * w(d)}$$</p>
</li>
</ul>
<h5 id="probe-and-adaptpanda算法">Probe AND Adapt(PANDA)算法</h5>
<p>用于检测网络状况，考虑未来比特率选择的平均目标数据比特率。</p>
<p>目标是当多个HAS客户端共享一个拥塞带宽信道时，通过正确探测网络，进而最小化<strong>比特率震荡</strong>。</p>
<p>PANDA算法在性能上击败了FESTIVE算法，并且PANDA算法在这些解决方案中表现出了最好的适应性，在不同带宽情况和播放器设置下实现了最优的<strong>效率、公平性和稳定性</strong>。</p>
<p>整体上的推流质量不只依赖于本地的吞吐量测量，还依赖服务端的网络容量。</p>
<ol>
<li>利用服务器发起的推送机制来降低DASH内容推流到移动客户端的端到端延迟。</li>
<li>利用<em>HTTP/2</em>的流终止特性来实现中间质量调整。</li>
<li>基于估计的用户QoE，功耗和可用资源来改善用户端的推流体验。</li>
</ol>
<p>虽然有证据表明性能得到了提高，但是评估工作只是在受控的LAN环境下有效。</p>
<h5 id="cross-session-stateful-predictorcs2p方案">Cross Session Stateful Predictor(CS2P)方案</h5>
<p>一种数据驱动的吞吐量估计方案，以克服不准确的 HAS 流量预测问题。</p>
<p>将共享相似特性的推流会话分簇，然后对每个簇使用隐马尔科夫模型预测相应的吞吐量样本。</p>
<p>在一个大规模数据集上实验性的评估表明：CS2P高效地估计了可用的网络吞吐量，进而改善了整体上的视频比特率的适应性。</p>
<p>CFA和Pytheas等方案和CS2P类似，也使用数据驱动的控制器来估计可用的吞吐量。</p>
<p>但是这些工作<strong>不支持异构系统</strong>并且<strong>需要额外的训练复杂性</strong>，使其不够具有吸引力。</p>
<p>基于吞吐量的适应性方案主要的挑战在于对吞吐量的精确估计。</p>
<p>为360度视频采用一个没有经过精巧设计的吞吐量估计机制可能会导致不稳定性和较差的QoE，在高度动态化的无线和蜂窝网络中尤甚。</p>
<h4 id="基于缓冲区的自适应方案">基于缓冲区的自适应方案</h4>
<p>客户端会在播放视频时根据当前缓冲区的占用情况请求将要到来的segment。</p>
<h5 id="如何克服不完整的网络信息的限制">如何克服不完整的网络信息的限制</h5>
<ol>
<li>
<p>在多客户端启用缓存的环境中，结合客户端测量工具集和补偿算法构造模型。</p>
<p>这个模型可以高效探测比特率切换时间并通过选择切换适当的比特率来进行补偿，最终实现了可达20%的比特率改善。</p>
</li>
<li>
<p>Buffer Based Adaptation(BBA)方法</p>
<p>应用于Netfix客户端时可以减少可达20%的重新缓冲事件。</p>
<p>BBA方法考虑的缓冲区较大，因此对于比较短的视频不一定有这样的性能。</p>
</li>
<li>
<p>Buffer Occupancy-based Lyapunov Algorithm(BOLA)</p>
<p>把比特率适应性问题看作是与播放质量和重新缓冲时间相关的最优化问题。</p>
<p>BOLA旨在通过把缓冲区大小保持在设定的目标水平来避免重新缓冲。</p>
<p>对于缓冲区级别的突然下降，BOLA通过请求最低可用视频比特率来避免停顿事件的频率。</p>
</li>
</ol>
<h5 id="如何优化缓冲区利用率">如何优化缓冲区利用率</h5>
<ol>
<li>
<p>Adaptation and Buffer Management Algorithm(ABMA+)</p>
<ul>
<li>基于重新缓冲事件的可能性确定未来representation的下载时间。</li>
<li>通过基于预先计算的缓冲区大小和segment下载时间选择最大比特率来确保流畅的播放。</li>
</ul>
<p>这样可以实现低计算开销的良好部署。</p>
</li>
<li>
<p>Scalable Video Coding(SVC)/Bandwidth Independent Efficient Buffering(BIEB)</p>
<ul>
<li>基于层分发获取视频块，进而维持稳定的缓冲区大小来避免频繁的中断。</li>
<li>没有考虑QoE模型中的卡顿和质量切换。</li>
<li>涉及额外的编码和处理开销。</li>
</ul>
</li>
<li>
<p>使用PID控制器的控制论方法</p>
<ul>
<li>强制执行缓冲区设置点来使缓冲区保持在最佳水平。</li>
<li>略微降低视频比特率，以防止不必要的视频比特率调整。</li>
<li>在多个客户端竞争的情况下，不能保证公平性。</li>
</ul>
</li>
</ol>
<h5 id="如何降低dash流的排队延迟">如何降低DASH流的排队延迟</h5>
<p>DASH流会经历最长可达1s的排队延迟和严重拥塞，导致缓冲区膨胀问题，而这会严重损害实时多媒体服务的QoE。</p>
<p>旨在减少网络拥塞的主动队列管理 (AQM) 策略并没有充分减少这种不必要的延迟。</p>
<ol>
<li>DASH客户端根据网络设备的队列大小动态接收窗口大小可以显著减轻缓冲区膨胀效应。</li>
<li>由于长期的viewport预测的高度不确定性，充足的缓冲区空间对于360度视频的流畅播放来说并不可行。</li>
<li>通常小于3s的缓冲区大小对于短期的viewport预测来讲比较适合。</li>
<li>由于小缓冲区很有可能造成播放卡顿，因此较短持续时间的segment可以被用于基于tile的流中，但是相比于长持续时间的segment，这样也会降低编码效率。</li>
</ol>
<h4 id="混合自适应方案">混合自适应方案</h4>
<p>客户端同时考虑吞吐量和播放缓冲信号来确定即将到来的segments的视频比特率。</p>
<h5 id="model-predictive-controlmpc">Model Predictive Control(MPC)</h5>
<p>利用良好定义的参数集合来估计可用的网络和缓冲区资源，进而为高QoE的比特率做出最优调整的控制论方法。</p>
<p>提出的QoE模型采用视频的平均质量$R_k$，平均比特率切换，重新缓冲事件，和初始延迟$T_s$作计算：
$$
QoE_1^K = \sum_{k=1}^{K}q(R_k) - \lambda\sum_{k=1}^{K-1}|q(R_{k+1}) - q(R_k)| - \mu\sum_{k=1}^{K}(d_k(R_k)/C_k - B_k)_+ - \mu_sT_s
$$
$C_k$：第k个块的可用带宽，$B_k$：第k个块的可用缓冲区大小</p>
<p>$\lambda, \mu, \mu_s$：可以根据用户兴趣进行调整的权重</p>
<ul>
<li>
<p>MPC用调和平均的方法来估计吞吐量，并且能够明确管理复杂的控制对象。</p>
</li>
<li>
<p>只研究了单播放器的情况，因此没有公平性的考量。</p>
</li>
</ul>
<h5 id="throughput-and-buffer-occupancy-based-adaptationtboa">Throughput and Buffer Occupancy-based Adaptation(TBOA)</h5>
<p>选择合适的视频比特率来获得单个或多个客户端环境中改进的推流体验。</p>
<ul>
<li>
<p>激进地提高了比特率来最高效地利用可用的带宽。</p>
</li>
<li>
<p>等待缓冲区超过某个级别，然后降低比特率以获得稳定的性能。</p>
</li>
<li>
<p>为缓冲区等级设置三个阈值，例如：</p>
<p>$0 &lt; B_{min} &lt; B_{low} &lt; B_{high}$</p>
<p>目标区间在$B_{low}$和$B_{high}$之间。</p>
<p>算法努力使最优区间$B_{opt}满足$ $B_{opt} = B_{low} + B_{high} \over 2$。</p>
<p>通过控制$B_{low}$和$B_{high}$的阈值，使缓冲区和比特率的变化稳定来应对未知的TCP吞吐量。</p>
</li>
<li>
<p>算法表现的流畅而公平，但是没有把用户满意度的度量考虑在内。</p>
</li>
</ul>
<h5 id="fuzzy-logic-based-dash">fuzzy logic-based DASH</h5>
<p>控制重新缓冲事件和视频推流的质量。</p>
<ul>
<li>考虑了平均吞吐量的估计方法，获得了更高的视频比特率和更少的质量波动。</li>
<li>没有考虑QoE度量。</li>
</ul>
<p>为了更好地调整比特率做出的改进：</p>
<ul>
<li>用Kaufman&rsquo;s Adaptive Moving Average/KAMA测量法估计吞吐量。</li>
<li>用Grey Prediction Model/GPM来估计缓冲区等级。</li>
</ul>
<p>竞争流模拟环境中，改进所取得的效果：</p>
<ul>
<li>平均情况下达到50%的公平性。</li>
<li>最好情况下达到17%的更好的接收质量。</li>
</ul>
<h5 id="spectrum-based-quality-adaptationsquad算法">Spectrum-based Quality Adaptation(SQUAD)算法</h5>
<p>解决吞吐量预测和缓冲区等级估计的不连续性。</p>
<ul>
<li>吞吐量和缓冲区等级反馈信号都被用于选择恰当的质量。</li>
<li>在一开始获取最低质量的segment来减少启动时间。</li>
<li>在视频质量切换频率和幅度方面性能显著提高。</li>
</ul>
<p>尚未有方案讨论如何在视频质量和带宽利用率之间做出很好的平衡。</p>
<h5 id="throughput-friendly-dashtfdash">Throughput Friendly DASH/TFDASH</h5>
<p>获得多个竞争客户端情形下的公平性、稳定性和效率。</p>
<ul>
<li>通过避免OFF端获得了最大并且公平的带宽利用率。</li>
<li>双阈值的缓冲区保证播放时的稳定性。</li>
</ul>
<p>在单客户端的环境中，混合适应方案表现的很合理。</p>
<p>但是多个客户端一起竞争带宽时会迅速扼杀整个网络。</p>
<p>当客户端的缓冲区达到了最大阈值时，客户端进入了ON-OFF阶段，此时客户端只对自己的视频比特率做了调整而没有考虑其他客户端，因而不能正确地估计可用的带宽资源。</p>
<p>这会导致竞争客户端之间带宽利用不足以及带宽分配不均。</p>
<h4 id="基于多路径的自适应方案">基于多路径的自适应方案</h4>
<p>解决的主要问题是在异质网络之上，如何面对交付内容的增加。</p>
<h5 id="multipath-transmission-control-protocolmptcp">Multipath Transmission Control Protocol(MPTCP)</h5>
<ul>
<li>有用但是并不理想
<ul>
<li>因为需要发送端和接收端同时修改内核堆栈。</li>
<li>因为受到网络运营商的限制可能无法通过中间件。</li>
</ul>
</li>
</ul>
<h5 id="cmt-qa方案">CMT-QA方案</h5>
<p>采用多种特定的网络技术来实现并发的多路内容交付。</p>
<h5 id="multi-source-playermsplayer">Multi-source player(MSPlayer)</h5>
<p>实现多条链路之上的高质量视频传送和弹性的容错机制。</p>
<ul>
<li>
<p>客户端驱动的对未来视频segment的比特率分配依赖于估计的网络状况。</p>
</li>
<li>
<p>视频segment可以在两种可用网络之上进行下载，但是多路径的下载可能会造成交付顺序错乱。</p>
</li>
</ul>
<h5 id="cross-layer-fairness-solution">Cross-layer Fairness solution</h5>
<p>通过探索数据链路层和传输层之间的交互来分析数据传输路径的实时质量，提出了一个公平性驱动的高效流控机制。</p>
<p>在模拟环境中，相比于CMT-QA方案：</p>
<ul>
<li>获得了更高的公平性评级。</li>
<li>获得了更低的平均吞吐量和PSNR（峰值信噪比）。</li>
</ul>
<h5 id="kim-and-chungs-work">Kim and Chung&rsquo;s work</h5>
<p>同时利用WiFi和LTE网络接口，从多个视频源下载部分segment。</p>
<ul>
<li>对多路径的聚合带宽进行平滑处理以避免带宽波动。</li>
<li>实现了一种部分segment请求策略以避免乱序问题，经过各种路径传输的部分片段
在呈现给用户之前进行组合。</li>
</ul>
<h5 id="gos-work">Go&rsquo;s work</h5>
<p>在网络成本限制下，调度跨网络间相同比特率的视频块中的所有segment。</p>
<h5 id="基于mpeg-dash的推流策略实验性评估">基于MPEG-DASH的推流策略实验性评估</h5>
<p>以低功耗为移动设备提供了WiFi和LTE网络下的无缝视频播放。</p>
<ul>
<li>没有分析感知视频质量的影响。</li>
</ul>
<h5 id="davvi">DAVVI</h5>
<p>基于HTTP的推流系统，为了实现3G和WiFi网络之上的多信道支持。</p>
<ul>
<li>基于每个信道的质量，视频segment被动态地划分成subsegment，以便于最大负载可以被应用到每个信道上。</li>
</ul>
<p>为多媒体内容交付使用多个网络接口需要为路径质量测量和数据调度精心设计机制，来避免丢包和乱序交付的问题。</p>
<p>然而因为无线异质网络的高度动态性和复杂性，现有的方案在测量实时信息的时候是受限的。</p>
<h5 id="elgablis-work">Elgabli&rsquo;s work</h5>
<p>考虑了基于 SVC 的优先自适应视频传输的两条路径。</p>
<ul>
<li>属于每一层的段可以根据质量、块deadline和路径偏好从可用路由之一传输。</li>
<li>没有考虑在任何路径上应用最大贡献度。</li>
</ul>
<h5 id="zhangs-work">Zhang&rsquo;s work</h5>
<p>提出了一种基于两个流的优先级感知自适应解决方案，它为每个流使用不同的视频比特率。</p>
<ul>
<li>实现了一个集成带宽的方式来为高优先级流启用更高的视频比特率，并在没有足够的可用带宽时终止低优先级流。</li>
</ul>
<h5 id="yun-and-chungs-work">Yun and Chung&rsquo;s work</h5>
<p>为多视图视频提出了一种基于DASH的推流框架，它包括基于缓冲区的服务器推送方案和并行传输机制，以减少不同传输视图之间的切换时间。</p>
<ul>
<li>只有一种路径配置被应用。</li>
</ul>
<h5 id="rahman-and-chungs-work">Rahman and Chung&rsquo;s work</h5>
<p>介绍了基于 HAS 的多视图会议流解决方案，其中演示者、观众和演示屏幕的多个流通过多条路径同时传输。</p>
<ul>
<li>对所有的3个流分配相同的优先级。</li>
<li>采用统一带宽的方式，以便于统一的质量可以被分配到所有流的segment上。</li>
<li>对于多个流的每个segment，其路径以通过考虑网络吞吐量和每个segment的比特率来决定。</li>
<li>没有考虑多信道的影响，这可能降低整体性能。</li>
</ul>
<p>利用多路径网络的特点和优先级特性可以为360度tile视频推流提供更高的推流性能。</p>
<p>提出的所有自适应策略都是通用的，目标是标准的视频交付，并没有对360度视频内容做出特别的考虑。</p>
]]></description>
</item><item>
    <title>360度流媒体面临的挑战、机遇和解决方案</title>
    <link>https://ayamir.github.io/posts/note1/</link>
    <pubDate>Wed, 20 Oct 2021 20:08:38 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://ayamir.github.io/posts/note1/</guid>
    <description><![CDATA[<h2 id="360度流媒体视频框架">360度流媒体视频框架</h2>
<h3 id="视频采集和拼接">视频采集和拼接</h3>
<p>使用不同的360度视频采集相机可以将视频内容存储为3D的球形内容</p>
<h3 id="使用不同的投影策略实现降维">使用不同的投影策略实现降维</h3>
<p>策略主要分为2种：视角独立型和视角依赖型</p>
<h4 id="视角独立型">视角独立型</h4>
<p>整个3D的视频内容被按照统一的质量投影到2D平面上</p>
<p>主要包括等距长方形投影和立方贴图投影</p>
<h5 id="等距长方形投影erp">等距长方形投影(ERP)</h5>
<p>使用左右偏向和俯仰值将观察者周围的球体展平到二维表面上</p>
<p>视角范围：左180度～右180度、上90度～下90度</p>
<p>缺点：</p>
<ul>
<li>极点处会使用比赤道处更多的像素进行表示，会消耗有限的带宽</li>
<li>由于图像失真导致压缩效率不足</li>
</ul>
<h5 id="立方贴图投影cmp">立方贴图投影(CMP)</h5>
<p>六面立方体组合用于将球体的像素映射到立方体上的相关像素</p>
<p>在游戏中被广泛应用</p>
<p>优点：</p>
<ul>
<li>节省空间，相比于等距长方形投影视频体积能减少25%</li>
</ul>
<p>缺点：</p>
<ul>
<li>只能渲染有限的用户视野</li>
</ul>
<h4 id="视角依赖型">视角依赖型</h4>
<p>视角内的内容比之外的内容有更高保真度的表示</p>
<p>主要包括金字塔投影、截断方形金字塔投影(TSP)和偏移立方贴图投影</p>
<h5 id="金字塔投影">金字塔投影</h5>
<p>球体被投影到一个金字塔上，基础部分有最高的质量，大多数的投影区域属于用户的视角方向</p>
<p>优点：</p>
<ul>
<li>节省空间，降低80%的视频体积</li>
</ul>
<p>缺点：</p>
<ul>
<li>用户以120度旋转视角时，视频的质量会像旋转180度一样急速下降</li>
</ul>
<h5 id="截断方形金字塔投影">截断方形金字塔投影</h5>
<p>大体情况和金字塔投影相同，区别在与使用了被截断的方形金字塔</p>
<p>优点：</p>
<ul>
<li>减少了边缘数据，提高了高码率视频的推流性能</li>
</ul>
<p>缺点：</p>
<ul>
<li>使边缘更加锐利</li>
</ul>
<h5 id="偏移立方贴图投影">偏移立方贴图投影</h5>
<p>与原始的立方贴图投影类似，球体的像素点被投影到立方体的6个面上</p>
<p>优点：</p>
<ul>
<li>视角方向的内容会有更高的质量，提供平滑的视频质量变化</li>
</ul>
<p>缺点：</p>
<ul>
<li>存储开销很大</li>
</ul>
<h3 id="编码视频内容">编码视频内容</h3>
<p>目前主要的编码方式有AVC/H.264和HEVC/H.265。</p>
<h4 id="h264">H.264</h4>
<p>使用16x16的宏块结构对帧编码。</p>
<p>因为使用了编码器的动作预测的特性，编码的数据大小得到减少。</p>
<h4 id="h265">H.265</h4>
<p>相比于同质量的H.264编码方式，H.265编码减少了50%的比特率。</p>
<p>H.265支持tiling特性来实现高效视频推流。</p>
<p>每个tile在物理上被分割然后在普通的流中拼接，并且使用一个解码器来解码。</p>
<h4 id="vvc">VVC</h4>
<p>相比于H.265，下一代标准VVC有望提高30%的压缩效率。</p>
<h3 id="分包和传输">分包和传输</h3>
<h4 id="分包">分包</h4>
<p>使用DASH协议分包。</p>
<h4 id="传输">传输</h4>
<p>依赖于雾计算和边缘计算等技术可以缩短分发中心和客户端之间的距离进而实现快速响应和低缓冲时间。</p>
<h3 id="渲染和展示">渲染和展示</h3>
<h4 id="客户端处理">客户端处理</h4>
<p>主流方案是使用客户端处理，但是由于会处理不属于用户视角范围内的视频内容，所以会造成计算资源的浪费。</p>
<h4 id="云端处理">云端处理</h4>
<p>另一种方案是使用云端处理，只有用户视角内的视频内容会被传输到客户端，没有更多的带宽和客户端硬件资源要求。</p>
]]></description>
</item></channel>
</rss>
