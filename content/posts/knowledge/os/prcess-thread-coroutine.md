---
title: "进程、线程和协程"
date: 2024-04-06T19:23:04+08:00
draft: false
math: true
keywords: ["进程", "线程", "协程"]
tags: ["os"]
categories: ["knowledge"]
url: "posts/knowledge/os/prcess-thread-coroutine"
---

## 进程

### 是什么

学操作系统课的时候学过一句话叫做：进程是操作系统资源分配的最小单位，进程的资源直接由 OS 分配，并存储在进程控制块 PCB 中：

- 进程标识符 PID
- 进程状态：就绪、运行、阻塞
- 内存资源：
  - 代码段、数据段、堆和栈
- 文件描述符 fd ：
  - stdin、stdout、stderr、以及进程打开的文件描述符列表比如本地文件以及网络连接等的 fd
- 寄存器：
  - PC、SP、还有其他的通用寄存器
- 进程控制信息：
  - 父进程 ID ，子进程 ID ，以及信号处理器这些

### 有什么用

在拿进程和程序做对比的时候我们知道，进程就是运行着的程序（这里的运行指的是程序被加载到内存空间中然后开始按照程序指令执行，而不是指进程状态中的运行状态），受 OS 的调度，可以说我们写程序的目的就是要让 CPU 可以按照磁盘上的代码指令来执行操作，进程就是实现这一目的的过程。

因为 OS 使用了虚拟内存这一概念，使得每个进程都认为自己是独占 OS 的，所以一个进程是不知道其他进程的存在的。因而如果面对需要多个进程协作完成一项任务的时候（其实这种情况的描述从逻辑上应该是自上到下的，先有的是一项任务，我们通过分析发现这两个任务需要写多个程序来完成），就会不可避免地引入进程间通信 IPC 。

常用的进程间通信手段大概有 6 种：消息队列、共享内存、匿名管道、命名管道、信号量、Socket，这几种方式根据需求的不同都有自己的用武之地，不过我个人最习惯用的还是 Socket ，因为它具有最优的可扩展性（跨主机、跨语言），可记录性（可以使用 tcpdump/wireshark 抓包），也完美符合我对于通信这一名词想象（明确的通信双方、全双工的信道）。

从我的实际项目经历中来看，我的 Unity 客户端实例需要把游戏运行过程中产生的 2D 轨迹数据输入给 Python 端的 AI 模型，并获取模型输出。对于这一场景，我的首选就是 Socket 通信，首先是因为 Socket 具备全双工的特性可以满足需求，其次是使用 Socket 可以在 AI 模型部署到其他主机上的时候也能正常运行。

## 线程

### 是什么

上面说到进程是 OS 资源分配的最小单位，这句话的下半句是：线程是操作系统调度的最小单位，这句话其实暗示了，线程和进程的概念对于单线程的进程而言是相同的。

OS 在调度 CPU 的时候是以线程为单位的，也就说明线程其实也是一种 OS 级别的概念。对于 Linux 而言，线程和进程使用的是相同的数据结构 `task_struct` 来表示的，不过进程的创建使用的是 `fork()` 这一系统调用，而线程的创建用的是 `clone()` 这一系统调用。

结合前半句话，说明 OS 在分配资源的时候分配不到线程这个层面上（单线程进程是特例），对于同一个进程的多个线程，他们之间共享进程的代码段、数据段和 fd 这些，不过每个线程都拥有自己独立的堆、栈空间。

### 有什么用

因为每个进程都会拥有上面列出的这些资源，直接受到 OS 的控制，所以进程的创建和销毁不可避免地会涉及到相对比较大的时间开销。

相比之下，线程因为可以直接继承并共享进程的部分资源，所以线程的创建和销毁要更加轻量。

也正因如此，同一进程之间的多个线程之间只需要使用一些编程上的技法就可以完成通信，常用的就是各种锁、条件变量以及阻塞队列。

### 什么时候用多线程

首先需要考虑的是能不能使用多线程。多线程的执行过程是 OS 调度 CPU 的多个核心来分别执行多个线程的过程，因而最适合使用多线程的任务一定具备：划分给各个线程之间的任务没有重叠、也无需通信（或者说没有依赖关系）的特性，每个任务都是 Compute-Intensive 的。

从我的实际项目经历中来看，在把 GPU 显存中的 yuv 图像数据回读到内存中的时候，图像的不同部分之间是相互独立的，因而这个过程天然适合使用多线程来完成，主线程只需要等待多个线程读完数据之后执行下一步操作即可。

其次需要考虑的是多线程能带来多大的收益。单线程和多线程的区别其实就是可以占有并利用的 CPU 核心数的区别，因此当任务的瓶颈不在于 CPU 的时候就需要考虑是否有使用多线程的必要。根据 Amdahl's law ，$S(n)=\frac{1}{(1-P)+\frac{P}{n}}$，当处理单元数趋向于无穷的时候，并行化所带来的加速比 $S(n)$ 将趋近于 $\frac{1}{1-P}$​ 。如果任务中可并行的部分比较小的情况下，可能就没有并行化的必要了。

![image-20240406212828943](https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20240406212828943.png)

实际任务中使用的线程数量应该结合**可以利用的系统资源（CPU 和内存）**和**相应任务的性能瓶颈**两方面考虑，这里之所以要强调是可以利用的资源是因为我们需要从 OS 的角度来考虑，如果当前进程使用了 CPU 的全部核心，那么 OS 上的其他任务就不能得到及时响应，当然因为线程本身需要独立的堆栈空间，所以线程的理论上限需要考虑内存大小。另一方面，多线程本质上只是在提高当前任务对于 CPU 的使用率，但是一个任务的执行不可能只用到 CPU ，还会用到内存以及可能涉及 IO 操作。就算是不涉及锁的并行读操作，也需要考虑 IO 可以利用的总线带宽大小，所以对于这样的任务使用多线程并行化带来的性能提升曲线应该会随着线程数的增多而呈现先升后降的趋势。还是以我上面遇到的问题为例，从 GPU 显存回读数据到内存中的操作就会受到 PCIe 总线带宽的限制，如果线程数过多就会造成多个线程对于总线的争用，这样就会导致性能下降。

### 怎么用多线程

默认的多线程使用方式就是在需要多线程执行任务的时候创建线程，在任务执行完毕之后销毁线程（就是直接交给 OS 来进行线程的创建和销毁）。

而实际上，我们常用的是线程池的方式，也就是在任务开始的时候我们就创建多个线程并且保存在一个线程池中，通过任务队列的形式确定将那个任务分配给哪个线程。这样做的方式其实就是把对线程的控制权从 OS 转移到程序员，避免了重复的线程创建和销毁带来的开销。

下面是使用 C++ 实现的一个简单的线程池：

```cpp
#include <condition_variable>
#include <functional>
#include <iostream>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>

class Task {
public:
  Task(std::function<void()> f) : func(f) {}
  void operator()() const { func(); }

private:
  std::function<void()> func;
};

class ThreadPool {
public:
  ThreadPool(size_t numThreads) : stop(false) {
    for (size_t i = 0; i < numThreads; ++i) {
      workers.emplace_back([this] {
        for (;;) {
          std::function<void()> task;
          {
            std::unique_lock<std::mutex> lock(queueMutex);
            condition.wait(lock, [this] { return stop || !tasks.empty(); });
            if (stop && tasks.empty())
              return;
            task = std::move(tasks.front());
            tasks.pop();
          }
          task();
        }
      });
    }
  }

  template <class F> void enqueue(F &&f) {
    {
      std::unique_lock<std::mutex> lock(queueMutex);
      tasks.emplace(std::forward<F>(f));
    }
    condition.notify_one();
  }

  ~ThreadPool() {
    {
      std::unique_lock<std::mutex> lock(queueMutex);
      stop = true;
    }
    condition.notify_all();
    for (std::thread &worker : workers) {
      worker.join();
    }
  }

private:
  std::vector<std::thread> workers;
  std::queue<Task> tasks;
  std::mutex queueMutex;
  std::condition_variable condition;
  bool stop;
};

// 示例任务函数
void printHello(int num) {
  std::cout << "Hello from thread " << num << std::endl;
}

int main() {
  ThreadPool pool(4); // 创建线程池，包含4个线程

  // 向线程池添加任务
  for (int i = 0; i < 8; ++i) {
    pool.enqueue([i] { printHello(i); });
  }

  return 0;
}
```

## 协程

### 是什么

协程这一概念可以理解为“函数plus”，普通的函数只有两种行为：调用(Invoke)和返回(Return)。协程比函数多了一种行为：挂起(Suspend/Yield)。

在只使用函数的情况下，程序的执行流可以只用一个栈就能模拟（调用函数时 push ，函数返回时 pop ），而引入协程之后，因为其具有挂起这一行为，所以需要额外的空间（比如堆）来暂存协程的上下文。

### 有什么用

协程的作用可以用一句话来描述，即：协程就是用单线程的方式完成并发的任务逻辑。

协程其实与进程和线程没有太近的“亲缘关系”，只是在作用上有着相近的效果，即宏观上看是并发执行的。以经典的生产者-消费者任务为例：

- 多进程/多线程：至少需要一个生产者进程/线程，消费者进程/线程，两者之间可能需要使用一个单向管道作为数据缓冲区来提高性能（或者说控制管道大小来实现不同的任务逻辑）。
- 协程：只需要一个线程，通过两个分别负责生产和消费的协程来完成，即：生产者协程生产一定数量之后挂起，并调用消费者协程。消费者协程消费完之后挂起，并调用生产者协程，如此交替往复进行。

协程相比于上面提到的进程和线程，区别在于协程是运行在用户态的，或者说协程的控制权是掌握在程序员手中的，由程序员负责控制在什么时候把 CPU 的使用权交给哪个协程。

### 什么时候用协程

协程的使用情形其实很简单，即：你需要在只利用一个 CPU 核心的情况下完成并发任务的时候就是使用协程的时候。所以其实协程这个概念诞生的很早（1960年 Melvin Conway 解决COBOL 编译器的问题，使用协程技术只需要遍历一遍源代码）

### 怎么用

目前 C++ 的协程只是在 C++20 中提供了机制，标准库的实现可能会在下一个版本 C++23 中提供。

Go 中的 Goroutine 其实并不受程序员调度，其挂起行为由 Go runtime 调度。

## 总结

从进程到线程再到协程的概念，其使用层级是逐级向上的。

- 如果希望程序可以充分利用多核资源来实现 CPU 密集型操作的并行加速，那可以使用多线程，通过使用锁/条件变量等方式来完成线程之间的协作。
- 如果不满 OS 的任务/线程调度策略，那可以在程序中使用并调度协程，用单线程+异步的逻辑来完成宏观上的并发操作。
